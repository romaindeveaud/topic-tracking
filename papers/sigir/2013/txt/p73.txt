An Experimental Study on Implicit Social Recommendation

Hao Ma

Microsoft Research
One Microsoft Way
Redmond, WA 98052

haoma@microsoft.com

ABSTRACT
Social recommendation problems have drawn a lot of at-
tention recently due to the prevalence of social networking
sites. The experiments in previous literature suggest that
social information is very eﬀective in improving traditional
recommendation algorithms. However, explicit social infor-
mation is not always available in most of the recommender
systems, which limits the impact of social recommendation
techniques.
In this paper, we study the following two re-
search problems: (1) In some systems without explicit so-
cial information, can we still improve recommender systems
using implicit social information? (2) In the systems with
explicit social information, can the performance of using im-
plicit social information outperform that of using explicit so-
cial information? In order to answer these two questions, we
conduct comprehensive experimental analysis on three rec-
ommendation datasets. The result indicates that: (1) Im-
plicit user and item social information, including similar and
dissimilar relationships, can be employed to improve tradi-
tional recommendation methods. (2) When comparing im-
plicit social information with explicit social information, the
performance of using implicit information is slightly worse.
This study provides additional insights to social recommen-
dation techniques, and also greatly widens the utility and
spreads the impact of previous and upcoming social recom-
mendation approaches.

Categories and Subject Descriptors
H.3.3 [Information Search and Retrieval]: Information
Filtering

General Terms
Algorithm, Experimentation

Keywords
Matrix Factorization, Recommender Systems, Implicit So-
cial Information, Singular Value Decomposition

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
SIGIR’13, July 28–August 1, 2013, Dublin, Ireland.
Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

1.

INTRODUCTION

Due to the rapid growth of information on the Web, espe-
cially on the social Web, recommender system has become
an indispensable technique for ﬁltering and recommending
online information.
In order to satisfy Web users’ ever-
increasing information needs, traditional recommendation
techniques have been widely adopted by various products
in industrial companies, including but not limited to Ama-
zon, Netﬂix, Apple iTunes, Yahoo! News, etc.

Traditional recommendation techniques normally only take
into account the user-item rating matrix for computing rec-
ommendations. Recently, based on the intuition that users’
social network information can be utilized to improve rec-
ommendation qualities, the research of social recommender
systems becomes popular. Several social recommendation
approaches [8, 9, 20, 21] have been proposed in the litera-
ture. These methods suggest that the explicit social infor-
mation is very helpful in improving the traditional methods,
especially when the user-item rating matrix is sparse.

In general, most of the social recommendation methods
are based on the matrix factorization framework, which is
both eﬀective and eﬃcient in generating recommendations.
Typically, social information is utilized to better shape the
user latent space. Diﬀerent intuitions on interpreting these
social information will result in diﬀerent objective functions
or learning models.
In [20], a social recommendation ap-
proach is proposed by adding the social regularization term
to the matrix factorization objective function. In this method,
the additional social regularization term ensures that the
distance of the latent feature vectors of two friends will be-
come closer if these two friends share similar tastes. The
experimental results illustrate that social recommendation
approaches are very eﬀective at improving traditional rec-
ommendation techniques, especially when few ratings are
available.

Although social recommendation methods have been ex-
tensively studied in the literature, many problems are still
left unexplored.

The essence of social recommendation methods is utiliz-
ing users’ explicit social connections to improve recommen-
dation results. However, explicit social connection informa-
tion is not always available in real-world recommender sys-
tems. Only few Web sites have implemented the social or
trust mechanisms, like Epinions (http://www.epinions.com,
a general consumer review site that was established in 1999,
where users can also add other users into their trust list)
and Doudan (http://www.douban.com, the largest Chinese
Web 2.0 site devoted for movies, books, and music reviews

73item social information is also very helpful in in-
creasing the recommendation performance.

• When explicit social information is available:

– We ﬁnd that using implicit social information per-
forms slightly worse than using explicit social in-
formation.

– We also conclude that a social network with larger
friend diversity is more eﬀective in improving rec-
ommendation quality.

The remainder of this paper is organized as follows. Sec-
tion 2 introduces previous methods that are related to this
work. Section 3 details one popular matrix factorization
method in the literature. Section 4 presents how to incorpo-
rate implicit social information. The results of an empirical
analysis are presented in Section 5, followed by the conclu-
sion in Section 6.

2. RELATED WORK

In this section, we review several popular approaches for
recommender systems in the literature, including: (1) tradi-
tional recommender systems, especially matrix factorization
based methods, and (2) social recommendation methods.
2.1 Traditional Recommender Systems

Traditional recommender systems normally only utilize
the user-item rating information for recommendation. One
of the the most popular techniques in recommender systems
is collaborative ﬁltering.

Typically, collaborative ﬁltering approaches include two
types of methods: memory-based methods as well as model-
based approaches. Memory-based methods focus on using
predeﬁned similarity calculation functions to ﬁnd similar
users or items for generating predictions. Memory-based
methods can be further classiﬁed as user-based [2, 4, 10] and
item-based approaches [3, 16, 27] based on whether similar
users or similar items are used.

In contrast to the memory-based methods, the model-
based approaches use the observed ratings to train a prede-
ﬁned learning model. The ratings are then predicted via the
trained model instead of directly manipulating the original
rating database as the memory-based approaches [17]. Algo-
rithms in this category include but not limited to clustering
model [11], the aspect models [5, 6, 28], the Bayesian hier-
archical model [33], the ranking model [17], etc. Hofmann
in [5] proposed an algorithm based on a generalization of
probabilistic latent semantic analysis to continuous-valued
response variables. Kohrs et al. [11] presented an algorithm
for collaborative ﬁltering based on hierarchical clustering,
which tried to balance both robustness and accuracy of pre-
dictions, especially when few data were available. Recently,
due to the eﬀectiveness and eﬃciency in dealing with very
large user-item rating matrices, several low-dimensional ma-
trix factorization techniques [15, 24, 25, 26, 29, 31] have been
proposed.

Matrix factorization methods in recommender systems nor-
mally seek to factorize the user-item rating matrix into two
low rank user-speciﬁc and item-speciﬁc matrices, and then
utilize the factorized matrices to make further predictions.
Low-rank matrix approximations based on minimizing the
sum-squared errors can be easily solved using Singular Value

Figure 1: Explicit and Implicit Social Relationships

that was launched in 2005). Lacking of social recommenda-
tion data greatly limits the impact and utilization of social
recommendation methods.

Fortunately, in case that we do not have explicit social
information, we can always compute a set of implicit social
information for each user. We summarize the relationships
between users’ explicit social information and implicit social
information in a toy example illustrated in Figure 1. In this
ﬁgure, users within the blue solid circle represent explicit
social connections of user ui, while users within the purple
dashed circle represent this user’s implicit social informa-
tion, which is calculated using some similarity metrics.

Thus, in this paper, based on the example shown in Fig-
ure 1, we are interested in exploring the following two re-
search problems:

1. Can we take advantages of implicit social information
in case we do not have explicit social connection infor-
mation?

2. When the explicit social information is available, can
the performance of using implicit social information
outperform that of using explicit social information?

In order to answer the questions, in this paper, we conduct
comprehensive experiments on three datasets: the Movie-
Lens and EachMovie datasets, which do not have explicit
social information, as well as the Douban dataset, which has
a social network in addition to the user-item rating matrix.
Based on our analysis, we have the following conclusions:

• When explicit social information is unavailable:

– In the absence of explicit user social information,
we ﬁnd that using implicit user social information
(i.e., the most similar users), can also improve
the recommendation qualities under the matrix
factorization framework.

– Besides the most similar users, for each user, the
list of most dissimilar users is another ideal source
to further improve recommender systems.

– We extend the idea of computing implicit user so-
cial information, and conclude that the implicit

74Decomposition (SVD), and a simple and eﬃcient Expecta-
tion Maximization (EM) algorithm for solving weighted low-
rank approximation is proposed in [29]. In [30], Srebro et
al. proposed a matrix factorization method to constrain the
norms of U and V instead of their dimensionality. Salakhut-
dinov et al. presented a probabilistic linear model with
Gaussian observation noise in [25]. The user and item latent
factors can be learned by maximize the proposed probabilis-
tic likelyhood function. The proposed method is very eﬀec-
tive and eﬃcient, and this method is essentially equivalent
to the Regularized SVD method.
In their following work
proposed in [26], Salakhutdinov et al. placed the Gaussian-
Wishart priors on the user and item hyperparameters, which
can further improve the prediction accuracy. More recently,
Koren et al. [12, 13, 14] proposed several enhanced matrix
factorization methods which illustrate promising results by
incorporating heterogeneous information.
In [12], the au-
thors discussed the possibility to improve recommender sys-
tems using neighborhood information, which is quite related
to our work. However, in this paper, we focus on very dif-
ferent aspect of recommender system, i.e., social recommen-
dation. Moreover, we provide many additional insights that
previous work ignored.

2.2 Social Recommendation

The above mentioned traditional recommendation tech-
niques are all based on working on the user-item rating ma-
trix, and ignore the abundant relationships among users.
Recently, due to the prevalence of Web 2.0 social networking
sites, many researchers have started studying social recom-
mender systems [1, 7, 8, 9, 20, 21, 22, 23, 32].

Due to the nature of each method, the social recommenda-
tion techniques can also be classiﬁed into two types: memory-
based [1, 8, 21, 22, 23] and model-based [7, 9, 20, 32].

The memory-based methods normally directly or indi-
rectly use the degree of social trust to represent the simi-
larity between two users. In [21], a trust-aware method for
recommender system is proposed. In this work, the collabo-
rative ﬁltering process is replaced by the reputation of users,
which is computed by propagating trust. The degrees of
trust are calculated to replace the similarity value between
two users. The experiments on a large social recommenda-
tion dataset - Epinions, show that this work increases the
coverage (number of ratings that are predictable) while not
decreasing the accuracy (the error of predictions). In [23],
two trust-aware methods are proposed to improve standard
collaborative ﬁltering methods. The experimental results
indicate that the user trust information can help improve
recommendation quality.

More recently, by taking advantages of the eﬀectiveness
and eﬃciency of matrix factorization framework, several novel
model-based methods have been proposed to enhance tradi-
tional matrix factorization methods by incorporating user
social information. In [20], two Social Regularization meth-
ods have been proposed by constraining the matrix factoriza-
tion objective function with user social regularization terms.
Diﬀerent with previous methods, the proposed methods are
very general, they not only work with user trust relation-
ships, but also perform well with user social friend relation-
ships. The experimental analysis indicates that the proposed
framework outperforms other state-of-the-art methods.

Although the aforementioned matrix factorization based
social recommendation methods move a nice step forward

in the research of recommender systems, their utilities are
limited since these methods require using explicit user so-
cial information, which is not always available in most of
the recommender systems. In [18], the idea of using implicit
information is brieﬂy introduced, however, many interesting
problems are left unattended. In this paper, we present an
comprehensive experimental study on implicit social recom-
mendation which provides many useful insights to current
social recommendation techniques.

3. MATRIX FACTORIZATION

In this subsection, we review one popular matrix factor-

ization method that is widely studied in the literature.

Considering an m×n matrix R describing m users’ ratings
on n items, a low-rank matrix factorization approach seeks
to approximate the frequency matrix R by a multiplication
of d-rank factors R ≈ U T V , where U ∈ Rd×m and V ∈ Rd×n
with d << min(m, n). The matrix R in the real-world is
usually very sparse since most of the users only visited a
few Web sites.

Traditionally, the Regularized Singular Value Decomposi-
tion (RSVD) method is employed to estimate a matrix R by
minimizing

L = min
U,V

+

λ1
2

1
2

mXi=1

nXj=1

||U ||2

F +

Iij (rij − uT

i vj )2

λ2
2

||V ||2
F ,

(1)

where ui and vj are column vectors with d values, Iij is the
indicator function that is equal to 1 if user i rated item j
and equal to 0 otherwise, and λ1, λ2 represent the regulariza-
tion parameters. The optimization problem in Equation 1
minimizes the sum-of-squared-errors objective function with
quadratic regularization terms.

By adopting a simple stochastic gradient descent tech-
nique, for each observed rating rij, we have the following
eﬃcient updating rules to learn latent variables ui, vj :

ui ← ui + γ1(∆ij vj − λ1ui),
vj ← vj + γ2(∆ijui − λ2vj ),

(2)

where

∆ij = rij − uT

i vj,

and γ1, γ2 are the learning rates.

The Regularized SVD algorithm introduced in this section
is both eﬀective and eﬃcient in solving the collaborative
ﬁltering problem and it is perhaps one of the most popular
methods in collaborative ﬁltering. In this paper, we use this
approach as the baseline method.

4.

INCORPORATING IMPLICIT SOCIAL IN-
FORMATION

In this section, we ﬁrst introduce a matrix factorization-
based social recommendation method proposed in the liter-
ature. Then we illustrate how to leverage the implicit user
social information in the case that explicit user social in-
formation is not available. Finally, we demonstrate how to
utilize dissimilar users as well as item social information to
further improve recommender systems.

Note that the main focus of this paper is designing a sci-
entiﬁc experimental study to explore several interesting re-
search problems by borrowing and extending previous social

75recommendation techniques. Developing brand new social
recommendation techniques is out of the scope of this pa-
per. Also, we will only brieﬂy describe the techniques if they
are borrowed from previous work.
4.1 Social Regularization

In [20], in order to model the social recommendation prob-
lems more accurately, a general social recommendation ap-
proach, Social Regularization (SR), is proposed.

The objective function of this approach is formulated as:

L = min
U,V

+

α
2

1
2

nXj=1
mXi=1
mXi=1 Xf ∈F +(i)

Iij (rij − uT

i vj )2

sif kui − uf k2

F

+

λ1
2

λ2
2

kU k2

F +

kV k2
F ,

(3)

where α is the regularization parameter, sif indicates the
similarity between user i and user f , and F +(i) represents
user i’s outlink friends.

In this method, the social network information is em-
ployed in designing the social regularization term to con-
strain the matrix factorization objective function. The social
regularization term also indirectly models the propagation
of tastes. More speciﬁcally, if user i has a friend f and user
f has a friend user g, this regularization term actually indi-
rectly minimizes the distance between latent vectors ui and
ug. The propagation of tastes will reach a harmonic status
once the learning is converged.

Similarly, for each observed rating rij , we have the follow-
ing stochastic gradient descent updating rules to learn the
latent parameters:

ui ← ui + γ1(cid:16)∆ijvj − α Xf ∈F +(i)

−α Xg∈F −(i)

sig(ui − ug) − λ1ui(cid:17),

vj ← vj + γ2(∆ijui − λ2vj),

sif (ui − uf )

where

∆ij = rij − uT

i vj ,

(4)

(5)

and F −(i) represents user i’s inlink friends.
4.2 Implicit User Social Relationships

As mentioned in Section 1, all the social recommendation
approaches need to utilize the additional explicit user social
information, which may limit the impact and utilization of
these approaches. In this section, we seek an alterative way
to compute implicit user social information once the explicit
user social relationships are unavailable.

The essence of social recommendation approaches lies in
the additional explicit social information of each user. The
information of these social friends can then be utilized to
help model a user’s taste more accurately.
In the case of
missing explicit social information, as shown in Figure 1, we
can always compute another set of Top-N similar users and
then plug in those similar users to the aforementioned social
recommendation matrix factorization framework.

There are several methods we can borrow in the literature
to compare the similarity between two users. In this paper,

we adopt the most popular approach Pearson Correlation
Coeﬃcient (PCC) [2], which is deﬁned as:

sif =

Xk∈I(i)∩I(f )

(rik − ri) · (rf k − rf )

s Xk∈I(i)∩I(f )

(rik − ri)2 ·s Xk∈I(i)∩I(f )

,

(6)

(rf k − rf )2

where I(i) is a set of items that rated by user i, and ri
represents the average rate of user i. From this deﬁnition,
user similarity sif is ranging from [−1, 1], and a larger value
means users i and f are more similar. We employ a map-
ping function f (x) = (x + 1)/2 to bound the range of PCC
similarities into [0, 1].

Based on the PCC similarity, the computed Top-N sim-
ilar users can then be injected into the objective function
detailed in Equation 3.

4.3 Dissimilar Users

So far in this paper, we only consider utilizing similar users
to improve recommender systems. In the social regulariza-
tion term sif ||ui − uf ||2
F employed in Equation 3, if user i is
similar to user f , the distance between latent vectors ui and
uf will become closer since the similarity sif is a relatively
large value.

Motivated by the similar users, we can actually endow the
social regularization term more modeling power if we also
include the most dissimilar users. If user i is dissimilar with
user f , the ideal property we want is to make the distance
between ui and uf larger or in other words, maximize the
distance between them.
Inspired by the work in [19], we
can easily achieve this property by turning the similarity
sif = −sif . Hence, in this case, the social regularization
term sif ||ui − uf ||2
F will actually lead to make the distance
between ui and uf larger. This is an ideal property we desire
to include those dissimilar users.

Hence, in this paper, in addition to the Top-N similar
users, we also include the Top-N dissimilar users for each
user. This will not change the objective function mentioned
in Equation 3. It will only increase the size of the implicit
social neighbors speciﬁed in the set F +(i) and change the
signs of the similarity values for dissimilar users.

4.4 Item Social Relationships

In the original social recommendation problems, there are
only social relationships among users due to the reason that
normally, social network only refers to the social relation-
ships between people.

In this paper, since we deﬁne the implicit user social infor-
mation as the similar or dissimilar users, we can naturally
extend this idea to also take advantages of the implicit item
social information, which can be found through the similar
or dissimilar items.

The Social Regularization method described in Section 4.1
is a very general approach, and it can be easily extended
to incorporate the item social information. The objective
function can be formulated as:

76L = min
U,V

+

β
2

1
2

nXj=1
mXi=1
nXj=1 Xq∈Q+(j)

Iij(rij − uT

i vj )2

sjqkvj − vqk2

F

+

λ1
2

λ2
2

kU k2

F +

kV k2
F ,

(7)

where Q+(j) represents item j’s implicit social information
(i.e., the Top-N items similar to item j and the Top-N items
dissimilar to item j).

The similarity between item j and item q can be calculated

by the item-based PCC method:

sjq=

Xk∈U (j)∩U (q)

(rkj − rj) · (rkq − rq)

s Xk∈U (j)∩U (q)

(rkj − rj)2 ·s Xk∈U (j)∩U (q)

,

(8)

(rkq − rq)2

where U (j) denotes a set of users that rated item j.

Similarly, we have the following updating rules to learn

the latent parameters:

ui ← ui + γ1(∆ijvj − λ1ui),

vj ← vj + γ2(cid:16)∆ij ui − β Xq∈Q+(j)

−β Xh∈Q−(j)

sjh(vj − vh) − λ1vj(cid:17),

sjq(vj − vq)

(9)

4.5 A Uniﬁed Model

From Section 4.2 to Section 4.4, we demonstrate how to
utilize implicit user social information, dissimilar users, and
item social information, respectively. We can then design
the following integrated model to take into account all the
possible information that will potentially beneﬁt the recom-
mender systems:

For every observed rating rij , we have the following stochas-

tic updating rules to learn the all the latent parameters:

sif (ui − uf )

ui ← ui + γ1(cid:16)∆ijvj − α Xf ∈F +(i)

−α Xg∈F −(i)

sig(ui − ug) − λ1ui(cid:17),

vj ← vj + γ2(cid:16)∆ij ui − β Xq∈Q+(j)

−β Xh∈Q−(j)

sjh(vj − vh) − λ1vj(cid:17),

sjq(vj − vq)

(12)

where

∆ij = rij − uT

i vj.

The uniﬁed model is constrained by four types of infor-
mation: similar user regularization, dissimilar user regular-
ization, similar item regularization and dissimilar item reg-
ularization. We use the aforementioned information to help
better shape the user and item latent spaces, hence generate
more accurate recommendation results.

5. EXPERIMENTAL ANALYSIS

In this section, we conduct several experiments to com-
pare diﬀerent recommendation methods using implicit social
information. Our experiments are intended to address the
following questions:

• When explicit social information is unavailable:

1. Is implicit user social information eﬀective in im-
proving traditional matrix factorization methods?

2. Can dissimilar users be used to further improve

the recommendation quality?

3. Can we also take advantages of implicit item so-
cial information in addition to the implicit user
social information?

4. What is the performance comparison on users with

• When explicit social information is available:

1. Can the performance of using implicit social in-
formation outperform that of using explicit social
information?

We use the popular Mean Absolute Error (MAE) and
Root Mean Square Error (RMSE) metrics to measure the
prediction quality of all the mentioned algorithms. MAE is
deﬁned as:

M AE = Pi,j |rij −brij|

N

,

(13)

where rij denotes the rating user i gave to item j,brij denotes

the related predicted rating, and N denotes the number of
tested ratings. RMSE is deﬁned as:

RM SE =sPi,j (rij −brij)2

N

.

(14)

where

∆ij = rij − uT

i vj .

(10)

diﬀerent observed ratings?

L = min
U,V

Iij (rij − uT

i vj )2

1
2

mXi=1
nXj=1
mXi=1 Xf ∈F +(i)
nXj=1 Xq∈Q+(j)

λ2
2

+

+

+

α
2

β
2

λ1
2

sif kui − uf k2

F

sjqkvj − vqk2

F

kU k2

F +

kV k2
F ,

(11)

From the deﬁnitions, we can see that a smaller MAE or
RMSE indicates a better performance.

77Table 1: Statistics of Dataset MovieLens

Statistics

User

Item

Min. Num. of Ratings
Max. Num. of Ratings
Avg. Num. of Ratings

20
737

106.04

1
583
59.45

Table 2: Statistics of Dataset EachMovie

Statistics

User

Item

Min. Num. of Ratings
Max. Num. of Ratings
Avg. Num. of Ratings

1

1,455
37.78

1

32,868
1,706.30

5.1 Without Explicit Social Information

5.1.1 Description of Datasets

When the explicit social information is not available, we
evaluate all the algorithms on two popular datasets: Movie-
Lens1 and EachMovie2.

The MovieLens dataset we adopt in this paper is a rela-
tively small dataset contains 100,000 user-item ratings (scale
from 1 to 5) rated by 943 users on 1,642 items. The Each-
Movie data set is a relatively large dataset includes 74,424
users, 1,648 movies, and 2,811,718 ratings in the range from
0 to 5.

Other statistics of these two datasets are summarized in

Table 1 and Table 2, respectively.

5.1.2 Performance Analysis

In this section, we will compare the following diﬀerent
methods described in this paper as well as some baseline
methods.

1. UserMean: this is a baseline method uses the mean

value of every user to predict the missing values.

2. ItemMean:

this is a baseline method utilizes the
mean value of every item to predict the missing values.

3. RSVD: this is the Regularized SVD method.

It is
equivalent with the method proposed by Salakhutdi-
nov and Minh in [25]. The underlining distribution is
assumed as Gaussian distribution. The details of this
method are also introduced in Section 3.

4. SRu+: this is the Social Regularization method using
implicit similar user information. The notation u in
the superscript denotes that implicit user social infor-
mation is used in this method, while the notation “+”
indicates only similar users are included.

5. SRu+−: this is the Social Regularization method using
both implicit similar and dissimilar user information.
The notation “−” indicates dissimilar information is
included.

6. SRi+: this is the Social Regularization method using
implicit similar item information. We use the subscript
to describe item related information.

1http://www.grouplens.org/system/ﬁles/ml-100k.zip.
2http://www.research.digital.com/SRC/EachMovie/.
now retired by Hewlett-Packard (HP).

It is

7. SRi+−: this is the Social Regularization method using
both implicit similar and dissimilar item information.

8. SRu+−

i+− : this is the ﬁnal integrated model that using
similar and dissimilar user information as well as sim-
ilar and dissimilar item information.

Data Preparation.

For all the experiments conducted in this section, we uti-
lize 80% as training data in both datasets. Training data
80%, for example, means we randomly select 80% of the
ratings from the MovieLens or the EachMovie dataset as
the training data to predict the remaining 20% of ratings.
Top-N Neighbors Generation.

The methods we study in this paper also involve the cal-
culation of the Top-N similar and Top-N dissimilar users
or items. We adopt the following rules to generate Top-N
similar and dissimilar users or items. In order to reduce the
noises when computing the similarities using PCC method
between two users i and f , we require that user i and user f
should at least co-rated 10 items, otherwise, we will ignore
user f when computing user i’s Top-N similar or dissimilar
neighbors, and vice versa. Furthermore, for all the simi-
lar neighbors, the similarity between two users should be
greater than 0.75, while for all the dissimilar neighbors, the
similarity between two users should be less than 0.25. The
same rules are also adopted when calculating similar and
dissimilar items.
Parameter Settings.

In order to fairly compare every method, we employ simi-
lar parameter settings for those common parameters adopted
In this paper, for RSVD, SRu+,
in all the approaches.
SRu+−, SRi+, SRi+− and SRu+−
i+− , we use the setting λ1 =
λ2 = 0.01. At the same time, all the learning rates γ1 and
γ2 are set to 0.005. For all the Social Regularization based
methods, α and β are set to 0.015 in the MovieLens dataset,
while in the EachMovie dataset, they are set to 0.001.
Performance Analysis.

The experimental results using 10 and 50 dimensions to
represent the latent factors in two diﬀerent datasets are
shown in Table 3 and Table 4, respectively. The percentages
in the results are the improvements of our SRu+−
i+− method
over the corresponding approaches. In all our methods, the
number of implicit user or item social neighbors are set to
10.

The following summarizes the key conclusions we observe

from the results:

• We ﬁrst notice that approach SRu+ outperforms the
RSVD method, which only utilizes the user-item rating
matrix. This observation coincides with our intuition
that, at the absence of the explicit user social network,
employing implicit user social information can help in-
crease the recommendation quality.

• Secondly, besides the implicit user social information,
the implicit item social information can also be used to
improve the recommendation quality, as demonstrated
by the method SRi+. Among SRu+ and SRi+, we
observe that SRi+ generates better results than SRu+
in both datasets. A possible reason is that the rating
styles of items typically have less diversities that those
of users. Hence, the similarity calculation based on

78Table 3: Performance Comparisons (MovieLens)

Dataset Dimension Metrics UserMean ItemMean RSVD SRu+ SRu+− SRi+ SRi+− SRu+−
i+−

MovieLens

10D

50D

MAE

Improve
RMSE
Improve

MAE

Improve
RMSE
Improve

0.8389
12.59%
1.0466
11.29%
0.8389
13.21%
1.0466
11.90%

0.8274
0.7525
11.37% 2.55%
1.0359
0.9540
10.37% 2.68%
0.8274
0.7416
12.00% 1.82%
1.0359
0.9413
10.99% 2.04%

0.7411 0.7400 0.7409 0.7398 0.7333

0.9421 0.9406 0.9403 0.9391 0.9284

0.7330 0.7321 0.7329 0.7320 0.7281

0.9298 0.9291 0.9292 0.9280 0.9221

Table 4: Performance Comparisons (EachMovie)

Dataset Dimension Metrics UserMean ItemMean RSVD SRu+ SRu+− SRi+ SRi+− SRu+−
i+−

EachMovie

10D

50D

MAE

Improve
RMSE
Improve

MAE

Improve
RMSE
Improve

1.1409
23.91%
1.4278
19.88%
1.1409
24.88%
1.4278
20.63%

1.1020
0.8854
21.23% 1.95%
1.3851
1.1678
17.41% 2.04%
1.1020
0.8751
22.22% 2.06%
1.3851
1.1579
18.18% 2.12%

0.8737 0.8725 0.8701 0.8690 0.8681

1.1520 1.1506 1.1491 1.1487 1.1440

0.8631 0.8614 0.8597 0.8588 0.8571

1.1413 1.1401 1.1389 1.1374 1.1333

Dimensionality = 10

Dimensionality = 10

 

RSVD
SRu+−
i+−

8000

7000

6000

5000

4000

3000

2000

1000

s
g
n
i
t
a
R

 
t
s
e
T

 
f
o
 
r
e
b
m
u
N

0.86

0.84

0.82

0.8

0.78

0.76

0.74

0.72

E
A
M

0.7
[1, 20)

 

 

RSVD
SRu+−
i+−

1.1

1.08

1.06

1.04

1.02

1

0.98

0.96

0.94

0.92

0.9

E
S
M
R

 

[1, 20)

[20, 40)

[40, 80)

[80, 160)

[160, 320)

Number of Observed Ratings

>=320

0

[1, 20)

[20, 40)
Number of Observed Ratings

[40, 80)

[80, 160) [160, 320) >=320

[20, 40)

[40, 80)

[80, 160)

[160, 320)

>=320

Number of Observed Ratings

(a) MAE Comparison on Diﬀerent User
Rating Scales (MovieLens)

(b) RMSE Comparison on Diﬀerent User
Rating Scales (MovieLens)

(c) Distribution of Testing Data (Movie-
Lens)

Figure 2: Performance Comparison on Diﬀerent Users (MovieLens)

E
A
M

0.96

0.94

0.92

0.9

0.88

0.86

0.84

0.82

 

[1, 20)

Dimensionality = 10

Dimensionality = 10

 

RSVD
SRu+−
i+−

 

RSVD
SRu+−
i+−

1.28

1.26

1.24

1.22

1.2

1.18

1.16

1.14

1.12

1.1

E
S
M
R

[20, 40)

[40, 80)

[80, 160)

[160, 320)

Number of Observed Ratings

>=320

1.08

 

[1, 20)

[20, 40)

[40, 80)

[80, 160)

[160, 320)

>=320

Number of Observed Ratings

x 104

15

s
g
n

i
t

a
R

 
t
s
e
T

 
f

o

 
r
e
b
m
u
N

12.5

10

7.5

5

2.5

0

[1, 20)

[20, 40)
Number of Observed Ratings

[40, 80)

[80, 160) [160, 320) >=320

(a) MAE Comparison on Diﬀerent User
Rating Scales (EachMovie)

(b) RMSE Comparison on Diﬀerent User
Rating Scales (EachMovie)

(c) Distribution of Testing Data (Each-
Movie)

Figure 3: Performance Comparison on Diﬀerent Users (EachMovie)

79items is probably more accurate than the calculation
based on users.

• Thirdly, another key observation we ﬁnd through the
experiments is that dissimilar user or item informa-
tion can be used to further improve the recommender
systems, as presented by the approaches SRu+− and
SRi+−. They generate slightly better results than SRu+
and SRi+, respectively.

• Fourthly, an integrated model SRu+−

i+− demonstrates
the best performance by incorporating all the useful
implicit social information, including similar and dis-
similar users as well as similar and dissimilar items. In
general, the experimental results not only prove the ef-
fectiveness of incorporating implicit social information,
but also demonstrate the ﬂexibility of social regular-
ization framework.

5.1.3 Prediction Accuracy on Different Users

In order to analyze the experiments thoroughly, in this
section, we evaluate how diﬀerent methods perform on dif-
ferent users based on how many ratings the users rated in
the training datasets. We ﬁrst group all the users in the
training datasets based on the number of observed ratings,
and then measure the prediction accuracies of diﬀerent user
groups. The experimental results conducted in both Movie-
Lens and EachMovie datasets are illustrated in Figure 2 and
Figure 3, respectively. In these two ﬁgures, in order to in-
terpret the results more intuitively, we include the baseline
method RSVD for comparison since it does not include any
social information.

Users are grouped into 6 classes: “[1, 20)”, “[20, 40)”, “[40,
80)”, “[80, 160)”,“[160, 320)” and “>=320”. Figure 2(c) and
Figure 3(c) summarizes the distributions of the number of
testing data according to the groups in the training data.
For example, in the EachMovie dataset, there are a total of
70,677 user-item pairs need to be predicted in the testing
dataset in which the related users in the training dataset
have rated 1 to 19 items.

From Figure 2(a), Figure 2(b), Figure 3(a) and Figure 3(b),
we can see that the method SRu+−
i+− with implicit social in-
formation consistently outperforms the RSVD method in
all the user groups. We also notice an interesting phe-
nomenon, that is, the method SRu+−
i+− performs much bet-
ter than RSVD when more ratings are observed. Actually,
when more ratings are observed for a user, the similarity cal-
culation process will ﬁnd more accurate similar or dissimilar
neighbors for this user since we have more information to
represent or interpret this user. Hence, it will perform bet-
ter than RSVD especially when more ratings are observed.
5.2 With Explicit Social Information

5.2.1 Description of Dataset

We use the Douban3 dataset in this subsection since in
addition to the user-item rating matrix, it also contains a
social friend network between users.

Douban is a Chinese Web 2.0 Web site providing user rat-
ing, review and recommendation services for movies, books
and music. Users can assign 5-scale integer ratings (from 1 to
5) to movies, books and music. It also provides Facebook-
like social networking services, which allows users to ﬁnd
3http://www.douban.com

Table 5: Statistics of User-Item Matrix of Douban

Statistics

User

Item

Min. Num. of Ratings
Max. Num. of Ratings
Avg. Num. of Ratings

1

1

6,328
129.98

49,504
287.51

Table 6: Statistics of Friend Network of Douban

Statistics

Friends per User

Max. Num.
Avg. Num.

986
13.07

Table 7: Performance Comparisons (5D)

40%

Training Data Metrics
SRexp
MAE
0.5698
RMSE 0.7214
MAE
0.5640
RMSE 0.7133

60%

SRimp
0.5707
0.7223
0.5648
0.7142

SRtop10
imp
0.5705
0.7222
0.5645
0.7139

their friends through their email accounts. This means that
most of the friends on Douban actually know each other
oﬄine.

The Douban dataset we study in this paper contains 129,490
unique users and 58,541 unique movies with 16,830,839 movie
ratings. As to the social friend network, the total number of
friend links between users is 1,692,952. The statistics of the
Douban user-item rating matrix and social friend network
are summarized in Table 5 and Table 6, respectively.
5.2.2 Performance Analysis

We compare the following three methods using Douban

datasets:

1. SRexp: this is the social regularization method de-
scribed in Equation 3, which utilizes the explicit social
information in improving recommender systems.

2. SRimp: this is the social regularization method that
uses the implicit social information. Suppose that user
ui has n explicit social connections in the Douban
dataset, then we will choose the most similar n users
as the implicit social connections in this method. This
setting is employed to fairly compare the method SRimp
with SRexp.

3. SRtop10

imp : this is also a social regularization method
uses implicit social information. Diﬀerent with SRimp,
for each user, we use the top-10 most similar users as
the implicit connections.

All the parameters of the above three methods are identical
for fairly comparison.

The results are summarized in Table 7.

In this table,
we evaluate three methods using diﬀerent percentages of
training data, i.e., 40% and 60%. From the results, we sur-
prisedly ﬁnd that for all the settings, the SRexp method
performs slightly better than both SRimp and SRtop10
imp ap-
proaches, which indicates that in recommender systems, us-
ing user-established explicit social connections are better
than computer-generated implicit social information.

In order to ﬁnd out why using explicit social connections
is more eﬀective, we conduct the consistence analysis on

80very general matrix factorization framework is employed to
incorporate diﬀerent implicit social information. The exper-
imental analysis suggests that similar user information, dis-
similar user information, similar item information and dis-
similar item information can be eﬀectively used to improve
recommender systems. Our work not only provides in-depth
insights to social recommendation techniques, but also will
greatly extend the impact of previous and upcoming social
recommendation approaches.

7. REFERENCES
[1] P. Bedi, H. Kaur, and S. Marwaha. Trust based

recommender system for the semantic web. In
Proceedings of the 20th international joint conference
on Artiﬁcal intelligence, IJCAI’07, pages 2677–2682,
Hyderabad, India, 2007.

[2] J. S. Breese, D. Heckerman, and C. Kadie. Empirical

analysis of predictive algorithms for collaborative
ﬁltering. In Proceedings of the Fourteenth conference
on Uncertainty in artiﬁcial intelligence, UAI’98, pages
43–52, Madison, Wisconsin, 1998.

[3] M. Deshpande and G. Karypis. Item-based top-n

recommendation. ACM Transactions on Information
Systems, 22(1):143–177, 2004.

[4] J. L. Herlocker, J. A. Konstan, A. Borchers, and

J. Riedl. An algorithmic framework for performing
collaborative ﬁltering. In Proceedings of the 22nd
annual international ACM SIGIR conference on
Research and development in information retrieval,
SIGIR ’99, pages 230–237, Berkeley, California, USA,
1999.

[5] T. Hofmann. Collaborative ﬁltering via gaussian

probabilistic latent semantic analysis. In Proceedings
of the 26th annual international ACM SIGIR
conference on Research and development in
informaion retrieval, SIGIR ’03, pages 259–266,
Toronto, Canada, 2003.

[6] T. Hofmann. Latent semantic models for collaborative
ﬁltering. ACM Transactions on Information Systems,
22(1):89–115, 2004.

[7] J. Huang, X.-Q. Cheng, J. Guo, H.-W. Shen, and

K. Yang. Social recommendation with interpersonal
inﬂuence. In Proceedings of the 19th European
Conference on Artiﬁcial Intelligence, ECAI ’10, pages
601–606, Amsterdam, The Netherlands, 2010.

[8] M. Jamali and M. Ester. Trustwalker: a random walk

model for combining trust-based and item-based
recommendation. In Proceedings of the 15th ACM
SIGKDD international conference on Knowledge
discovery and data mining, KDD ’09, pages 397–406,
Paris, France, 2009.

[9] M. Jamali and M. Ester. A matrix factorization

technique with trust propagation for recommendation
in social networks. In Proceedings of the fourth ACM
conference on Recommender systems, RecSys ’10,
pages 135–142, Barcelona, Spain, 2010.

[10] R. Jin, J. Y. Chai, and L. Si. An automatic weighting
scheme for collaborative ﬁltering. In Proceedings of the
27th annual international ACM SIGIR conference on
Research and development in information retrieval,
SIGIR ’04, pages 337–344, Sheﬃeld, United Kingdom,
2004.

Figure 4: Similarity Consistence Analysis

three social networks we have, including one explicit (used
in SRexp method), and two implicit social networks (used in
SRimp and SRtop10
imp methods). The questions we address in
this analysis are: How consistent are one user’s social peers?
Do the similarities between a user and his/her social peers
vary a lot?

In order to answer the above questions, we evaluate the
consistences based on the following metric, i.e., Root Mean
Square Distance (RMSD). The deﬁnitions of user i are:

RM SD =sPf ∈S(i)(sif − si)2

|S(i)|

,

(15)

where sik is the similarity between user i and user k deﬁned
in Equation 6, si is the average social similarity of user i,
while S(i) represents the list of social peers of user i.

From the deﬁnitions, we can see that we are actually mea-
suring in what extent a user’s social similarity sif will devi-
ate from his/her average social similarity si. If a user’s so-
cial peer similarities all fall into a small range, then his/her
RMSD will be relatively small, which indicates this user’s
social peers are very consistent with this user. If we observe
a large RMSD value, then this user’s social peers are rela-
tively diverse. Figure 4 shows the analysis results of RMSD.
We notice that the curves of these three social networks
illustrate diﬀerent patterns. The ﬁgure reveals that a very
large portion of users in the generated two implicit networks
have very small RMSD values, which implies that users’ so-
cial peers are relatively more consistent in these two implicit
social networks. The RMSD values in Douban explicit friend
communities are relatively larger, which presents that users’
social peers in this network are more diverse.

Combining the results we obtain from Table 7, this ob-
servation actually suggests that social network with larger
friend diversity is more eﬀective in improving recommenda-
tion quality. This conclusion also coincides with the intu-
ition we propose in Section 4.3, i.e., dissimilar users can also
be utilized to improve recommender systems.

6. CONCLUSION

This paper studies a research problem on how to improve
recommender systems using implicit social information. A

81[11] A. Kohrs and B. Merialdo. Clustering for collaborative

[23] J. O’Donovan and B. Smyth. Trust in recommender

ﬁltering applications. In Proceedings of CIMCA ’99,
1999.

[12] Y. Koren. Factorization meets the neighborhood: a

multifaceted collaborative ﬁltering model. In
Proceedings of the 14th ACM SIGKDD international
conference on Knowledge discovery and data mining,
KDD ’08, pages 426–434, Las Vegas, Nevada, USA,
2008.

systems. In Proceedings of the 10th international
conference on Intelligent user interfaces, IUI ’05,
pages 167–174, San Diego, California, USA, 2005.

[24] J. D. M. Rennie and N. Srebro. Fast maximum margin

matrix factorization for collaborative prediction. In
Proceedings of the 22nd International Conference on
Machine Learning, pages 713–719, Bonn, Germany,
2005.

[13] Y. Koren. Collaborative ﬁltering with temporal

[25] R. Salakhutdinov and A. Mnih. Probabilistic matrix

dynamics. In Proceedings of the 15th ACM SIGKDD
international conference on Knowledge discovery and
data mining, KDD ’09, pages 447–456, Paris, France,
2009.

[14] Y. Koren, R. M. Bell, and C. Volinsky. Matrix

factorization techniques for recommender systems.
IEEE Computer, 42(8):30–37, 2009.

[15] M. Kurucz, A. A. Benczur, and K. Csalogany.

Methods for large scale svd with missing values. In
Proceeding of KDD CUP ’07, San Jose, CA, USA,
2007.

[16] G. Linden, B. Smith, and J. York. Amazon.com

recommendations: Item-to-item collaborative ﬁltering.
IEEE Internet Computing, pages 76–80, Jan/Feb 2003.
[17] N. N. Liu and Q. Yang. Eigenrank: a ranking-oriented

approach to collaborative ﬁltering. In Proceedings of
the 31st annual international ACM SIGIR conference
on Research and development in information retrieval,
SIGIR ’08, pages 83–90, Singapore, Singapore, 2008.

[18] H. Ma, I. King, and M. R. Lyu. Learning to

recommend with explicit and implicit social relations.
ACM Transactions on Intelligent Systems and
Technology, 2(3):29:1–29:19, May 2011.

[19] H. Ma, M. R. Lyu, and I. King. Learning to

recommend with trust and distrust relationships. In
Proceedings of the third ACM conference on
Recommender systems, RecSys ’09, pages 189–196,
New York, New York, USA, 2009.

[20] H. Ma, D. Zhou, C. Liu, M. R. Lyu, and I. King.

Recommender systems with social regularization. In
Proceedings of the fourth ACM international
conference on Web search and data mining, WSDM
’11, pages 287–296, Hong Kong, China, 2011.

[21] P. Massa and P. Avesani. Trust-aware collaborative
ﬁltering for recommender systems. In Proceedings of
CoopIS/DOA/ODBASE ’04, pages 492–508, 2004.

[22] P. Massa and P. Avesani. Trust-aware recommender
systems. In Proceedings of the 2007 ACM conference
on Recommender systems, RecSys ’07, pages 17–24,
Minneapolis, MN, USA, 2007.

factorization. In Proceedings of Advances in Neural
Information Processing Systems, NIPS ’07, 2007.

[26] R. Salakhutdinov and A. Mnih. Bayesian probabilistic
matrix factorization using markov chain monte carlo.
In Proceedings of the 25th international conference on
Machine learning, ICML ’08, pages 880–887, Helsinki,
Finland, 2008.

[27] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl.

Item-based collaborative ﬁltering recommendation
algorithms. In Proceedings of the 10th international
conference on World Wide Web, WWW ’01, pages
285–295, Hong Kong, Hong Kong, 2001.

[28] L. Si and R. Jin. Flexible mixture model for

collaborative ﬁltering. In Proceedings of the 20th
International Conference on Machine Learning, ICML
’03, pages 704–711, 2003.

[29] N. Srebro and T. Jaakkola. Weighted low-rank

approximations. In Proceedings of the 20th
International Conference on Machine Learning, pages
720–727, Washington, DC, USA, 2003.

[30] N. Srebro, J. D. M. Rennie, and T. Jaakkola.

Maximum-margin matrix factorization. In Proceedings
of Advances in Neural Information Processing
Systems, NIPS ’04, 2004.

[31] K. Yu, S. Zhu, J. Laﬀerty, and Y. Gong. Fast

nonparametric matrix factorization for large-scale
collaborative ﬁltering. In Proceedings of the 32nd
international ACM SIGIR conference on Research and
development in information retrieval, SIGIR ’09, pages
211–218, Boston, MA, USA, 2009.

[32] Q. Yuan, L. Chen, and S. Zhao. Factorization vs.

regularization: fusing heterogeneous social
relationships in top-n recommendation. In Proceedings
of the ﬁfth ACM conference on Recommender systems,
RecSys ’11, pages 245–252, Chicago, Illinois, USA,
2011.

[33] Y. Zhang and J. Koren. Eﬃcient bayesian hierarchical

user modeling for recommendation system. In
Proceedings of the 30th annual international ACM
SIGIR conference on Research and development in
information retrieval, SIGIR ’07, pages 47–54,
Amsterdam, The Netherlands, 2007.

82