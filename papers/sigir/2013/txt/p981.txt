From Keywords to Keyqueries:
Content Descriptors for the Web

Tim Gollub

Matthias Hagen

Maximilian Michel

Benno Stein

Bauhaus-Universität Weimar

99421 Weimar, Germany

<ﬁrst name>.<last name>@uni-weimar.de

ABSTRACT

We introduce the concept of keyqueries as dynamic content descrip-
tors for documents. Keyqueries are deﬁned implicitly by the index
and the retrieval model of a reference search engine: keyqueries
for a document are the minimal queries that return the document
in the top result ranks. Besides applications in the ﬁelds of infor-
mation retrieval and data mining, keyqueries have the potential to
form the basis of a dynamic classiﬁcation system for future digital
libraries—the modern version of keywords for content description.
To determine the keyqueries for a document, we present an ex-
haustive search algorithm along with effective pruning strategies.
For applications where a small number of diverse keyqueries is
sufﬁcient, two tailored search strategies are proposed. Our experi-
ments emphasize the role of the reference search engine and show
the potential of keyqueries as innovative document descriptors for
large, fast evolving bodies of digital content such as the web.

Categories and Subject Descriptors: H.3.3 [Information Search
and Retrieval]: Retrieval Models, Query Formulation

General Terms: Algorithms, Experimentation, Performance

Keywords: keyquery, content description, automatic query formu-
lation, exhaustive search, search strategies

1.

INTRODUCTION

A content descriptor is a word or a short phrase that expresses
the central topical aspect or the domain of a document. Typical ex-
amples can be found in the meta section below this paper’s abstract:
the categories, general terms, and keywords integrate the document
into the ACM classiﬁcation system.

We propose an additional modern means of document content de-
scription: search queries. The underlying idea is that those queries
that return a given document in their top ranks for some reference
search engine “describe” the document’s content well enough to
stand out from the indexed collection. If the query is maximally
general (i.e., no subset of the query has the same property), we call
it a keyquery for the document. The validity check of a query’s suit-
ability as a document’s content descriptor is straightforward: sub-
mission to the reference search engine.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
SIGIR’13, July 28–August 1, 2013, Dublin, Ireland.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

In the context of digital libraries, keyqueries constitute an inter-
esting alternative to keywords, which typically are manually chosen
free form content descriptors. The advantage of keyqueries is that
their descriptiveness can be automatically tested using the library’s
search engine. Whenever a candidate is not descriptive enough, ad-
ditional terms can be suggested or automatically added. Carried
out consequently, the keyquery approach includes validity checks
for the whole library on every new insertion of a document, and
automatic re-establishment when necessary. This way, keyqueries
can form the basis of a dynamic and automatically maintained clas-
siﬁcation system for digital libraries. Especially for fast evolving
large-scale bodies of digital content, where manually maintained
classiﬁcation systems need enormous manpower to stay up to date,1
dynamic classiﬁcation with keyqueries is an effective alternative.

In information retrieval systems, keyqueries can serve as query
recommendations to ﬁnd related resources for a speciﬁed docu-
ment, or to implement query expansion and relevance feedback
techniques. For data mining tasks such as clustering, a “bag of
queries” document representation can be based on the keyqueries
of the dataset, and the relevance scores of the search engine can be
used as the feature weights. As the concept of search queries nowa-
days is well understood by web users, keyqueries might even be
used as cluster labels—especially when clustering search results.

In the following section, we review literature related to the con-
cept of keyqueries and give pointers to the state of the art in various
potential applications. Section 3 provides algorithms for ﬁnding
the keyqueries of a document and explores options for pruning the
search space. In Section 4, we report on our experiments with key-
queries of scientiﬁc papers using different reference search engines.
Our ﬁndings reveal that the concept of keyqueries is sound and ef-
fectively applicable. We conclude with an outlook on future work.

2. RELATED WORK

The state-of-the-art technique for the automated generation of
content descriptors is keyword or keyphrase extraction. Actually,
we chose the term keyquery in dependence on these two concepts.
A survey of current research in the ﬁeld is given in the overview pa-
per of the 2010 SemEval competition on keyphrase extraction [9].
In particular, and as will be discussed in detail in Section 3, we use
keyword extraction in a subroutine to efﬁciently ﬁnd a small subset
of diverse keyqueries. For the respective experiments presented in
Section 4, we employ the TextRank algorithm [10]. TextRank is an
unsupervised keyword and keyphrase extraction technique that rep-
resents a document as a graph and determines a keyword ranking
by applying the PageRank algorithm.

1A famous manually maintained, large-scale classiﬁcation system
is the Yahoo! directory, which went ofﬂine in Europe recently.

981{w1, w2, w3, w4, w5}

{w1, w2, w3, w4}

{w1, w2, w3, w5}

{w1, w2, w4, w5}

{w1, w3, w4, w5}

{w2, w3, w4, w5}

{w1,w2,w3}

{w1,w2,w4}

{w1,w2,w5}

{w1,w3,w4}

{w1,w3,w5}

{w1,w4,w5}

{w2,w3,w4}

{w2,w3,w5}

{w2,w4,w5}

{w3,w4,w5}

{w1, w2}

{w1, w3}

{w1, w4}

{w1, w5}

{w2, w3}

{w2, w4}

{w2, w5}

{w3, w4}

{w3, w5}

{w4, w5}

{w1}

{w2}

{w3}

{w4}

{w5}

}
{ 

too specific

keyquery(cid:13)

too general

Figure 1: The search space Q for a ﬁve-word vocabulary, divided into the three subspaces too generic, keyqueries Q∗, and too speciﬁc.

A dynamic classiﬁcation system based on keyqueries requires
an efﬁcient means to store and update the keyqueries. An ade-
quate data structure has been proposed by Pickens et al. in 2010:
the reverted index [11]. As its name suggests, the reverted in-
dex is related to the inverted index used in search engines, but
it stores queries in document postlists—instead of documents in
term postlists.
In their experiments on query recommendation
and relevance feedback, Pickens et al. populate the reverted in-
dex with unigram queries and suggest the usage of n-gram queries
or queries from query logs for further performance improvements.
Keyqueries now contribute a third sophisticated alternative with a
sound theoretical justiﬁcation.

Once keyqueries are stored in a reverted index, the next step to-
wards a dynamic classiﬁcation system is to derive a hierarchical
structuring of the queries. Bonchi et al. introduce this task as top-
ical query decomposition [3], since the queries of a common class
should represent “coherent, conceptually well-separated topics.” In
their work, Bonchi et al. achieve good results by using a set cover
algorithm with red-blue metric for the problem.

Also in the ﬁeld of data mining, inspiring related work exists. In
their optimum clustering framework (OCF) [4], Fuhr et al. suggest
to represent documents as “bags of queries” and to use the rele-
vance scores or retrieval ranks for each query as the feature weights.
Keyqueries ﬁt very naturally into the proposed scheme. That they
might be even more appropriate than arbitrary queries in an OCF-
style clustering approach can be motivated from a ﬁnding of Az-
zopardi and Vinay: in their analysis of document retrievability with
search engines, they observed that simple bag-of-words representa-
tions with tf ·idf -based weights are biased towards a small number
of documents [2]. These documents appear in the top results for sig-
niﬁcantly more of the basic index terms than other documents. In
the context of the optimum clustering framework, a set of arbitrary
queries would thus come with a bias, obviously harming the over-
all effectiveness. Instead, a comparably unbiased feature set can
be formed by including the same number of keyqueries from each
document. The documents’ retrievabilities then are approximately
equal and the feature weights’ distribution is rather unbiased.

3. COMPUTING KEYQUERIES

In this section, we formalize the keyquery concept and present an
exhaustive search algorithm to ﬁnd all keyqueries for a given docu-
ment. We also explore possibilities to reduce the search space and
present two heuristic search strategies that are tailored to scenarios
where a few diverse keyqueries sufﬁce.

Keyqueries.

Given the vocabulary Wd = {w1, w2, . . . , wn} of a document d,
let Qd denote the family of search queries that can be formulated
from Wd without word repetitions; i.e., Qd is the power set of Wd,
Qd = 2Wd . Note that no distinction is made with respect to the
ordering of the words in a query. If it is clear from the context, we
omit the subscripts and just use W and Q to denote the vocabulary
and the potential queries from d.
A query q ∈ Q is a keyquery for d with respect to a reference
search engine S iff: (1) d is among the top-k results returned by S
on q, and (2) no subset q′ ⊂ q returns d in its top-k results when
submitted to S. The parameter k controls the level of keyquery
generality and is usually set to some small integer, such as 10 in
our case. Let Q∗ denote the set of keyqueries for d.
Figure 1 shows a visualization of Q and Q∗, which we adapted
from work done by Hagen and Stein on query formulation [6]. The
keyquery search space Q divides into three subspaces. The sub-
space of too-general-queries that do not retrieve the desired doc-
ument in the top-k results, the subspace Q∗ of keyqueries, and
the subspace of too-speciﬁc-queries all of which are supersets of a
shorter keyquery. An interesting query in the example is {w1, w5}
(third row): it is still too general but cannot be extended without
becoming too speciﬁc.

Exhaustive Search.

Note that an exhaustive search in Q is required in order to ﬁnd
all keyqueries for a given document. Previous work in the ﬁeld
of query formulation used an adapted version of the Apriori algo-
rithm [1] to identify queries not returning too many results [7]. The
Apriori algorithm stems from the ﬁeld of frequent itemset mining
and is considered one of the top ten data mining algorithms [12].
It is more efﬁcient than enumerating Q in an arbitrary level-wise
order. As frequent itemset mining is very similar to our keyquery
setting we also employ a tailored Apriori variant.

The pseudo-code listing of Apriori for keyquery identiﬁcation is
given in Algorithm 1. The algorithm starts with submitting all one-
word queries to the reference search engine (line 1) and evaluates
whether the queries are either keyqueries or too general (lines 2–3).
Note that it is assumed that the search engine always retrieves the
document at some rank in the result list since all query words are
present in the document. If the query combining all the candidate
terms in C1 is still too general (lines 4–5), all shorter queries have
to be too general as well and the algorithm can immediately ter-
minate returning Q∗. The main loop of the algorithm (lines 7–15)

982Algorithm 1 The Apriori algorithm for keyquery search

document d with vocabulary W

Input:
Output: the family Q∗ of keyqueries

1: for all w ∈ W do submit(w)
2: Q∗← {w : w ∈ W and w is keyquery}
3: C1 ← {w : w ∈ W and w too general}
4: submit(Sw∈C1 w)
5: if Sw∈C1 w too general then stop and output Q∗
6: i ← 1
7: while Ci 6= ∅ do
8:
9:

for all q, q′ ∈ Ci do

if |q ∩ q′| = i − 1 then qcand ← q ∪ q′
if (qcand \ w) ∈ Ci for all w ∈ qcand then
if qcand 6∈ Ci+1 and qcand 6∈ Q∗ then

10:
11:
12:
13:

14:

i ← i + 1

15:
16: output Q∗

submit(qcand)
if qcand too general then Ci+1 ← Ci+1∪qcand
if qcand is keyquery then Q∗ ← Q∗ ∪ qcand

iterates through the search space in a level-wise manner, i.e., all
two-word keyquery candidates ﬁrst, then the three-word keyquery
candidates, etc. During this process, the search space is pruned
whenever possible: all queries which are supersets of identiﬁed
keyqueries can be omitted. The algorithm returns Q∗ if no new
candidate query qcand can be formulated.

Search Space Reduction.

Since the search space Q grows exponentially in the size of the
vocabulary, an effective strategy to prune Q is to reduce the vocabu-
lary ahead of a search. We call strategies that reduce the vocabulary
vertical pruning strategies, whereas horizontal pruning strategies
constrain the maximum length of the keyqueries to be found. In the
following, we explore pruning strategies of both kinds.

To understand the basic characteristics of contemporary content
descriptors, we analyze the 2012 version of the ACM Computing
Classiﬁcation System.2 Our review reveals that only three parts-
of-speech types are typically used for content descriptors: nouns
and noun combinations (e.g., web search), adjectives (e.g., person-
alized search), and conjunctions (e.g., retrieval models and rank-
ing). An appropriate vertical pruning strategy can thus ignore all
words that do not belong to any of these three classes. Furthermore,
adjectives are only considered when they appear in combination
with a noun. For the documents used in our experiments (cf. Sec-
tion 4), this vertical pruning results in a search space reduction to
about √2n, where n is the original vocabulary size.

We also infer a horizontal pruning strategy from the length of the
ACM content descriptors. The average descriptor length is about
three words, and up to eight words in extreme cases. Hence, we
suggest to not consider longer queries.

Heuristic Search Strategies.

For certain applications such as query recommendation, it is of-
ten not necessary to compute all keyqueries of a document; two or
three keyqueries with no or only a small term overlap could sufﬁce.
In such scenarios, heuristic search strategies can simply proceed in
a depth-ﬁrst manner. For this purpose, the TextRank algorithm [10]
provides an interesting basis. TextRank ranks each word of a doc-

2

http://dl.acm.org/ccs.cfm

ument by applying the PageRank procedure to a document’s graph
model: nodes represent words and edges connect words that occur
next to each other in the text. From the TextRank scores for words
and the graph representation, we derive two heuristic search strate-
gies. Note that the vertical pruning described above (vocabulary
reduction) is always applied.

Rank-Driven Search. An initially empty query is successively ex-
panded by that word from {w : w ∈ W, w /∈ q} with the highest
score until the document d is returned among the top-k results. As
the derived query q might be too speciﬁc, it may need to be mini-
mized. A straightforward solution is to successively remove each
word from q and to test whether d is still returned in the top-k (if
not, keep the word and try the next one). The reduced q then is
guaranteed to be a keyquery. To ﬁnd another keyquery with differ-
ent terms, start again with W = W \ {q∗} until no keyquery can
be found or sufﬁciently many have been returned.
Rank-driven search can also start from keyphrases instead of
words. This can be especially advisable for reference search en-
gines using proximity features or even allowing phrasal search—
good query segmentation then can help a lot [5].

Graph-Driven Search. A second heuristic search strategy can be
based on the TextRank graph. The ﬁrst term added to the initially
empty query q again is the highest scoring word w ∈ W . But then q
is extended by adding from all words adjacent to w in the TextRank
graph the word w∗ with the highest score.
If no adjacent word
exists, the word with the highest score from {w : w ∈ W, w /∈ q}
is used, similar to rank-driven search. The extension of w∗ works
analogously until a search with q has the document d among the
top-k results. Again, q is minimized as above by trying to remove
keywords, and the process restarts with W = W \{q∗} until either
enough keyqueries have been found or no more are possible.
Graph-driven search obviously favors phrases in the keyquery
generation and should work especially well for search engines that
include proximity features and allow phrasal search. However,
graph-driven search is also applicable with basic engines, then prob-
ably losing much of its potential.

4. EMPIRICAL ANALYSIS

Our empirical analyses are conducted in the setting of collections

of scientiﬁc papers and focus on the following two questions.

1. How many queries have to be submitted to determine one
keyquery for a paper against a contemporary search engine?
inﬂuence the number of submitted

2. Does citation count

queries or the keyqueries’ lengths?

The ﬁrst query addresses the efﬁciency or “costs” of keyquery
computation in general (typically query submissions require non-
negligible amounts of time) while the second query aims at evalu-
ating a potential factor inﬂuencing efﬁciency (Google often shows
highly cited papers in the top ranks).

Our experimental study is conducted on all the papers published
at the SIGIR and CIKM conferences in the years 1999–2012. To
address our ﬁrst question, we sample the document set SIGrandom
containing 50 random papers published at SIGIR. To address our
second question, we use the document set SIGcited of the 50 SIGIR
papers having the highest citation numbers in the ACM Digital
Library (DL). The three reference search engines are Google as
representative of current web search and two variants of a local
Lucene indexing the 3796 papers (phrasal search enabled): with
and without a logarithmic citation boost on the actual relevance
score (i.e., the score is multiplied with the log2 of the paper’s cita-
tion count obtained from the ACM DL). The granularity parameter

983Table 1: Keyquery statistics for two document sets and three reference search engines.

Search
engine

Google

Lucene

(citation boost)

Lucene

(no boost)

Document

set

SIGrandom
SIGcited

SIGrandom
SIGcited

SIGrandom
SIGcited

Query

submissions

Success

ratio

Keyquery

Retrieval

Result list

length

rank

length

18.8
10.6

4.4
14.4

5.5
3.4

60%
54%

100%
100%

100%
100%

7.3
5.7

3.2
3.6

3.4
2.8

3.1
4.2

4.1
4.9

4.0
3.5

3.2 million
3.5 million

89
161

88
234

is set to k = 10. Since Google imposes usage restrictions, we con-
strain the number of queries that can be submitted per document
to 128 for all the engines. This would allow exhaustive search with
seven words but in the experiments presented here, we focus on the
graph-driven heuristic and evaluate ﬁnding one keyquery per doc-
ument. The results of our experiments are shown in Table 1. All
values are averaged over the document sets.

Using Google, a keyquery is found for about 54–60% of the doc-
uments in the collections (success ratio). This does not mean that
the documents cannot be found using Google, but that within our
restricted budget of 128 query submissions no keyquery could be
identiﬁed. As expected, the average number of required queries in
case of success is lower for highly cited papers than for random
ones (10.6 vs. 18.8). Keyqueries for highly cited papers are also
shorter (5.7 vs. 7.3). The documents themselves are returned higher
in the ranking for random papers which is not that surprising as the
longer keyqueries are more speciﬁc; the total result list lengths are
of comparable magnitude (3.5 million). Given the size of Google’s
search index, the observed keyquery length is small; it is compara-
ble to manually created content descriptors in the ACM DL. How-
ever, the success ratio of only 54–60% supports Azzopardi and
Vinay’s ﬁnding that retrievability of documents often is an issue [2].
The low success ratio using Google cannot be further explored
due to the black-box characteristic of the search process. It is thus
interesting to compare the ﬁndings with the two Lucene instances
that we can control completely. As expected, the small size of the
index yields a perfect success ratio with Lucene and also enables
more efﬁcient construction (less query submissions) and shorter
keyqueries. Not surprisingly, the number of results of a keyquery
is much lower for Lucene than for Google.

Comparing the two document sets on the two Lucene instances
yields an interesting observation. Without citation boost, it is much
more difﬁcult to ﬁnd keyqueries for the highly cited papers than
for a random one (14.42 vs. 4.44 queries). A possible explanation
is that the highly cited papers are part of large research branches
with many papers on similar topics—the highly cited papers proba-
bly being the most inﬂuential ones. Without boosting highly cited
papers, it is much more difﬁcult to retrieve them from the rest. Ran-
dom papers on the other hand often do not have that many other
papers on similar topics such that keyqueries are easier to ﬁnd. The
average keyquery result list length also supports this explanation as
the result lists are longer for SIGcited keyqueries (161.34 vs. 88.56).
When the citation boost is included, the SIGcited papers are much
more easy to ﬁnd (11 queries less than without boost) and ranked
higher in even longer keyquery result lists. The random papers
instead require a little more effort than before but their keyquery
characteristics remain comparable.

5. SUMMARY

With the concept of keyqueries we introduce a dynamic means
to address the fast evolving bodies of digital content in our soci-

ety. The range of potential applications in information retrieval,
data mining, or digital library tasks underline the innovation and
relevance of our idea: relying on the acceptance, the agreed se-
mantics, and the approved indexing of keyword-based search en-
gines, the state-of-the-art search technologies become a viable re-
placement for manually constructed content descriptors. Our ex-
periments show that keyqueries can be effectivly constructed for
the majority of the analyzed documents when using a graph-driven
search, and that the role of the reference search engine as context
provider can be exploited to favor content with speciﬁc properties.
As for future work, it would be very interesting to study basic
characteristics of keyqueries for larger document corpora and to
further investigate the retrievability issues we observed for our re-
stricted budget with Google. In the digital library setting also the
actual acceptance of keyqueries with human users could be evalu-
ated. Other interesting research directions are the potential applica-
tions of keyqueries as suggestions to ﬁnd related documents or as
cluster labels in search scenarios.

Last but not least, note that the shortest possible keyquery for our
paper against the SIGIR-CIKM test corpus used in our experiments
is very simple: keyquery.

6. REFERENCES

[1] R. Agrawal and R. Srikant. Fast algorithms for mining association

rules in large databases. In VLDB 1994, pp. 487–499.

[2] L. Azzopardi and V. Vinay. Retrievability: An evaluation measure

for higher order information access tasks. In CIKM 2008, pp.
561–570.

[3] F. Bonchi, C. Castillo, D. Donato, A. Gionis. Topical query

decomposition. In KDD 2008, pp. 52–60.

[4] N. Fuhr, M. Lechtenfeld, B. Stein, T. Gollub. The optimum
clustering framework: Implementing the cluster hypothesis.
Information Retrieval, 15(2):93–115.

[5] M. Hagen, M. Potthast, A. Beyer, B. Stein. Towards optimum query

segmentation: In doubt without. In CIKM 2012, pp. 1015–1024.

[6] M. Hagen and B. Stein. Capacity-constrained query formulation. In

ECDL 2010, pp. 384–388.

[7] M. Hagen and B. Stein. Candidate document retrieval for web-scale

text reuse detection. In SPIRE 2011, pp. 356–367.

[8] E. Hatcher and O. Gospodnetic. Lucene in Action. Manning

Publications Co., 2004.

[9] S. N. Kim, O. Medelyan, M.-Y. Kan, T. Baldwin. SemEval-2010
task 5: Automatic keyphrase extraction from scientiﬁc articles. In
SemEval 2010.

[10] R. Mihalcea and P. Tarau. TextRank: Bringing order into texts. In

EMNLP 2004, pp. 404–411.

[11] J. Pickens, M. Cooper, G. Golovchinsky. Reverted indexing for

feedback and expansion. In CIKM 2010, pp. 1049–1058.

[12] X. Wu, V. Kumar, J. Ross Quinlan, J. Ghosh, Q. Yang, H. Motoda,

G. J. McLachlan, A. Ng, B. Liu, P. S. Yu, Z.-H. Zhou, M. Steinbach,
D. J. Hand, D. Steinberg. Top 10 algorithms in data mining.
Knowledge and Information Systems, 14(1):1–37, 2007.

984