Retrieving Documents With Mathematical Content

Shahab Kamali

Frank Wm. Tompa

David R. Cheriton School of Computer Science
University of Waterloo, Waterloo, ON, Canada

David R. Cheriton School of Computer Science
University of Waterloo, Waterloo, ON, Canada

skamali@cs.uwaterloo.ca

fwtompa@uwaterloo.ca

ABSTRACT
Many documents with mathematical content are published
on the Web, but conventional search engines that rely on
keyword search only cannot fully exploit their mathemati-
cal information. In particular, keyword search is insuﬃcient
when expressions in a document are not annotated with nat-
ural keywords or the user cannot describe her query with
keywords. Retrieving documents by querying their mathe-
matical content directly is very appealing in various domains
such as education, digital libraries, engineering, patent doc-
uments, medical sciences, etc. Capturing the relevance of
mathematical expressions also greatly enhances document
classiﬁcation in such domains.

Unlike text retrieval, where keywords carry enough se-
mantics to distinguish text documents and rank them, math
symbols do not contain much semantic information on their
own. In fact, mathematical expressions typically consist of
few alphabetical symbols organized in rather complex struc-
tures. Hence, the structure of an expression, which describes
the way such symbols are combined, should also be consid-
ered. Unfortunately, there is no standard testbed with which
to evaluate the eﬀectiveness of a mathematics retrieval al-
gorithm.

In this paper we study the fundamental and challenging
problems in mathematics retrieval, that is how to capture
the relevance of mathematical expressions, how to query
them, and how to evaluate the results. We describe various
search paradigms and propose retrieval systems accordingly.
We discuss the beneﬁts and drawbacks of each approach, and
further compare them through an extensive empirical study.

Categories and Subject Descriptors
H.3.3 [Information Storage And Retrieval]: Informa-
tion Search and Retrieval− Retrieval models

Keywords
Mathematics retrieval, Search, Math queries, Documents
with math content.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for proﬁt or commercial advantage and that copies bear
this notice and the full citation on the ﬁrst page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior speciﬁc permission and/or a fee. Request
permissions from permissions@acm.org.
SIGIR’13, July 28–August 1, 2013, Dublin, Ireland.
Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

1.

INTRODUCTION

Many collections of documents contain mathematical ex-
pressions. Examples include technical and educational web
sites, digital libraries, and other document repositories such
as patent collections. Currently, due to the lack of an ef-
fective mathematics retrieval system, such rich mathemati-
cal knowledge is not fully exploited when searching for such
documents. Querying with mathematical expressions, and
consequently retrieving relevant documents based on their
mathematical content, is not straightforward:

• Mathematical expressions are objects with complex
structures and rather few distinct symbols and terms.
The symbols and terms alone are usually inadequate to
distinguish among mathematical expressions. For ex-
j are quite similar, but 2n and n2

n(cid:80)

m(cid:80)

ample

i and

i=1

j=1

are quite dissimilar even though they share the same
symbols.

• Relevant mathematical expressions might include small
variations in their structures or symbols. For example,
jk might both be useful matches to

n(cid:80)

n(cid:80)

i2 and

1 +

i=1
a query.

j=1

• Each mathematical expression has two sides: i) its ap-
pearance (or presentation) and ii) its mathematical
meaning (often termed its content). The majority of
the published mathematical expressions are encoded
with respect to their appearance, and most instances
do not preserve much semantic information.

As is true for other retrieval systems, a mathematics search
engine should be evaluated based on its usefulness, that is,
how well it can satisfy users’ needs. What makes math-
ematics retrieval distinct is the diﬃculty of judging which
mathematical expressions are relevant and which are not.
For example, a user who is interested in sin2(x) might also
be interested in sin3(x) but not in cos2(x). We know of
no consensus for similarity of mathematical expressions in
general. On the other hand, if we were to limit the search
to exact matches only, many relevant expressions will be
missed, and the user might need to issue too many queries
to ﬁnd a useful answer. For example if the user is looking

1

(i+1)2 , then pages that contain

1

(j+1)2 ,

1

(i+1)2 ,

10(cid:80)

j=1

n(cid:80)

i=1

10(cid:80)
n(cid:80)

i=1

x=1

for

and

1
x2 probably also address her needs.

353Mathematics retrieval is still at an early stage. Unfortu-
nately, content-based mathematics retrieval systems [7, 15]
are limited to resources that encode the semantics of mathe-
matical expressions, and they do not perform well with pre-
sentation markup. The lack of content information within
web pages forces a retrieval system to rely mostly on the
presentation of expressions, and it is often hard to judge
whether a similar-looking expression is relevant to a query.
Some systems rely on the presentation of mathematical
expressions [3, 9, 20, 26, 27, 28], but they either ﬁnd exact
matches only or they use models that ignore the whole or
parts of the structure and usually return many irrelevant
results. They do not deﬁne how to measure the relevance of
matched mathematical expressions, and there has not been
much eﬀort to evaluate such systems in terms of the useful-
ness of search results.

In this paper we focus on the problem of matching mathe-
matical expressions, and hence we assume that a query con-
sists of a single expression. Systematically addressing this
problem is a prerequisite for developing systems that handle
more complex queries, such as ones that consist of multiple
expressions or a combination of expressions and keywords.
Because mathematical expressions are often distinguished
by their structure rather than relying merely on the sym-
bols they include, we describe two search paradigms that
incorporate structure:

1. Structural similarity: The similarity of two expressions
is deﬁned as a function of their structures and the sym-
bols they share. The similarity is used as an indication
of how relevant a document containing an expression
is when given another expression as a query. We pro-
pose an algorithm based on tree edit distance to calcu-
late the similarity of two expressions. Documents are
ranked with respect to the similarity of their contained
mathematical expressions to the query.

2. Pattern match: As an alternative approach, a query
can be represented as a pattern or template. The
added expressivity of such a query language provides
the user with tools to specify more details, which al-
lows more accurate and complete results in return. On
the other hand, the richness and variety of mathemat-
ical concepts implies that the query language is poten-
tially diﬃcult to learn and use.

If the two mentioned approaches perform equally well,
the simpler query language is probably preferred; the ex-
tra cost of forming a query with the expressive query lan-
guage is justiﬁed only when this expressive power results in
higher-quality answers. We discuss the advantages and dis-
advantages of each approach, and we report on an extensive
empirical study to evaluate them in terms of their ability
to predict the relevance of pages containing mathematical
expressions. We also describe other alternative algorithms
(e.g. keyword search only, etc.) and compare them against
the proposed algorithms.

The contributions of this paper are as follows:
• We categorize existing approaches to match mathe-
matical expressions, concentrating on two paradigms
that consider the structure of expressions.

• We propose a representative system for each search

paradigm.

<apply>

<times/>
<cn>

2

</cn>
<apply>

<plus/>
<ci>

x

</ci>
<apply>

<times/>
<cn>

3

</cn>
<ci>

y

</ci>

</apply>

</apply>

</apply>

<mrow>

<mn>

2

</mn>
<mfenced>
<mi>

</mi>
<mo>

</mo>
<mn>

</mn>
<mi>

x

+

3

y

</mi>
</mfenced>

</mrow>

Figure 1: Content MathML (left) vs. Presentation
MathML (right) for 2(x + 3y)

• We evaluate and compare the described approaches

through detailed user studies in real scenarios.

This is the ﬁrst attempt to describe and evaluate possible
solutions in a principled way. Understanding the eﬀective-
ness of approaches to matching mathematical expressions
is necessary for evaluating the further development of any
mathematics retrieval algorithm. Hence, we believe the re-
sult of this study is an important step towards building a
useful mathematics retrieval system.

In this paper we focus on the quality of results when
matching mathematical expressions. Indexing and other op-
timization techniques to reduce query processing time or in-
dex size is out of the scope of this paper (Elsewhere, we
extensively discuss such optimization techniques [14].). In
this paper, we also do not address the problem of evaluating
mathematical expressions, which is the goal of systems such
as Wolfram Alpha [1], or Bing Math [11].

The rest of this paper is organized as follows. After for-
mulating the mathematics retrieval problem more precisely
in the next section, we describe related work in more detail
in Section 3. In Section 4 we describe an approach based on
matching structurally similar expressions, and in Section 5
we describe an approach based on matching expressions to
templates. We present the results of our experiments and
the comparison of alternative search approaches in Section 6.
We ﬁnally conclude the paper with an indication of future
work.

2. THE FRAMEWORK

In this section we present deﬁnitions for some general con-
cepts. We also describe the search problem and any assump-
tions we make about the query and the results.
2.1 Deﬁnitions

Math Expression: A mathematical expression is a ﬁ-
nite combination of symbols that is formed according to
some context-dependent rules. Symbols can designate num-
bers (constants), variables, operations, functions, and other
mathematical entities.

There are various ways to encode and represent a math-
ematical expression. Such approaches can be divided into
two main groups:

1. Content-based: Semantics of symbols and their inter-
actions are encoded. Content MathML [6] and Open-

354Figure 2: Two trees representing sin(i) (left) and
sin j (right) in Presentation MathML.

Math [5] are XML-based markup languages that be-
long to this group.

2. Presentation-based: Expressions are encoded with re-
spect to their appearance. Examples include images of
expressions, Presentation MathML [6], and LATEX.

Example 1. Consider 2(x + 3y) as a simple expression.
The Content MathML encoding for this expression is shown
in Figure 1 (left), and the Presentation MathML is shown in
Figure 1 (right). Presentation MathML contains some sur-
face semantic information. For example, <mn> and <mi>
indicate that 2 and 3 are numbers and x and y are variables,
respectively. However, the multiplication operator is repre-
sented by the <times> tag in content markup, but it is in-
visible and hence not shown in presentation markup. On the
other hand, parentheses are not encoded in content markup
because they do not carry semantic information. The plus
operator is represented by the <plus> tag in content markup,
and its operands (x and 3y) are also clearly speciﬁed. Using
presentation markup, the “+” symbol is shown where it ap-
pears in the expression, and even though it is marked as an
an operator, its operands are not explicitly indicated.

Presentation MathML is part of the W3C recommenda-
tion that is increasingly used to publish mathematics infor-
mation on the web, and many web browsers support it [18].
There are various tools to translate mathematical expres-
sions from other languages, including LATEX, into Presenta-
tion MathML. Moreover, Presentation MathML expressions
can be processed by parsers and other applications for XML
documents. Hence, in this paper we assume mathematical
expressions are encoded with Presentation MathML unless
otherwise is speciﬁed.

DOM Tree: Documents with XML markup can be nat-
urally expressed as ordered labelled trees, also called Docu-
ment Object Model (DOM) trees. A DOM tree T is repre-
sented by T = (V, E), where V represents the set of vertices
and E represents the set of edges of T . A label λ(n) is as-
signed to each node n, and Σ is the set of all possible labels.
Two examples are shown in Figure 2.

A text document, such as a web page, that contains a
mathematical expression is a document with mathematical
content. The search goal is to retrieve such documents by
querying their mathematical content.
2.2 Problem Formulation

Here we present a general deﬁnition for the search problem
and the query language. Details of the query language and
the way a match is deﬁned are speciﬁc to a mathematics
retrieval system. We describe several possible approaches in
the following sections.

Query: The aim of a query is to describe a mathematical
expression. Hence, a query is either a mathematics
expression, or it speciﬁes a pattern that describes one
or more expressions.

Search problem: Given a query, the search problem is to
ﬁnd a list of relevant documents with mathematical
content. A document is relevant if it contains an ex-
pression that matches the query.

The query and all mathematical expressions are encoded
with Presentation MathML. Because forming queries directly
with Presentation MathML is diﬃcult, input devices such
as pen-based interfaces and tablets [17, 25] or more widely-
known languages such as LATEX could be used instead to
enter a query. Automatic tools can then be applied to trans-
late queries to Presentation MathML. Hence, regardless of
the user interface, we assume the query is eventually rep-
resented in the form of Presentation MathML. Thus, this
approach is appropriate for the majority of the available
mathematics information on the web.
2.3 Discussion

In the case of text retrieval, syntactic variants of query
terms can be matched through stemmers and semantic vari-
ants can be matched through ontologies. These and similar
tools can improve the results of search systems. Similarly,
for mathematics retrieval using mathematical equivalence
rules and transforming expressions to canonical forms ac-
cordingly (e.g. “ab + ac” and “a(b + c)”) can improve search
results. Nevertheless, such approaches are orthogonal to our
algorithms and out of the scope of this paper.

Extending the query language to cover more complex cases
can increase the usefulness of a search system. For exam-
ple, allowing a query to consist of multiple mathematical
expressions or a combination of mathematical expressions
and text keywords can increase its expressive power.
In-
cluding a (symbolic) mathematics engine to calculate the
answer to a mathematical query can also be used to address
some users’ needs. However, in this paper our primary goal
is to study the usefulness of the basic search paradigms and
to compare them. While such extensions are potentially use-
ful, the eﬀectiveness of the basic search primitives should be
proved ﬁrst. Hence, in this paper we only focus on the basic
search paradigms. An extended query language can then be
studied by leveraging our ﬁndings.

3. RELATED WORK

In this section, we describe existing algorithms for mathe-
matics retrieval systems in a framework that classiﬁes them
based on how they attempt to match expressions.
3.1 Exact Match

Some algorithms assume expressions are available only in
images, and they try to match a given query by calculat-
ing the similarity of images [30, 31]. In the best case, the
performance of such algorithms is similar to ExactMatch al-
gorithms, which allow for very limited variation among the
expressions returned. We describe and evaluate ExactMatch
algorithms further in Section 6.

TexSN [27] is a textual language that can be used to nor-
malize mathematical expressions into canonical forms. Af-
ter that a search is performed to ﬁnd mathematical expres-
sions that exactly match a (normalized) query. MathQL [9]

sini<mi>X<math><mfenced><mo>Z<mrow>j<mrow><mo>sin<mi>Y  <math>355and MML Query [3] propose very detailed and formal query
languages through which mathematical expressions are pre-
sented as sets of symbols. To perform a search, sets of ex-
pressions containing speciﬁc symbols are selected and then
intersected using relational database operations. Einwohner
and Fateman [7] propose a data structure and an algorithm
for searching integral tables. In this approach, pre-calculated
integrals are stored in a table. A requested integral matches
an entry in the table if its integrand agrees with that of the
x2+1 matches
table entry up to a choice of parameters, e.g.
x2+a . We characterize all of these approaches as Normal-
izedExactMatch algorithms, which we describe and evaluate
further in Section 6.

1

1

As shown in Section 6, ExactMatch and NormalizedEx-
actMatch perform poorly in retrieving web pages with math-
ematical content.
3.2 Approximate match

3.2.1 Substructure match
Sojka and Liska [26] propose another algorithm that ﬁrst
tokenizes expressions, where a token is a subtree of the ex-
pression. Each token is next normalized with respect to var-
ious rules (e.g. variables names are removed, number values
are removed, or both), and multiple normalized copies are
preserved. The resulting collection of tokens is then indexed
with a text search engine. A query is similarly normalized
(but not tokenized) and then matched against the index.
Similarly, Egomath [19] tranforms math expressions into to-
kens (that represent subexpressions), and uses a text search
system to index and query them. Regardless of the tok-
enization details, some structure information is missed by
transforming an expression into bags of tokens, which af-
fects the accuracy of results as shown later in this paper.
MathWebSearch [15] is a semantic-based search engine for
mathematical expressions. The query language is an exten-
sion to OpenMath, with some added tags and attributes, e.g.
mq:not, mq:and, mq:or. Mathematical expressions are inter-
preted as preﬁx terms and are stored in a tree data struc-
ture called a substitution tree, where common preﬁxes are
shared. A search is performed by traversing the tree. Math-
WebSearch can only process and index expressions encoded
with Content MathML and OpenMath; presentation-based
encoding is not well suited for use by this system. Schel-
lenberg et al. [24] propose extending substitution trees to
expressions with LATEX encoding. Such approaches support
exact matching of expressions well, but they support partial
matching only when expressions share a common part at the
top of the tree. Kamali and Tompa [12] propose to allow
the common parts of two expressions to appear anywhere
in the trees. We characterize such algorithms as SubexprEx-
actMatch algorithms, and we show in Section 6 that their
performance remains relatively poor.

Structure Similarity

3.2.2
Pillay and Zanibbi [23] propose an algorithm based on
tree edit distance for combining the results of diﬀerent math
recognition algorithms. The goal of this approach is to
enhance such algorithms to recognize hand-written expres-
sions. Algorithms for retrieving general XML documents
based on tree-edit distance have been proposed [16], and
these could be adapted to match XML-encoded mathemat-
ical expressions. However, these approaches have not been

thoroughly investigated for retrieving mathematical expres-
sions. We propose an algorithm in this SimSearch class in
Section 4 and show in Section 6 that it has a much better
performance than other approaches such as exact match.

An alternative for matching based on structural similarity
is to express a query in the form of a template, much as QBE
does for querying relational data [33]. We describe how
templates may be used to specify precisely where variability
is permitted. We review our previous work on PatternMatch
algorithm [13] in more detail in Section 5 and evaluate its
performance in Section 6.

3.2.3 Keyword Similarity
The maturity of keyword search algorithms has motivated
some researchers to use them for mathematics retrieval [28,
31]. Such approaches typically represent a mathematics ex-
pression as a bag of words, where each word represents a
mathematics symbol or function. Youssef [28] proposes an
algorithm based on the vector space model to rank mathe-
matical expressions in response to a given query. To try to
accommodate the speciﬁc nature of mathematics, alterna-
tive weighting schemes are considered instead of term fre-
quency and inverse document frequency. Nguyen et al. [21]
propose another algorithm that considers a semantic encod-
ing (Content MathML) of expressions. Each expression is
represented by several textual tags, after which standard
keyword search algorithms are used to search mathemati-
cal expressions. This allows supporting queries that contain
both keywords and mathematical expressions and using ex-
isting IR optimizations. As shown in Section 6, ignoring the
structure signiﬁcantly aﬀects the performance.

3.3 Evaluating Math Retrieval Systems

Very few studies consider the problem of evaluating math
retrieval systems in terms of satisfying user needs. This is
partly due to the lack of a consensus on the deﬁnition of the
relevance of math expressions, and partly due to the lack
of a clear understanding of users’ needs. Zhao et al. [32]
report on the interviews of a small group of potential users
to ascertain their needs. They conclude that users prefer
to use keywords that describe an expression to search for it
rather than specifying the expression (e.g. “binomial coef-

ﬁcient” instead of (cid:0)n
expressions more details can be speciﬁed (e.g. (cid:0)n2

(cid:1)). As we mentioned earlier, in many
(cid:1)). Finally,

cases an expression is not described with keywords or the
user is not aware of such keywords. Moreover, with math

k

n

user-friendly interfaces for entering math expressions, such
as pen-based devices, were not widely available at the time
of the interview. Some search algorithms that compare im-
ages of expressions evaluate their systems in terms of success
rate [31, 29]. In such cases, the success rate mostly captures
the correctness of recognizing math expressions rather than
their relevance. In other words, if an expression or subex-
pression is returned as the search result, and they exactly
match, it is counted as a successful search.

To date, mathematics retrieval systems that perform ap-
proximate matching and then rank expressions based on
their similarity to a query have not been analyzed in terms
of their eﬀectiveness: there are no experimental results com-
paring their ability to ﬁnd relevant matches. However, the
lack of their popularity may be a sign that in many situa-
tions they do not perform well.

356Figure 3: The ﬂow of data in a mathematics retrieval
system based on similarity ranking.

4. SIMILARITY SEARCH

The similarity function for mathematics considers only the
mathematical content of a document, where each potentially
relevant document contains at least one mathematics expres-
sion that matches the query. After the user inputs a query
through a user interface, it is translated into Presentation
MathML to be processed by the ranking algorithm. The
result consists of a list of ranked documents sorted with re-
spect to the similarity of their mathematical content to the
query. Figure 3 shows the ﬂow of data in this approach.

A general sketch for similarity search is presented in Algo-
rithm 1. The deﬁnition of similarity between two mathemat-
ical expressions (Line 6) is a key concept that signiﬁcantly
aﬀects such systems.

Just like other information retrieval systems, semantic
similarity ranking is generally very useful, as it can better
capture the intention of a user. Thus, the limited seman-
tic information that is available (i.e., whether a symbol is
a number, a variable, or an operator) should also be con-
sidered to calculate similarity in order to broaden the set of
potentially matching expressions.

Unfortunately, a ranking function based on more expres-
sive semantic similarity requires that the query and the ex-
pressions be semantically encoded using a markup language
such as OpenMath or Content MathML. Hence, it requires
more eﬀort from the user to form a query semantically and
also requires that content markup be used to publish math-
ematical expressions. As stated earlier, this is generally un-
available for retrieval from the web.

Algorithm 1 Similarity Search
1: Input: Query q and collection D of documents.
2: Output: A list of documents ranked with respect to

their similarity to q.

3: Deﬁne list L that is initially empty
4: for each document d ∈ D do
5:
6:

for each math expression E in d do

Calculate the similarity of E and q and store the
result
end for
Calculate the similarity of d and q and store the result
in L

7:
8:

9: end for
10: Sort documents in L with respect to the calculated sim-

ilarities in descending order

11: return L

appropriate similarity functions to be used in Lines 6 and 8
of Algorithm 1.
Consider two ordered labelled trees T1 = (V1, E1) and
T2 = (V2, E2) and two nodes N1 ∈ V1 ∪ Pφ and N2 ∈
V2 ∪ Pφ where Pφ is a special node with label . An edit
operation is a function represented by (N1 → N2) where
(λ(N1), λ(N2)) ∈ (Σ ∪ ) × (Σ ∪ ) − {(, )}. The operation
is a relabelling if λ(N1), λ(N2) (cid:54)= . It is a deletion if N1 is
not the root of T1 and λ(N2) = , where deleting N1 makes
the children of N1 become the children of the parent of N1
in place of node N1. Finally, the operation is an insertion if
λ(N1) = , where insertion is the mirror image of deletion.
A transformation τ from T1 to T2 is a sequence of edit op-
erations that transforms T1 to T2. To each edit operation
N1 → N2 we assign a cost ω(N1 → N2). The cost of a
transformation is the sum of the costs of its edit operations.
The edit distance of T1 and T2 is deﬁned as follows:

dist(T1, T2) = min{cost(τ )|τ (T1) = T2}

(1)
We customize the cost of an edit operation N1 → N2 for

mathematical expressions as follows:

1. If λ(N1) = λ(N2) then ω(N1 → N2) = 0.
2. If N1, N2 are leaf nodes and λ(N1) (cid:54)= λ(N2) and
λ(parent(N1)) = λ(parent(N2)) then ω(N1 → N2) =
CP L(λ(parent(N1)), λ(N1), λ(N2)).

3. If N1, N2 are leaf nodes and λ(N1) (cid:54)= λ(N2) and
λ(parent(N1)) (cid:54)= λ(parent(N2)) then ω(N1 → N2) =
CL(λ(N1), λ(N2)).

4. If N1, N2 are not both leaf nodes and λ(N1) (cid:54)= λ(N2)

then cost(N1 → N2) = CI (λ(N1), λ(N2)).

In the above deﬁnition, CI and CL, and CP L are static
functions that assign values to an edit operation. Their val-
ues for various inputs are shown in Table 1. In this table,
“<mi>”, “<mn>”, and “<mo>” represent variables, num-
bers, and operators respectively; α, β, and γ are constants
whose values are set based on the following observations
about math expressions (Some math retrieval systems nor-
malize math expressions based on similar observations [19].).
Typically, renaming variables aﬀects the semantics less than
changing math operators. Similarly, renaming a variable
should be less costly than changing a variable to a number,
and renaming non-leaf nodes should be more costly that re-
naming leaf nodes. Therefore, we set α ≤ β ≤ γ.

Example 2. Consider nodes X and Y in Figure 2. X →
Y is a relabelling. The label of their parents, <mi>, states
that they are variables. According to Table 1, CP L(“ <mi>
”, “i”, “j”) = α. Hence, ω(X → Y ) = α. Also, Z → Pφ is a
deletion and ω(Z → Pφ) = γ. The edit distance between the
two trees is equal to α + γ.

Consider two mathematical expressions E1 and E2 repre-
sented by trees T1 and T2. The similarity of the two expres-
sions is calculated as follows:

sim(E1, E2) = 1 − dist(T1, T2)
|T1| + |T2|
where |T| is the number of nodes in tree T .

(2)

We now propose a similarity function that is based on tree
edit distance [4], and deﬁne the similarity of a document to
a math query accordingly. More speciﬁcally, we propose

There are many algorithms for calculating the edit dis-
tance between two trees. We use RTED [22] to calculate the
tree edit distance.

357Value of C
Condition
x (cid:54)= y
CP L(“ < mi > ”, x, y) = α
CP L(“ < mn > ”, x, y) = α x (cid:54)= y
x (cid:54)= y and {x, y} ∈ {+, −}
CP L(“ < mo > ”, x, y) = α
CL(, x) = β
CL(x, ) = β
CL(x, y) = 2β
CI (, x) = γ
CI (x, ) = γ
CI (x, y) = 2γ

x (cid:54)= y

x (cid:54)= y

Table 1: Examples of various cost values assigned to
edit operations

Assume document d contains mathematical expressions
E1 . . . En. The rank of d for a query Q is calculated with
the following formula:

docRank(d, Q) = max{sim(Ei, Q)|Ei ∈ d}

(3)

that is, a document’s score is equal to the similarity of the
most similar expression in that document.

5. PATTERN SEARCH

An alternative to similarity ranking is to specify a tem-
plate as the query and return expressions that match it as
the search result [13]. This allows ﬂexible matching of ex-
pressions but in a controlled way (as distinct from the simi-
larity ranking where the user has less control on approximate
matching of expressions). For example, the user can specify
that she is looking for [E]n where n is a number and [E]
is an expression that contains sin(x). This capability is not
supported by any exact matching algorithm, and the simi-
larity search may not rank relevant expressions high enough.
The approach is analogous to querying a collection of strings
by specifying a partial context-free grammar, and returning
strings that can be parsed by the grammar. Similarly, a
template can be deﬁned using wildcards as non-terminals,
and regular expressions to describe their relationships. For

example, (cid:112)[V ], where [V ] is a wildcard that matches any

variable, can be used to search for expressions that consist
of the square root of a variable.

According to this paradigm, the user has more power to
direct the search; hence the results are expected to be more
relevant. However, the variety of wildcards and operations
that are available to specify a template may result in a com-
plex query language, which requires more eﬀort from the
user.

To ﬁnd a relevant document, the user starts with a pattern
to be searched. It may be necessary to tune the query, as the
initial pattern may not correctly model the expression the
user is looking for or it may be too general or too speciﬁc.
After the results are shown, she tunes the pattern until she
ﬁnds a relevant answer. A diagram of the data ﬂow for this
search paradigm is shown in Figure 4. Algorithm 2 presents
a general sketch for this search paradigm.

In some cases, combining similarity ranking and struc-
tured search is useful. For example, assume a user is looking
for expressions that contain the square root of an expression

E such that E is similar to sin(x). In this case,(cid:112)sin(x) is
a better match than(cid:112)sin( x
complies with the pattern,(cid:112)sin(x) + 1 is not match. This

2 + 1), and while the latter still

Figure 4: The ﬂow of data in a mathematics retrieval
system based on pattern matching.

keyword search features on structured data [10]. Adding
this capability to a search system can increase its ﬂexibility
to capture relevant results.

In conclusion, this search paradigm is suitable for spe-
cialized search where the user can be expected to put more
eﬀort to form a query and get better results in return.

Algorithm 2 Structured Search
1: Input: Query q and collection D of documents.
2: Output: A ranked list of documents that match the

query.

if E matches q then

for each math expression E in d do

3: Deﬁne list L that is initially empty
4: for each document d ∈ D do
5:
6:
7:
8:
9:
10: end for
11: Sort documents in L with respect to ranking criteria
12: return L

put d in L

end if
end for

5.1 A Model Query Language

A query is expressed as a pattern consisting of a mathe-
matical expression augmented with wild cards, optional parts,
and constraints in the form of where clauses. A query matches
an expression (Algorithm 2-Line 6) as follows. A wild card
represents a slot that will match any subtree of the appro-
priate type, where [Vi] matches any variable, [Ni] matches
any number, [Oi] matches any operator, and [Ei] matches
any expression. A wild card’s index i is an optional natural
number such that if two or more wild cards share the same
type and index, they must match identical subtrees. Wild
cards with no index are unconstrained.

Example 3. The query x[N1]− y[N1] matches x2− y2 and
x5 − y5 but not x2 − y3, whereas either of the queries x[N1] −
y[N2] or x[N ] − y[N ] matches all three.

Optional parts are enclosed by braces and they may ap-

pear in some matching expressions.

Example 4. x2{+[N ]} matches x2 and x2 + 1 but not

x2 + y or x2 − 1.

search paradigm has been adopted in other contexts. Exam-
ples include XQuery with full-text capability [2] and other

Constraints can be speciﬁed for wild cards in a query using
a “where” clause, as follows:

358• Number wild cards can be constrained to a speciﬁc
range or to a domain, which can be speciﬁed using a
context-free grammar.

• Variable wild cards can be constrained to a restricted

set of possible names.

• Operator wild cards can be constrained to a restricted

set of operators.

• Expression wild cards can be constrained to contain a
given subexpression, which can in turn include further
wild cards and constraints.

Example 5.
• Query “[E]2[O1]3 where O ∈ {+,−}” matches x2 + 3

and (x + 1)2 − 3 but not x2 × 3.

• Query “x[N 1] where 1 ≤ N 1 ≤ 5” matches x2 but not

x9 or x−1.

• Query “[E1]−2 where [E1] contains x2” matches x2−

2 and log(x2 + 3y) − 2 but not x − 2 or y2 − 2.

• Query “[E1] where E1 contains log2([V ])” matches all
expressions that include a base 2 logarithm of a vari-
able.

In our experiments we assume a pattern does not contain
a similarity constraint. Otherwise, pattern search would be
a generalized form of the similarity search approach, which
makes it hard to compare them. Moreover, ranking docu-
ments with respect to a pattern query that contains multiple
similarity constraints is a complex problem that should be
addressed after the more basic problem of capturing the sim-
ilarity of two math expressions (discussed in this paper) is
addressed. This problem is a direction of our future work.
5.2 Query Processing

A query is processed by trying to match it against the
stored expressions by parsing them with respect to the query.
Each document that contains a match is included in the
search result.

While similarity ranking is in fact an information retrieval
approach to the problem, pattern search resembles a database
look-up. Therefore, the result of this search paradigm is a
list of documents with expressions that match the query. To
rank documents in the list (Algorithm 2-Line 11), a ranking
criterion should be considered.
In our implementation we
sort results with respect to the sizes of the matched expres-
sions in increasing order.

6. EXPERIMENTS

In this section we present the results of our empirical eval-

uation of the described approaches.
6.1 Alternative Algorithms

In our experiments we consider the following speciﬁc al-

gorithms:

• TextSearch: The query and expressions are treated as
bags of words (nodes’ labels in their DOM trees). A
standard text search algorithm is used for ranking doc-
uments according to a given query1.

• ExactMatch: An expression is reported as a search re-
sult only if it matches a given query exactly. Results
are ranked with respect to the alphabetic order of the
name of their corresponding documents.

• NormalizedExactMatch: Some normalization is per-
formed on the query and on the stored expressions: in
particular, we ignore speciﬁc numbers, variables, and
operators by removing all leaf nodes. The normalized
expressions are searched and ranked according to the
ExactMatch algorithm.

• SubexprExactMatch: An expression is returned as a
search result if at least one of its subexpressions exactly
matches the query. Results are ranked by increasing
sizes of their DOM trees.

• NormalizedSubExactMatch: Normalization is done on
the query and on the stored expressions as for Nor-
malizedExactMatch, and an expression is returned as
a search result if one of its normalized subexpressions
matches the normalized query.

• MIaS: As described in Section 3, subtrees are normal-
ized and transformed into tokens and a text search
engine is used to index and retrieve them [26].

• SimSearch: Expressions are matched against a query

according to the algorithm described in Section 4.

• PatternSearch: Expressions are matched against a pat-
tern according to the algorithm described in Section 5.
Like SubexprExactMatch, results are ranked with re-
spect to the sizes of their DOM trees.

Note that among the above algorithms, the results of Ex-
actMatch are subsets of the results of TextSearch, Normal-
izedExactMatch, and SubexprExactMatch.
6.2 Experiment Setup
6.2.1 Data Collection
For our experiments we use a collection of web pages
with mathematical content. We collected pages from the
Wikipedia and DLMF (Digital Library of Mathematics Func-
tions) websites. Wikipedia pages contain images of expres-
sions annotated with equivalent LATEX encodings of the ex-
pressions. We extracted such annotations and translated
them into Presentation MatchML using Tralics [8]. DLMF
pages use Presentation MathML to represent mathematical
expressions. Statistics summarizing this dataset are pre-
sented in Table 2.
6.2.2 Queries
To evaluate the described algorithms we prepared two sets

of queries as follows.

• Interview: We invited a wide range of students and re-
searchers to participate in our study. They were asked

Number of pages

Number of expressions

Average size of expressions
Maximum size of expressions

28.3
578

Wikipedia DLMF
1,550

44,368
611,210

Total
45,918
863,358

25.2
578

252,148

17.6
223

1We used Apache Lucene in our implementation.

Table 2: Dataset statistics

359to try our system and search for mathematical expres-
sions of potential interest to them in practical situa-
tions. They could also provide us with their feedback
about the quality of results after each search.

• Mathematics forum: People often use mathematics fo-
rums in order to ask a questions or discuss math-
related topics. Many discussion threads can be de-
scribed with a query that consists of a single math
expression. Usually, by reading the rest of the thread
and responses, the exact intention of the user is clear.
This allows us to manually judge if a given expression,
together with the page that contains it, can answer the
information need of the user who started the thread.
We manually read such discussions and gathered a col-
lection of queries.

The precise query formulations for PatternSearch were
created by one of the authors. Thus the experimental re-
sults reﬂect search environments in which queries are formed
reasonably well by an experienced user.

Table 3 summarizes statistics about the queries, where
the number of nodes in the query tree is used to represent
query size. For the sake of reproducibility and as a basis
for further evaluation of various search paradigms, both the
dataset and the complete set of queries can be obtained from
the authors upon request2.
6.2.3 Methodology
For each query we use each algorithm to search the dataset,

and only consider the top 10 results.

The way we collected queries ensures that a user’s infor-
mation needs are clear, which allows us to judge if a match
is actually relevant or not. Searches for which we do not
have a user’s relevance feedback (i.e., Forum queries) re-
quire that we manually judge results. Hence, for Forum
queries we consider discussion threads that clearly describe
an information need with no ambiguity. For example a dis-
cussion thread might start with this question: “prove that
n − Fn−1Fn−2 = (−1)n−1 where Fn is the nth Fibonacci
F 2
number”. A search result page is considered relevant if it sat-
isﬁes the information need that is inferred from the thread.
If a page contains data that can be clearly used to answer
the query, we judge it as relevant. Note that a page may
contain an exact match to a query, but it still does not an-
swer the information need, hence we assume it is irrelevant
(e.g. if a page contains the same expression as in the previ-
ous example, but Fn is not a Fibonacci number, or it does
not contain any information that helps to prove it.).

As mentioned earlier, for PatternSearch the query may be
reﬁned repeatedly unless appropriate results are returned or
the query is reﬁned a certain number of times and the user
gives up (Figures 4). Hence, unless otherwise speciﬁed, the
results for PatternSearch are presented with respect to the
ﬁnal reﬁned query. For other algorithms however, reﬁning a
query is often not necessary or eﬀective, and the results are
shown for the original query.
6.2.4 Evaluation measures
NFR: A search fails if fewer than 10 results are returned
(including nothing returned), and none of them is relevant.
2The
matching
http://db.uwaterloo.ca/mathretrieval/queries.xhtml.

collections
are

examples
available

with

publicly

documents

query

of
at

Number of queries

Average size of queries

45
14.2

53
23.8

98
19.4

Interview Math Forum Total

Table 3: Query statistics

Non-Failure-Rate (NFR) is the number of searches that do
not fail divided by the total number of searches:

NFR =

|{q ∈ Q|searching q does not fail}|

|Q|

(4)

MRR: The rank of the ﬁrst correct answer is a representa-
tive metric for the success of a mathematics search. Hence,
for each search we consider the Reciprocal Rank (RR), that
is, the inverse of the rank of the ﬁrst relevant answer. For
example if the ﬁrst correct answer is ranked second, the re-
ciprocal rank of the search is 1
2 . The Mean Reciprocal Rank
(MRR) is the average reciprocal rank for all queries:

(cid:88)

MRR =

1
|Q|

1

C(q)

q∈Q

(5)

where Q is the collection of queries, and C(q) is the rank of
the ﬁrst relevant answer for query q.

If no relevant document is among the top 10 results, we
optimistically assume the search did not fail, and the rank
of the ﬁrst relevant document is 11. If a search fails, we do
not include it for calculating MRR.

Rewrite-Rate: It often happens that a search is not suc-
cessful, and a user must rewrite the query to ﬁnd a relevant
result. For each search algorithm, starting from an initial
query, we logged how many times a query was rewritten to
obtain a relevant answer among the top 10 results. We as-
sume that the user gives up after ﬁve tries, and the search
fails or no relevant result is found. The average number of
rewrites for all queries is the rewrite rate of an algorithm.

Other measures such as Mean Average Precision (MAP)
could alternatively be considered. However, for our data
and query collections, MRR seems to be a better choice. In
most cases, there are a few (often one) relevant documents
for the query. Hence, MRR can better reﬂect the accuracy of
algorithms. Recall that some of the baselines (e.g. pattern
search and substructure search) deploy database operators
to perform a search, while some other ones (e.g. structural
similarity and keyword search) use IR techniques. Hence,
because such approaches are inherently diﬀerent, it is impor-
tant to consider measures that fairly compare them. MRR
and NFR together provide an indicative measure of the ac-
curacy of such algorithms.
6.3 Evaluation Results

6.3.1 Correctness
The NFR and MRR for each algorithm are presented in
Tables 4 and 5 for the Forum and Interview queries, respec-
tively. As the results suggest, PatternSearch and SimSearch
have high NFR and also high MRRs. PatternSearch has a
higher MRR because irrelevant expressions are less likely to
match a carefully formed pattern. On the other hand, Sim-
Search has a slightly higher NFR because in some cases even
an experienced user may not be able to guess the pattern
that will yield a correct answer. Furthermore, the next sec-
tion shows that a template pattern may need to be modiﬁed
several times to capture a relevant result.

360Algorithm
SimSearch

PatternSearch

MiaS

TextSearch
ExactMatch

NormalizedExactMatch

SubexprExactMatch

NormalizedSubExactMatch

-

NFR MRR p-value
100% 0.74
90%
0.86
94%
0.46
100% 0.19
13%
34%
18%
41%

0.171
0.002
0.000
0.186
0.007
0.173
0.004

0.46
0.94
0.43

1

Algorithm
SimSearch

PatternSearch

MiaS

TextSearch
ExactMatch

NormalizedExactMatch

SubexprExactMatch

NormalizedSubExactMatch

-

NFR MRR p-value
100% 0.78
76%
0.96
90%
0.63
100% 0.23
15%
50%
30%
60%

0.084
0.014
0.000
0.211
0.005
0.044
0.009

0.58
0.62
0.44

1

Table 4: Algorithms’ performance for Forum Queries.

Table 5:
Queries.

Algorithms’ performance for

Because MRR is only calculated when the search does
not fail, ExactMatch has a high (in fact, perfect) MRR.
However, in most cases, there is no expression that exactly
matches the query, and hence no result is produced and this
algorithm fails. SubexprExactMatch has a slightly better
NFR, but it is still too low to satisfy many users’ needs.
This implies that often there are no relevant expressions or
subexpressions that exactly match the query. However, in
instances where a matching expression or subexpression ex-
ists, it is ranked highly by ExactMatch and SubexprExact-
Match. Normalizing expressions, as done in NormalizedEx-
actMatch and NormalizedSubExactMatch, further increases
the NFR, but it also increases the chances that irrelevant
expressions are matched. Because such algorithms do not
oﬀer an eﬀective ranking algorithm, in many cases the most
relevant results are not among the top 10 results.

Note that although the MRR of SimSearch is lower than
ExactMatch and SubexprExactMatch, it has a much higher
NFR as it produces some results for all queries. If we only
consider queries for which there is an exact match (so Ex-
actMatch produces at least one answer), SimSearch has an
MRR that is not signiﬁcantly diﬀerent from that of Exact-
Match. The reason is that in such cases, the structural sim-
ilarity for documents that contain exact matches is 1, and
such documents are ranked at the top of the results.

TextSearch has a very low MRR. Because this algorithm
ignores the structure, it often does not rank a correct answer
highly enough against many irrelevant expressions with sim-
ilar MathML tags and symbols but diﬀerent structures.

Note that, although we reformulate queries only for pat-
tern search, the structural similarity search produces results
that are comparable with the results of well-formulated pat-
tern queries. ExactMatch or NormalizedExactMatch are
essentially pattern search with poorly formed queries. As
shown, such algorithms produce poor results.

To show the statistical signiﬁcance of the results, we use
a Student’s t-test on the reciprocal ranks of the queries. For
each algorithm, we test whether there is a statistical dif-
ference between the reciprocal ranks of its produced results
and that of SimSearch. We consider a one-tailed t-test for
paired samples (i.e. only non-failed searches are considered).
As the data in Tables 4 and 5 suggest, there are signiﬁcant
diﬀerences (at the 0.05 signiﬁcance level) between the re-
sults of SimSearch and all algorithms except PatternSearch,
ExactMatch, and SubexprExactMatch (for Forum queries).
The reason is that in cases that such algorithms do not fail,
SimSearch ranks relevant results equally well.
6.3.2 Query Rewriting
To compare how much eﬀort is required from the user to
perform a search, we look at PatternSearch in terms of its

rewrite rates. Assume a user is looking for

2i, and sup-

10(cid:80)

i=1

Interview

ai. The edit

n(cid:80)

i=1

pose the only relevant match to this query is

distance between the corresponding DOM trees is relatively
low, and thus this answer is ranked highly by the SimSearch
algorithm. For PatternSearch, however, if the user forms
a query with no wild cards, it performs similarly to Exact-
Match, and the correct answer is not found. The following is
a plausible sequence of query reﬁnements before an answer
is found:

2[V 1] → [N 1](cid:80)

[N 2][V 1] → [N 1](cid:80)

10(cid:80)

2i → 10(cid:80)

[V 2][V 1]

i=1

[V 1]=1

[V 1]=1

[V 1]=1

While the rewrite rate of SimSearch is always 1 (as no
query rewriting is required), PatternSearch has an average
rewrite rate of 2.2 and 1.45 for the Forum and Interview
queries respectively. As the results suggest, when using Pat-
ternSearch, each query may well be reﬁned to obtain relevant
results, and hence the user must invest more eﬀort to ﬁnd
relevant documents.

Summary

6.3.3
In summary, simply viewing mathematics expressions as if
they were conventional document fragments, as represented
by TextSearch, or not allowing variations in matched ex-
pressions or subexpressions, as represented by ExactMatch
and SubexprExactMatch, leads to extremely poor search re-
sults. On the other hand, SimSearch and PatternSearch per-
form very well: much better than the other algorithms that
ignore the structure or perform exact matching only. Pat-
ternSearch may perform slightly better than SimSearch, but
the user will likely need to spend more time to tune a query
pattern when using this algorithm. Reassuringly, these re-
sults are consistent across the two sources of queries.

7. CONCLUSIONS AND FUTURE WORK
Given a mathematics expression, ﬁnding pages with rele-
vant mathematical content is an important problem that is
the basis of many mathematics retrieval systems. Correctly
predicting the relevance of mathematical expressions is a
core problem that should be addressed in order to develop
useful retrieval systems.

We characterized several possible approaches to this prob-
lem, and we elaborated two working systems that exploit
the structure of mathematical expressions for approximate
match: structural similarity search and pattern matching.
We empirically showed that these two search paradigms out-
perform other search techniques, including the ones that per-
form exact matching of (normalized) expressions or subex-
pressions and the one that performs keyword search. We
also showed that it takes more eﬀort from the user to form
queries when doing pattern search as compared to similar-
ity search, but when relevant matches are found they are

361ranked somewhat higher. So in conclusion, structural sim-
ilarity search seems to be the best way for general users
to search for mathematical expressions, but we hypothesize
that pattern search may be the preferred approach for ex-
perienced users in speciﬁc domains.

In this paper we focussed on the usability of answers and
how well a search system can ﬁnd relevant documents for a
given query. Others may wish to re-evaluate these results
using more controlled methods for assessing relevance. The
study should next be extended in an ongoing eﬀort to in-
clude new approaches as they are developed. Optimizing
the proposed search techniques in terms of query process-
ing time and index size is a separate direction [14]. Based
on the results of this paper, more complex query languages
can also be developed to accommodate queries that con-
sist of multiple mathematical expressions supplemented by
textual keywords that might match other parts of relevant
documents, or pattern queries with one or more similarity
constraints.

NTCIR is an international initiative to create a public
and shared infrastructure to facilitate research in Math IR.
It aims to provide a test collection and a set of math tasks.
As a part of our future research, we plan to use this data
(which is not yet available) to further evaluate the discussed
algorithms.

8. ACKNOWLEDGEMENTS

We acknowledge ﬁnancial support from NSERC, Mprime,
and the University of Waterloo, and we thank the referees
for their suggestions.

9. REFERENCES
[1] www.wolframalpha.com.
[2] S. Amer-Yahia, C. Botev, and J. Shanmugasundaram.
TeXQuery: a full-text search extension to XQuery. In
WWW, pages 583–594, 2004.

[3] G. Bancerek. Information retrieval and rendering with

MML Query. In MKM, pages 266–279, 2006.

[4] P. Bille. A survey on tree edit distance and related
problems. Theor. Comput. Sci., 337(1-3):217–239,
2005.

[5] S. Buswell, O. Caprotti, D. P. Carlisle, M. C. Dewar,

M. Ga¨etano, and M. Kohlhase, editors. The OpenMath
Standard, Version 2.0. The OpenMath Esprit
Consortium, 2004.

[6] D. Carlisle, P. Ion, and R. Miner. Mathematical
Markup Language (MathML) Version 3.0. W3C
Recommendation, 2010.

[7] T. H. Einwohner and R. J. Fateman. Searching
techniques for integral tables. In ISSAC, pages
133–139, 1995.

[8] J. Grimm. Tralics, A LATEX to XML Translator.

INRIA, 2008.

[9] F. Guidi and I. Schena. A query language for a

metadata framework about mathematical resources. In
MKM, pages 105–118, 2003.

[10] V. Hristidis, L. Gravano, and Y. Papakonstantinou.

Eﬃcient IR-style keyword search over relational
databases. In VLDB, pages 850–861, 2003.

[11] S. Kamali, J. Apacible, and Y. Hosseinkashi.

Answering math queries with search engines. In
WWW, pages 43–52, 2012.

[12] S. Kamali and F. W. Tompa. Improving mathematics

retrieval. In DML, pages 37–48, 2009.

[13] S. Kamali and F. W. Tompa. A new mathematics
retrieval system. In CIKM, pages 1413–1416, 2010.
[14] S. Kamali and F. W. Tompa. Structural similarity

search for mathematics retrieval. In CICM, 2013.
[15] M. Kohlhase and I. A. Sucan. A search engine for
mathematical formulae. In AISC, pages 241–253.
Springer, 2006.

[16] C. Laitang, M. Boughanem, and K. Pinel-Sauvagnat.
XML information retrieval through tree edit distance
and structural summaries. In AIRS, pages 73–83, 2011.

[17] S. Maclean and G. Labahn. A new approach for

recognizing handwritten mathematics using relational
grammars and fuzzy sets. IJDAR, pages 1–25, 2012.
[18] B. Miller. 3 years of DLMF: Web, math & search. In

CICM, 2013.

[19] J. Misutka and L. Galambos. System description:
Egomath2 as a tool for mathematical searching on
wikipedia.org. In Calculemus/MKM, pages 307–309,
2011.

[20] R. Munavalli and R. Miner. Mathﬁnd: a math-aware

search engine. In SIGIR, pages 735–735, 2006.

[21] T. T. Nguyen, K. Chang, and S. C. Hui. A

math-aware search engine for math question answering
system. In CIKM, pages 724–733, 2012.

[22] M. Pawlik and N. Augsten. RTED: A robust algorithm
for the tree edit distance. PVLDB, 5(4):334–345, 2011.

[23] A. Pillay and R. Zanibbi. Intelligent combination of

structural analysis algorithms: Application to
mathematical expression recognition. In PenMath,
2009.

[24] T. Schellenberg, B. Yuan, and R. Zanibbi.

Layout-based substitution tree indexing and retrieval
for mathematical expressions. In DRR, 2012.

[25] E. S. Smirnova and S. M. Watt. Communicating

mathematics via pen-based interfaces. In SYNASC,
pages 9–18, 2008.

[26] P. Sojka and M. L´ıska. The art of mathematics

retrieval. In ACM Symposium on Document
Engineering, pages 57–60, 2011.

[27] A. Youssef. Search of mathematical contents: Issues

and methods. In IASSE, pages 100–105, 2005.
[28] A. Youssef. Methods of relevance ranking and

hit-content generation in math search. In
Calculemus/MKM, pages 393–406, 2007.

[29] R. Zanibbi and D. Blostein. Recognition and retrieval

of mathematical expressions. IJDAR, 15(4):331–357,
2012.

[30] R. Zanibbi and L. Yu. Math spotting: Retrieving

math in technical documents using handwritten query
images. In ICDAR, pages 446–451, 2011.

[31] R. Zanibbi and B. Yuan. Keyword and image-based

retrieval of mathematical expressions. In DRR, pages
1–10, 2011.

[32] J. Zhao, M.-Y. Kan, and Y. L. Theng. Math

information retrieval: user requirements and prototype
implementation. pages 187–196, 2008.

[33] M. M. Zloof. Query-by-Example: the invocation and
deﬁnition of tables and forms. In VLDB, pages 1–24,
1975.

362