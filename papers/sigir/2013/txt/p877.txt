Document Classiﬁcation by Topic Labeling

Swapnil Hingmire*†

swapnil.hingmire@tcs.com

Sandeep Chougule*

sandeep.chougule@tcs.com

Girish K. Palshikar*
gk.palshikar@tcs.com

Sutanu Chakraborti†

sutanuc@cse.iitm.ac.in

*Systems Research Lab

Tata Research Development and Design Center

Tata Consultancy Services

Pune-13, India

†Department of Computer
Science and Engineering

IIT Madras

Chennai-36, India

ABSTRACT
In this paper, we propose Latent Dirichlet Allocation (LDA)
[1] based document classiﬁcation algorithm which does not
require any labeled dataset. In our algorithm, we construct
a topic model using LDA, assign one topic to one of the class
labels, aggregate all the same class label topics into a single
topic using the aggregation property of the Dirichlet distri-
bution and then automatically assign a class label to each
unlabeled document depending on its “closeness” to one of
the aggregated topics.
We present an extension to our algorithm based on the com-
bination of Expectation-Maximization (EM) algorithm and
a naive Bayes classiﬁer. We show eﬀectiveness of our algo-
rithm on three real world datasets.

Categories and Subject Descriptors
I.2.7 [Artiﬁcial Intelligence]: Natural Language Process-
ing—Text analysis

General Terms
Experimentation, Performance, Theory, Veriﬁcation

Keywords
Expectation-Maximization, Text classiﬁcation, Topic Mod-
elling

1.

INTRODUCTION

With the advent of cheap and fast storage, there is an ex-
plosive growth in the size and number of documents available
in electronic format. Document classiﬁcation is a technique
which helps users to make eﬀective use of the knowledge
hidden in the documents.
Traditional supervised document classiﬁers require a large

c(cid:13) 2013 Association for Computing Machinery. ACM acknowledges that
this contribution was authored or co-authored by an employee, contractor
or afﬁliate of the national government of India. As such, the government of
India retains a nonexclusive, royalty-free right to publish or reproduce this
article, or to allow others to do so, for Government purposes only.
SIGIR’13, July 28–August 1, 2013, Dublin, Ireland.
Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

number of labeled dataset. Many times obtaining such a la-
beled dataset is expensive. Nigam et al. [5] proposed semi-
supervised approaches for document classiﬁcation based on
labeled and unlabeled datasets. McCallum and Nigam [4]
proposed a semi-supervised approach based on labeling of
keywords. In keyword based approaches, ﬁnding right set of
keywords is a challenge.
In this paper, we propose Latent Dirichlet Allocation (LDA)
[1] based document classiﬁcation algorithm. Our algorithm
does not require any labeled dataset. In our algorithm, we
construct a topic model using LDA, assign one topic to one
of the class labels, aggregate all the same class label top-
ics into a single topic using the aggregation property of the
Dirichlet distribution and then automatically assign a class
label to each unlabeled document depending on its “close-
ness” to one of the aggregated topics.
In our algorithm an expert assigns one topic to one of the
class labels, also as LDA topics correlate with human as-
signed class labels [6], our algorithm exerts a low cognitive
load on the expert.
Class labels predicted by our algorithm may be approxi-
mate or noisy.
In order to reduce the inﬂuence of such
an approximate or noisily labeled documents, we present
an extension to our algorithm based on the combination of
the Expectation-Maximization (EM) algorithm and a naive
Bayes classiﬁer. We show eﬀectiveness of our algorithm on
three real world datasets.
The paper is organized as follows: In section 2 we give brief
introduction to LDA and the Dirichlet distribution. Section
3 contains our document classiﬁcation algorithm. Section
4 demonstrates eﬀectiveness of our algorithm with experi-
ments on three real world datasets. We end our paper with
conclusions and future prospects of our work in section 5.

2. LATENT DIRICHLET ALLOCATION

(LDA)

LDA is an unsupervised generative probabilistic model for
collections of discrete data such as text documents. In LDA,
each document is generated by choosing a distribution over
topics and then choosing each word in the document from a
topic selected according to the distribution [3]. Generative
process of LDA can be described as follows:

1. for t = 1...T

(a) φt ∼ Dirichlet(β)

8773.1 ClassifyLDA

prominent words. Create Z(cid:48) =(cid:83)m

Our algorithm is based on generative property of LDA
and the aggregation property of the Dirichlet distribution.
Let us assume, we want to classify each document to one of
the class labels from C = {1, 2, ..., m}. Using Collapsed
Gibbs sampling for LDA, Z = {z1, z2, ..., zT} topics are
learnt on the document corpus D. Now an expert will assign
a class label, i ∈ C to each topic zt ∈ Z based on its most
i=1 Z i, the partition of Z
such that Z i = {zt|zt ∈ Z and class label of zt is i}.
If
θd =
(θ1,d, θ2,d, ..., θT,d) ∼ Dirichlet(α1, α2, ..., αT ) then using the
aggregation property of the Dirichlet distribution deﬁne θ(cid:48)
as:

a document d in the

corpus D,

for

d

θt,d, ..., (cid:80)
αt, (cid:80)

zt∈Zm

θt,d)

αt, ..., (cid:80)

zt∈Z1

zt∈Z2

zt∈Zm

αt)

(5)

d using following equations:

[ψw,t + βw] φ(cid:48)

w,Zi =

w,Zi(cid:80)

ψ

ψ

v∈W

v,Zi

(6)

θ

zt∈Z2

(cid:48)

zt∈Z1

θt,d, (cid:80)
d = ( (cid:80)
∼ Dirichlet( (cid:80)
ψw,Zi = (cid:80)
ΩZi,d = (cid:80)

t and θ(cid:48)

t∈Zi

Initialize φ(cid:48)

[Ωt,d + αt]

Zi ,d(cid:80)
(7)
Using Collapsed Gibbs sampling for LDA, update φ(cid:48)
t and θ(cid:48)
d.
A class label c ∈ C is assigned to document d ∈ D such that:
c = arg max

θ(cid:48)
Zi,d =

t∈Zi

k∈C

Zk ,d

Ω

Ω

θ(cid:48)
Zi,d.

Algorithm 1 describes our for document classiﬁcation algo-
rithm .

i

Algorithm 1: ClassifyLDA

input : D = {d} : Document corpus
output: Class label (dc) from C = {1, 2, ..., m} for

each document d ∈ D

1 begin
2
3
4

Create a partition Z(cid:48) =(cid:83)m

Use LDA to learn Z = {z1, ..., zT} topics on D;
Compute φt and θd using equations 1 ;
Expert will assign a class label, i ∈ C to each
topic zt ∈ Z based on its most prominent words;
i=1 Z i such that:
Z i = {zt|zt ∈ Z and class label of zt is i};
Initialize φ(cid:48)
Update φ(cid:48)
sampling;
for d ∈ D do
Infer θ(cid:48)
dc = arg max

Zi,d;∀i ∈ C using equation 7 ;

d using equations 6 and 7;

d using Collapsed Gibbs

t and θ(cid:48)
t and θ(cid:48)

θ(cid:48)
Zi,d ;

5

6
7

8
9
10

i

end

11
12 end

2. for each document d ∈ D

(a) θd ∼ Dirichlet(α)
(b) for each word w at position n in d

i. zn
ii. wn

d ∼ Multinomial(θd)
d ∼ Multinomial(zn
d )

Where, T is the number of topics, φt is the word probabil-
ities for topic t, θd is the topic probability distribution, zn
d
is topic assignment and wn
d is word assignment for nth word
position in document d respectively. α and β are topic and
word Dirichlet priors respectively.
Training an LDA model is estimation of the word-topic dis-
tributions and the topic distributions for all documents in
the corpus. Direct and exact estimation of these parame-
ters is intractable. Collapsed Gibbs sampling is one of the
techniques used for the parameter estimation of LDA [3]. Af-
ter performing collapsed Gibbs sampling, probability of the
word w assigned to the topic t (φw,t) and the probability of
the topic t assigned to document the d (θt,d) is estimated as:

φw,t =

(cid:34) (cid:80)

v∈W

ψw,t+βw

ψv,t+βv

(cid:35)

θt,d = Ωt,d+αt
Ωi,d+αi

(cid:34) T(cid:80)

i=1

(cid:35)

(1)

Where ψw,t is the count of the word w assigned to the topic
t, Ωt,d is the count of the topic t assigned to words in the
document d and W is the vocabulary of the corpus.
LDA discovers a set of topics present in the documents and
gives probabilities of observing each word in each topic.
Most prominent words in a topic frequently co-occur with
each other in the documents so one can infer context of
the words in a topic. Using the word probabilities one can
interpret meaning of topics and ﬁnd major themes in the
documents. The topic probabilities of a document provide
its explicit representation and these probabilities can be em-
bedded in more complex model.
2.1 The Dirichlet distribution

The Dirichlet distribution is deﬁned as:

p(θ|α) =

θαt−1

t

(2)

Γ(αt)

t=1

t=1

(i.e. 0 < θt < 1 and(cid:80)T

where, θ = {θ1, ..., θt, ..., θT} is a point on the (T −1) simplex
t=1 θt = 1) and α = (α1, ..., αt, ..., αT )

is a set of parameters with αt > 0. So,

θ = (θ1, ..., θt, ..., θT ) ∼ Dirichlet(α1, ..., αt, ..., αT )

(3)
Aggregation property of the Dirichlet distribution:
The Dirichlet distribution has a fractal
like aggregation
property [2]. It is deﬁned as the aggregation of any subset
of Dirichlet distribution variable yields a Dirichlet distribu-
tion, with corresponding aggregation of the parameters. If
{A1, A2, ..., Ar} is a partition of {1, 2, ..., T} then,

(cid:48)

θ

= ( (cid:80)
θt, (cid:80)
∼ Dirichlet( (cid:80)

θt, ..., (cid:80)
αt, (cid:80)

t∈A2

t∈A1

t∈Ar

θt)

αt, ..., (cid:80)

αt)

t∈Ar
3. DOCUMENT CLASSIFICATION

t∈A2

t∈A1

In this section, we propose our document classiﬁcation
algorithm based on LDA (ClassifyLDA) and an extension of
the algorithm based on the combination of EM algorithm
and a naive Bayes classiﬁer (ClassifyLDA-EM).

T(cid:80)

t=1

Γ(

T(cid:81)

T(cid:89)

αt)

(4)

3.2 ClassifyLDA-EM

In ClassifyLDA-EM algorithm, we build a classiﬁer us-
ing the combination of EM and a naive Bayes classiﬁer. In
this algorithm we use EM iterations along with the relation
between word co-occurrence knowledge and class labels to
improve the parameters of a naive Bayes classiﬁer.

878Initially, we label all the unlabeled documents in the cor-
pus using ClassifyLDA algorithm described in algorithm 1.
Then, we build a naive Bayes classiﬁer using these labeled
documents and estimate class probabilities for each docu-
ment. Using these estimated class probabilities we reassign
a class label to each document and rebuild a new naive Bayes
classiﬁer.
We iterate this process of reassigning class labels to the doc-
uments and rebuilding a naive Bayes classiﬁer until it con-
verges to a stable classiﬁer. We say a classier is stable when
the change in log likelihood of the parameters of the classier
is below a threshold. ClassifyLDA-EM can be described as:

• Input: D = {d} : Unlabeled document corpus
• Initialization:

Let ˆC be an initial classiﬁer, built
using ClassifyLDA algorithm. Assign a class label to
each unlabeled document in D using ClassifyLDA.

• Loop while ˆC converges:

– E-step: Use the current classiﬁer, ˆC, to estimate
the probability of a document belonging to each
class.

– M-step: Re-estimate the classiﬁer, ˆC using naive
Bayes model based on the document-class proba-
bilities computed in E-step

• Use ˆC to classify an unlabeled document.

4. EXPERIMENTAL EVALUATION

We

We determine the eﬀectiveness of our algorithm in relation
to semi-supervised text classiﬁcation algorithm proposed in
[5] (NB-EM). We report the minimum number of labeled
documents at which the performance of ClassifyLDA-EM
and NB-EM are almost similar.
4.1 Datasets
evaluate

eﬀectiveness of ClassifyLDA and
ClassifyLDA-EM on following three real world text classi-
ﬁcation datasets.
1. 20Newsgroup: This dataset contains messages across
twenty newsgroups. In our experiments, we use bydate ver-
sion of the 20Newsgroup dataset1. This version contains
separate train and test datasets of 20 newsgroups which are
grouped into 6 major categories. We selected 4 major cat-
egories: comp, politics, rec, and religion. Following are the
newsgroups in each selected category.

the

1. comp:

comp.graphics,

comp.sys.ibm.pc.hardware,
comp.windows.x

comp.os.ms-windows.misc,
comp.sys.mac.hardware,

2. politics:

talk.politics.misc,

talk.politics.guns,

talk.politics.mideast

3. rec:

rec.autos, rec.motorcycles, rec.sport.baseball,

rec.sport.hockey

4. religion:

talk.religion.misc,

alt.atheism,

soc.religion.christian

We experimented with all possible combinations of these ma-
jor categories.
2. SRAA: Simulated/Real/Aviation/Auto UseNet
data2: This dataset contains 73,218 UseNet articles from
1http://qwone.com/~jason/20Newsgroups/
2http://people.cs.umass.edu/~mccallum/data.html

four discussion groups, for simulated auto racing (sim auto),
simulated aviation (sim aviation), real autos (real auto),
real aviation (real aviation). Following are the three clas-
siﬁcation tasks associated with this dataset.

1. sim auto vs sim aviation vs real auto vs real aviation

2. auto (sim auto + real auto) vs aviation (sim aviation

+ real aviation)

3. simulated (sim auto + sim aviation) vs real (real auto

+ real aviation)

3. WebKB 3: This dataset contains 4199 university web-
pages. The task is to classify the webpages as student,
course, faculty or project.
We randomly split SRAA and WebKB datasets such that
80% is used as training data and remaining 20% is used as
test data.
4.2 Experimental settings

We did preprocessing on the dataset by removing headers
and stopwords. We evaluated eﬀectiveness of our algorithm
by computing the Macro F-measure (F1).
For classiﬁcation tasks of 20Newsgroup related dataset we
choose number of topics (T) equal to two times number of
classes. For SRAA dataset we learnt 10 topics on the com-
plete dataset and labeled these 10 topics for all the three
classiﬁcation tasks. For WebKB dataset we learnt 10 topics.
The Dirichlet parameter β was chosen to be 0.01 and α was
50/T. We used Mallet4 to run LDA on the documents.
In NB-EM algorithm, we do 10 trails per number of labeled
documents and report average Macro F1.
4.3 Results

Table 1 shows experimental results. We can observe that,
ClassifyLDA-EM algorithm can achieve almost similar per-
formance in relation to NB-EM with signiﬁcant reduction in
labeling eﬀorts and for most of the datasets performance of
our algorithm is above 0.9. In table 1, we can also observe
improvement in the performance of ClassifyLDA-EM over
ClassifyLDA which proves that the combination of EM and
a naive Bayes classiﬁer reduces the inﬂuence of approximate
or noisily labeled documents.
We observed that, performance of NB-EM depends on initial
labeled documents.
4.4 Example

Table 2 shows topics learnt and classiﬁcation of the top-
ics on “politics vs rec” dataset. With the help of most
prominent words in a topic an expert can assign a class
label to the topic. Due to generative property of LDA,
topics labeled with class label “politics” will generate pol-
itics related documents with high probability. Now we will
create the partition Z(cid:48) = {{z0, z1},{z2, z3}} for the topics
Z = {z0, z1, z2, z3}. Using the aggregation property of the
Dirichlet distribution, all the same class label topics are ag-
gregated into a single topic. Now, we can use algorithm 1
and the combination of EM algorithm and a naive Bayes
classiﬁer to estimate class labels for unseen documents.
We also explored how well a topic correlates with the class

3http://www.cs.cmu.edu/~webkb/
4http://mallet.cs.umass.edu/

879Data set

ClassifyLDA
(Macro-F1)

ClassifyLDA-EM
(Macro-F1)

# Topics NB-EM

(Macro-F1)

# Labeled docu-
ments for NB-EM

20Newsgroup
comp vs politics
comp vs rec
comp vs religion
politics vs rec
politics vs religion
rec vs religion
comp vs politics vs rec
comp vs politics vs religion
comp vs rec vs religion
politics vs rec vs religion
comp vs politics vs rec vs religion
SRAA
sim auto vs sim aviation vs real auto
vs real aviation
auto vs aviation
simulated vs real
WebKB
student vs course vs faculty vs project

0.960
0.903
0.953
0.957
0.872
0.959
0.932
0.896
0.936
0.889
0.891

0.732

0.908
0.917

0.711

0.976
0.949
0.979
0.980
0.929
0.988
0.960
0.932
0.965
0.937
0.936

0.770

0.929
0.933

0.719

4
4
4
4
4
4
6
6
6
6
8

10

10
10

10

0.974
0.947
0.981
0.978
0.927
0.986
0.960
0.929
0.964
0.935
0.934

0.786

0.927
0.931

0.730

20
25
25
70
65
105
125
115
105
190
480

10250

300
5250

1150

Table 1: Experimental results (Macro-F1) of document classiﬁcation on 20Newsgroup, SRAA and WebKB datasets

ID Most prominent words in the topic
0

gun armenian turkish didn guns killed ﬁle
weapons armenia
israel government president jews american
fact question law case rights
team game play season hockey players win
league baseball
car bike front road buy drive speed engine

1

2

3

Class
politics

politics

rec

rec

Table 2: Topic labeling on the politics vs rec dataset

assigned to it. We represented each class as probability dis-
tribution over words. We computed P (w|cj), the probability
of the word w belonging to the class cj as the fraction of the
number of times word w appears among all the words in
documents of class cj. Then we computed Kullback-Leibler
(K-L) divergence between each class and a topic. Table 3
shows K-L divergence between each class and a topic for the
same dataset. We can observe that the K-L divergence is
least for the class assigned to a topic by the expert.

Topic-class mapping

ID Expert assigned class label
0
1
2
3

politics
politics

rec
rec

politics

Class labels
rec
6.12
6.12
3.73
4.32

3.89
3.57
6.64
6.13

Table 3: K-L Divergence between each class and a topic
for the politics vs rec dataset

5. CONCLUSIONS

In this paper, we propose a novel, inexpensive document
classiﬁcation algorithm which requires minimal supervision.
Our algorithm is based on the generative property of LDA

and the aggregation property of the Dirichlet distribution.
We also show eﬀectiveness of our algorithm with the help of
experiments. Our approach is speciﬁcally suited for domains
where establishing a mapping from topics to class labels is
easier than acquiring a labeled collection of documents. In
future we would like to carry out experiments on datasets
like Reuters-21578 and a more detailed investigation on how
the topic-class mapping inﬂuences the classiﬁcation eﬀec-
tiveness. We will also explore tools that help experts arrive
at the most appropriate topic-class mapping.

6. REFERENCES
[1] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent

dirichlet allocation. The Journal of Machine Learning
Research, 3:993–1022, March 2003.

[2] B. A. Frigyik, A. Kapila, and M. R. Gupta.

Introduction to the dirichlet distribution and related
processes. Technical report. University of Washington,
Seattle, 2012. https://www.ee.washington.edu/
techsite/papers/documents/UWEETR-2010-0006.pdf

[3] T. L. Griﬃths and M. Steyvers. Finding scientiﬁc

topics. PNAS, 101(suppl. 1):5228–5235, April 2004.

[4] A. Mccallum and K. Nigam. Text classiﬁcation by

bootstrapping with keywords, EM and shrinkage. In
ACL-99 Workshop for Unsupervised Learning in
Natural Language Processing, pages 52–58, 1999.

[5] K. Nigam, A. K. McCallum, S. Thrun, and T. Mitchell.

Text classiﬁcation from labeled and unlabeled
documents using EM. Machine Learning - Special issue
on information retrieval, 39(2-3), May-June 2000.
[6] A. Chanen and J. Patrick. Measuring Correlation

Between Linguists’ Judgments and Latent Dirichlet
Allocation Topics. Proceedings of the Australasian
Language Technology Workshop, pages 13–20, 2007.

880