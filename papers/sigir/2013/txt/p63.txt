Learning Latent Friendship Propagation Networks with

Interest Awareness for Link Prediction∗

Jun Zhang1,2,3,4 Chaokun Wang2,3,4

Philip S. Yu5

Jianmin Wang2,3,4

1 Department of Computer Science and Technology, Tsinghua University

2 School of Software, Tsinghua University

3 Tsinghua National Laboratory for Information Science and Technology

4 Key Laboratory for Information System Security, Ministry of Education, P. R. China

5 Department of Computer Science, University of Illinois at Chicago

zhang-jun10@mails.thu.edu.cn, chaokun@tsinghua.edu.cn, psyu@uic.edu, jimwang@tsinghua.edu.cn

ABSTRACT
It’s well known that the transitivity of friendship is a popular soci-
ological principle in social networks. However, it’s still unknown
that to what extent people’s friend-making behaviors follow this
principle and to what extent it can beneﬁt the link prediction task.
In this paper, we try to adopt this sociological principle to explain
the evolution of networks and study the latent friendship propaga-
tion. Unlike traditional link prediction approaches, we model link
formation as results of individuals’ friend-making behaviors com-
bined with personal interests. We propose the Latent Friendship
Propagation Network (LFPN), which depicts the evolution progress
of one’s egocentric network and reveals future growth potentials
driven by the transitivity of friendship based on personal interests.
We model individuals’ social behaviors using the Latent Friend-
ship Propagation Model (LFPM), a probabilistic generative model
from which the LFPN can be learned effectively. To evaluate the
power of the friendship propagation in link prediction, we design
LFPN-RW which models the friend-making behavior as a random
walk upon the LFPN naturally and captures the co-inﬂuence effect
of the friend circles as well as personal interests to provide more
accurate prediction.

Experimental results on real-world datasets show that LFPN-RW
outperforms the state-of-the-art approaches. This convinces that
the transitivity of friendship actually plays important roles in the
evolution of social networks.

Categories and Subject Descriptors
H.2.8 [DATABASE MANAGEMENT]: Database Applications—
Data mining; J.4 [SOCIAL AND BEHAVIORAL SCIENCES]:
Sociology

Keywords
Link Prediction; Social Networks; Transitivity of Friendship; Friend-
ship Propagation; Interest Awareness
∗

Corresponding authors: Chaokun Wang and Jianmin Wang.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for proﬁt or commercial advantage and that copies bear
this notice and the full citation on the ﬁrst page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior speciﬁc permission and/or a fee. Request
permissions from permissions@acm.org.
SIGIR’13, July 28–August 1, 2013, Dublin, Ireland.
Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

1.

INTRODUCTION

The evolution of social networks has attracted considerable at-
tention recently. Since the seminal work of Liben-Nowell and K-
leinberg [18], it has been formulated as the link prediction task
which studies the formation and variation of the links in the net-
work. Both unsupervised and supervised approaches have been
proposed, based on the current observations of the network, utiliz-
ing the structural or vertex-intrinsic features [19][9][20][1]. Most
approaches treat the network as an evolving graph and each indi-
vidual as a general vertex in the graph, while ignoring the initiative
of individuals as active participants in the evolution of the social
network.

From another point of view, people’s social behaviors have been
studied by sociologists long ago [28]. They have found many inter-
esting and popular phenomena [23][21][26][8], which are also ver-
iﬁed in online social networks by computer scientists [12][5][24]
[11][27]. Among these phenomena is triadic closure [26][8], which
states that two persons with common friends will likely become
friends in the future. The sociological principle under this phe-
nomenon is the transitivity of friendship [26][15]. Although re-
searchers have found that most of new links close an open triangle
[16], not all open triangles will be closed with equal probabilities.
It’s still unknown how this principle works in real world, and to
what extent it can promote the evolution of social networks and
furthermore beneﬁt the link prediction task.

In this paper, we study the evolution of social network based on
one of the well-known sociological principles, i.e.
the transitivi-
ty of friendship. We address the above problems by positing that
there is some underlying unknown network over which friendships
propagate, and the evolution of social networks can be regarded as
results of the friendship propagation based on common user inter-
ests. We formulate such network as the Latent Friendship Propa-
gation Network (LFPN), which depicts the growth process of one’s
ego-centric social network driven by the friendship propagation via
the co-inﬂuence effect of the friend circles with common user in-
terests, and also captures the trend of friendship propagation on the
whole network. In LFPN, we assume one, denoted by the ego, ex-
pands her social circles mainly via her existing friends, who act as
intermediaries and introduce new friends to the ego explicitly or
implicitly based on common interests.

We demonstrate the proposed LFPN with a toy example. Fig. 1(a)
shows an egocentric network with a as the ego, which we mark as
purple. The blue vertices are a’s friends; the green ones show the
friends of a’s friends. The connections among the blue and green
vertices are omitted for brevity. Given the plain structure of an
egocentric network, we can hardly observe the implicit intrinsic

63a

Local Layer

Local Layer

Local Layer

Ego

Ego

Ego

(a) Egocentric network of a

(b) a’s partial view of the LFPN

(c) More complete view of the LFPN

Figure 1: An LFPN is composed of three layers: the ego layers, the local layers for each ego, and the global layer for the whole
network. In this ﬁgure, the purple vertex a is the ego, the blue vertices are the friends of the ego and the green ones show other
individuals in the network.

Global Layer

structures and relations within it. The LFPN shows a 3-layer hi-
erarchical network for the original network. Fig. 1(b) shows the
partial view of the ego a. While the ﬁrst layer is the ego herself, the
second layer, the local layer, consists of all her current friends and
the directed edges as representation of the friendship propagation
traces along which a created relationships with each one. In this
ﬁgure we can see that a made friends with b directly, and via b she
became friends of e, and furthermore she created friendship with d
via b and e. Through the local layer as intermediaries a can make
more new friends in the global layer in which the edges among in-
dividuals represent the potential friendship propagation directions
in the whole network. While the local layer is deﬁned for each ego
and visualizes the growth of one’s friend circles by showing the
intermediaries for each of her friends, the global layer is inferred
based upon all the local layers and deﬁned for the whole network.
A more complete LFPN with multiple egos is shown in Fig. 1(c).

However, learning the LFPN is challenging because the network
over which friendship propagation takes place is usually unknown
and unobserved. Thus, the ﬁrst challenge is, how we can lever-
age one’s social behaviors to infer all the potential intermediaries
and furthermore learn the structure of the friendship propagation
network?

While traditional approaches for link prediction are usually based
on the topological features, LFPN provides a hierarchical view of
one’s friend circles from which we can observe the evolution of
networks from the perspective of the ego, who drives this evolution
progress. This leaves us the second challenge: to what extent the
transitivity of friendship inﬂuences the network evolution, whether
there is a co-inﬂuence effect of the friend circle, and how they can
be utilized to predict future shapes of the network?

Along with the transitivity of friendship, another factor which
affects one’s social behaviors is the personal interests. In this s-
tudy, we’re also interested in the challenge that how the personal
interests, along with the friendship propagation, affect the creation
of friendships?
1.1 Contributions

To address these challenges we study how the LFPN can be in-
ferred based on behavior modeling, and further utilized for predict-
ing or recommending new links. To the best of our knowledge,
this is the ﬁrst time that the transitivity of friendship is deeply in-
vestigated and the link formation is studied based on the behavior
modeling. The main contributions of this paper can be summarized
as follows.

Firstly, we formulate the LFPN, which depicts the evolution
traces of one’s egocentric social network and potential friendship
propagation traces on the whole network based on the transitivity
of friendship with interest awareness.

We design LFPM (Latent Friendship Propagation Model), a prob-
abilistic generative model for the friend-making behaviors of indi-
viduals in social networks. LFPM models the interest-aware friend-
ship propagation driven by the transitivity of friendship. Given the
time-stamped individuals’ social behavior histories, we can learn
the hidden LFPN based on LFPM effectively. It should be noted
that both the friendship propagation and personal interests are in-
ferred from the social behaviors only, and no other evidences are
included.

Furthermore, we put forward a new method for link prediction
utilizing the transitivity of friendship and personal interests based
on the LFPN. We simulate the link creation using a random walk
of an ego on the two layers of the LFPN. Firstly, she seeks for
a preferred intermediary in her local layer of the LFPN, and via
this intermediary she goes to the global layer where she makes
new friends. We name this process as LFPN-RW (Random Walk
upon LFPN), in which the random walk is guided by the friendship
propagation based on the co-inﬂuence effect of friend circles and
personal interests.

We conduct extensive experiments on real-world datasets. Ex-
perimental results show that the inferred LFPN actually contains
important knowledge about the network evolution and can beneﬁt
the link prediction signiﬁcantly.
1.2 Roadmap

The rest of this paper is organized as follows. We formulate the
LFPN in Section 2. Methods for inferring the LFPN are developed
in Section 3. Afterwards we present LFPN-RW, the new approach
for link prediction upon LFPN in Section 4. In Section 5, we dis-
cuss the experimental results. We review related work in Section 6
and conclude this study in Section 7.

2. LFPN DEFINITION
In this section, we introduce the concepts related to LFPN. As
shown in Fig. 1(c), the LFPN G is composed of three layers: the
ego, the local layer and the global layer. In the following we ﬁrst
deﬁne the local layer and global layer respectively, and then give
the deﬁnition of the LFPN.
Let G = {G1, G2,··· , GT} denote an evolving social network
where Gt = (Vt, Et) is a directed graph denoting the snapshot
of the network at time t. Each vertex in Vt represents an individ-
ual in the network, and the edges in Et indicate the friendships
among them. ΔGt denotes the new vertices and edges appearing
during the period t (i.e. the time from t − 1 to t), and thus we have
Gt = Gt−1 ∪ ΔGt. We’ll use G to denote any snapshot of the
evolving G for simplicity. Furthermore, for each snapshot Gt we
have a corresponding interaction set Xt ⊂ Vt × Vt which denotes

64the interactions among individuals in t. The interactions include
co-authoring a paper in scholar collaboration network, leaving a
message on Facebook, etc.

It should be noted that although the network G is directed here,
the problem discussed in this paper is also applicable to undirected
networks which can be transformed to directed networks.

In this paper, we study how E grows in social networks, i.e. the
formation of friendships. Based on the transitivity of friendship,
when two individuals become friends, we assume their common
friends act as the role of “intermediaries”.

Deﬁnition 1. Latent Friendship Propagation Triple (LFP Triple).

For three vertices u, z and v in G, (u, z, v) is named as an LFP
Triple if u makes friends with v via z. u is called the initiator of
this tuple and z is the intermediary.

Each LFP Triple (u, z, v) is associated with an intermediation
probability p(z|(cid:5)u, v(cid:6)) which denotes the probability that z has
acted as the intermediary for u to makes friends with v.

We use Ft(u) to denote the set of friends of u at time t, and
Ft(u, v) to denote the set of common friends of u and v at time t.
As each common friend in Ft(u, v) may act as the intermediary,
the intermediation probability satisﬁes:

(cid:2)

z∈Ft(u,v)

p(z|(cid:5)u, v(cid:6)) = 1.

(1)

If u doesn’t have any common friends with v, we assume u

makes friends with v directly.

Deﬁnition 2. The local layer of ego u on an LFPN G, denoted
as GL(u), consists of all the friends of u. For each LFP Triple
(u, z, v) initiated by u there is a corresponding local LFP edge
(cid:5)z, v(cid:6) in GL(u), whose weight wL(u)

z,v = p(z|(cid:5)u, v(cid:6)).

The local layer of the LFPN is deﬁned for each ego u. Each
friend of the ego u ∈ GL(u) can play the role of intermediary for
u to make more new friends. We use the intermediary preference
probability p(u (cid:2) z) to measure u’s preference for each friend z
as the intermediary.

We deﬁne the cross-layer edges from the ego to the local layer

as intermediary preference edges.

Deﬁnition 3. For each friend z ∈ GL(u), there’s an intermedi-
ary preference edge (cid:5)u, z(cid:6) pointing from the ego u to z in the local
layer, whose weight wE

u,z = p(u (cid:2) z).

Deﬁnition 4. Each LFP Triple (u, z, v) derives an LFP Pattern
z (cid:3) v, indicating that one’s friendship with z is likely to propagate
to v.

Each LFP Pattern is associated with a friendship propagation
probability p(z (cid:3) v) which denotes the extent to which z is will-
ing to recommend v to her friends and the friends of z are likely to
make friends with v in the future.

Deﬁnition 5. The global layer of an LFPN G, denoted as GG,
consists of all the individuals of the given social network. For each
LFP Pattern z (cid:3) v there’s a corresponding global LFP edge (cid:5)z, v(cid:6)
in GG, whose weight wG

z,v = p(z (cid:3) v).

The global layer is deﬁned for the whole network based on the
LFP Patterns. It can be interpreted as the aggregation of all the local
layers. Each vertex has its direct projection on the global layer so
we don’t deﬁne the cross-layer from the local to global layer again.

Now we can give the deﬁnition of LFPN.

U, K
Nu, Vu
F (u)
Y (u)
X(u)

θu
φu
χu
ψc
zu,y

α, β, δ, γ
Ω(cz)
ci,zi
Ω(cy)
ci,yi

Ω(uc)
ui,ci
Ω(uz)
ui,zi
Ω(zy)
zi,yi
Ω(uv)
ui,yi

Table 1: The notations for the LFPM
# of individuals and topics
# of new friends and interactions of u
The current friend set of individual u
The new friend set of individual u
The interaction collection of individual u
The intermediary preference distribution of u
The friendship strength distribution of u
The interest preference distribution of u
The reputation distribution of topic c
The intermediary assignment of the friendship u → y
The prior parameters for θ, φ, χ, ψ, respectively
# that zi has acted an intermediary in topic ci
# that yi has been recommended and accepted as a
new friend in topic ci
# that ui has selected friends in topic ci
# that ui has selected zi as an intermediary
# that zi has recommend yi for others
# that ui has interacted with yi

Deﬁnition 6. The Latent Friendship Propagation Network (LF-
PN) G for a given social network G is a weighted 3-layer net-
work consisting the ego layers {u}, the local layers for each ego
{GL(u)}, and the global layer GG.

The local layer shows the inferred traces for the evolution his-
tory of one’s current egocentric network, while the global layer
indicates the possible traces for the friendship propagation on the
whole social network in the future. The global layer can also be
regarded as a friend-recommendation network, as in some sense
it’s the recommendation among people that promotes the friend-
ship propagation.

3. LFPN INFERENCE

In this section, we develop effective algorithms for the inference
of LFPN for the given social network. Before proceeding, we for-
mulate our problem as follows:
LFPN Inference Problem. Given an evolving social network
G = {G1, G2,··· , Gt} and the associated interaction sets X =
{X1, X2,··· , Xt}, the LFPN inference problem is to infer the LF-
PNs G1,G2,··· ,Gt, where Gt is the LFPN for Gt.

As each snapshot is a subgraph of any of later snapshots, each
LFPN also contains the structures of the LFPN inferred from the
earlier snapshots. However, the weights of the same edges are not
necessarily equal because the network is evolving and the propaga-
tion patterns are also varying.

In the remainder of this section, we ﬁrst introduce the LFPM
model for learning the LFPN on a single snapshot, and then present
the inference framework for LFPM. We discuss the inference of
LFPN on an evolving network at last.
3.1 The LFPM Model

Each LFP Triple (u, z, v) implies the assumption that the friend-
making behavior is a 2-step process: u selects z as an intermediary
ﬁrst and then via z she makes friends with v. Meanwhile this pro-
cess is inevitably inﬂuenced by the interests of u. LFP Patterns
are the aggregation of LFP Triples, and both of them are the basic
elements for LFPN. Thus the preliminary problem for the LFPN
inference is to ﬁnd all the LFP Triples. In other words, given each
friendship between u and v, we need to infer the intermediary z.

65(cid:2009)(cid:3)(cid:3)(cid:3)

(cid:3)(cid:3)(cid:577)(cid:3)
(cid:3)

(cid:3)(cid:3)(cid:2031)(cid:3)

(cid:3)(cid:3)(cid:1855)(cid:3)

(cid:1847) 

(cid:1847)(cid:3)

(cid:1840)(cid:3048)(cid:3)
 (cid:3)

(cid:3)(cid:3)(cid:1876)(cid:3)

(cid:1848)(cid:3048)(cid:3)
(cid:3)(cid:3)

(cid:3)(cid:3)(cid:2011)(cid:3)

(cid:3)(cid:3)(cid:2032)(cid:3)

(cid:1837)(cid:3)

  (cid:2016) 

(cid:3)(cid:3)(cid:1878)(cid:3)

(cid:3)(cid:3)(cid:1877)(cid:3)

(cid:3)(cid:3)(cid:2038)(cid:3)

(cid:3)(cid:3)(cid:2010)(cid:3)

Figure 2: The graphical representation of LFPM

To model this process and infer the intermediaries of each friend-
ship, we propose the Latent Friendship Propagation Model (LFP-
M), a probabilistic generative model for the social behaviors in so-
cial networks. In this paper we only consider the social behaviors
like friend-making and interactions. LFPM models the generative
process for individuals’ social behaviors as follows:

1. Sample the number of individuals U ∼ Poisson ().
2. For each of the K interest areas c, sample its reputation dis-

tribution ψc ∼ Dir(γ)
3. For each individual u:
(a) Sample her friendship strength distribution φu ∼ Dir(βu).
(b) Sample the number of her interactions, Vu ∼ Poisson(ξ).
(c) For each of the Vu interactions:
i. Sample one of her existing friends, x ∼ φu, as

another participant of the interaction

4. For each individual u:

(a) Sample her interest preference distribution χu ∼ Dir(δ).
(b) Sample her intermediary preference distribution θu ∼
(c) Sample the number of her new friends, Nu ∼ Poisson(ζ).
(d) For each of the Nu new friends:

Dir(αu).

i. Sample an interest area c ∼ χu
ii. Sample an intermediary z ∼ θu · ψc
iii. Sample a new friend y ∼ φz · ψc

We draw the graphical representation of LFPM in Fig. 2. In LFP-
M, each interest area is modelled as a distribution over individuals.
Each ego is modelled as a distribution of her intermediaries, i.e.
the individuals that may make recommendations to her, and each
intermediary as a distribution over the friends of this intermediary.
Thus, the set of new friends of an ego can be modelled as the mix-
ture of her intermediaries and interest areas. Speciﬁcally, the inter-
mediary preference distribution θ describes through whom an ego
prefers to make new friends, and friendship strength distribution φ
models the closeness of an ego with each of her friends. Such close-
ness can be reﬂected by both the frequency of their interactions and
the willingness of the ego to recommend her friends to others. We
use the interest preference distribution χ to model one’s interest
preference in friend-making behaviors, and regard the reputation
distribution ψ as a global reputation ranking of all individuals in
each interest area. It’s natural to assume that one prefers to make
friends with someone with higher reputation in her preferred area.
It should be noted that the interests here are learned only from the
social behavior histories, rather than external proﬁles.

To improve the inference performance, we adopt heuristic prun-
ing by constraining that for each individual her intermediary pref-
erence distribution and friendship strength distribution are only de-
ﬁned over her current friends, based on the assumption that only the

current friends of ego u may act as u’s intermediaries, and that an
intermediary z can only recommend and interact with the current
friends of z. This is different from traditional topic models like L-
DA[2], which deﬁnes the distributions over the whole space. Thus
in our model, each individual maintains a unique sampling space
for herself. Correspondingly, the prior distributions for θ and φ are
also required to be deﬁned on the corresponding pruned space for
each individual. That’s why the priors α and β need to be deﬁned
for each individual u and are placed within the big box labelled U
in the graphical model shown in Fig. 2.

LFPM applies to a snapshot Gt and tries to infer the friendship
propagation in the expansion of one’s egocentric network in peri-
od t. For the social behaviors that happen in period t, the hidden
distributions θ and φ of LFPM can be naturally interpreted as the
intermediary preference probabilities wE of each ego and friend-
ship propagation probabilities wG in the LFPN in period t, respec-
tively. Each possible intermediary assignment for each friendship
is an LFP Triple and the sampling probability can be regarded as
the intermediation probabilities wL. With the inferred LFP Triples
and the weights wE, wL and wG we can construct the LFPN Gt.
3.2 Inference Framework for LFPM

Exact inference for LFPM is generally intractable. In this sub-
section we present the framework for LFPM inference using Gibbs
sampling, a special case of Markov-Chain Monte Carlo (MCMC)
simulation, which can emulate high-dimensional probability distri-
butions by the stationary behavior of a Markov chain.

Firstly, the joint probability of all observed and unobserved data

can be stated as follows (with the distributions integrated out):

P (C, Z, X, Y ; α, β, γ, δ)

U(cid:3)

B(Ω(uz)

= (

· (

u=1

U(cid:3)

B(Ω(uv)

K(cid:3)

)(

u + α(θ)
u )
B(α(θ)
u )
k=1
u + Ω(zy)
u + β(φ)
u )
B(β(φ)
u )

B(Ω(cz)

k + Ω(cy)

k + γ)

)

B(γ)

U(cid:3)

B(Ω(uc)
u + δ)
B(δ)

)(

u=1

u=1

),(2)
where B(·) is the multinomial Beta function. For the details of
other notations please refer to Table 1.

We infer the model by updating the estimation for unobserved
variables c and z iteratively. In each iteration, we sample c and z
for each new friendship i according to the conditional probability
p(ci|C−i, Z, X, Y ; α, β, γ, δ) and p(zi|C, Z−i, X, Y ; α, β, γ, δ).
Y and X are the new friendship and the interaction data, respec-
tively. C and Z are estimations for the interest area and intermedi-
ary for each friendship, respectively. C−i is the current estimations
except ci and Z−i is that except zi.

The sampling probabilities can be estimated by

p(ci|C−i, Z, X, Y ; α, β, γ, δ)=

ci,yi + γci,zi − 1)

P (C, Z, X, Y )
P (C−i, Z, X, Y )
ci,v + γci,v) − 1

∝

(cid:4)

ci,zi + Ω(cy)

(Ω(cz)
ci,v + Ω(cy)
v∈F (ui)(Ω(cz)
ui,ci + δui,ci − 1
Ω(uc)
(cid:4)K
ui,k + δui,k − 1)
k=1(Ω(uc)

·

,

(3)

p(zi|C, Z−i, X, Y ; α, β, γ, δ)=

∝

(cid:4)

Ω(uz)

ui,zi + α(θ)

ui,zi − 1
ui,v + α(θ)

P (C, Z, X, Y )
P (C, Z−i, X, Y )
ui,v) − 1
zi,yi + β(φ)

zi,yi − 1
zi,v + β(φ)
ci,zi + γci,zi − 1

zi,v + Ω(zy)

zi,v) − 1

v∈F (ui)(Ω(uz)
(cid:4)

Ω(uv)

zi,yi + Ω(zy)

v∈F (ui)(Ω(uv)

Ω(cz)

ci,zi + Ω(cy)

v∈F (ui)(Ω(cz)

ci,v + Ω(cy)

ci,v + γci,v) − 1

(cid:4)

·

·

.

(4)

66Algorithm 1 LFPM Inference using Gibbs Sampling
Require:

The snapshot network Gt−1 at time t − 1
The increment of the network in period t, ΔGt
The interaction set in period t, Xt

Ensure:

The hidden distributions θ, φ, χ, ψ
The sampling distributions P c, P z

for each individual u who has new friends do

1: Initialize F, Y using Gt−1, ΔGt, respectively
2: Assign interest areas for each new friendship randomly
3: Assign intermediaries for each new friendship randomly
4: while not ﬁnished do
5:
6:
7:
8:
9:
end for
10:
11: end while
12: Update distributions θ, φ, χ, ψ using Eq. 5 – 8
13: Record all the sampling distributions for topics and intermedi-

for each new friend v ∈ Y (u) do
Sample interest area using Eq. 3
Sample intermediary using Eq. 4

end for

aries in the last iteration with P c and P z

14: return θ, φ, χ, ψ, P c, P z

Given the estimations for all unobserved data, we can estimate

the hidden distributions:

θui,zi =

(cid:4)

φzi,yi =

(cid:4)

Ω(uz)

ui,zi + α(θ)

ui,zi

,

v∈F (ui)(Ω(uz)

ui,v + α(θ)

ui,v)
zi,yi + β(φ)
zi,yi

Ω(uv)

zi,yi + Ω(zy)

χui,ci =

ψci,ui =

(cid:4)K

(cid:4)U

zi,v + Ω(zy)

zi,v + β(φ)
zi,v)

v∈F (ui)(Ω(uv)
Ω(uc)
ui,ci + δui,ci
k=1(Ω(uc)
Ω(cz)
u=1(Ω(cz)

ci,ui + Ω(cy)

ui,k + δui,k)

,

ci,ui + γci,ui

.

ci,u + Ω(cy)

ci,u + γci,u)

,

(5)

(6)

(7)

(8)

Algorithm 1 presents the inference framework. Firstly, it initial-
izes the friends set F before period t, and the new friendships Y
that emerge in t. The interest area and intermediary for each new
friendship are initialized randomly before the iteration. Next in
Line 4–11 the interest and intermediary are updated for each new
friendship using Eq. 3 and 4, iteratively. The iteration is repeated
until converge or the count of iterations reaches a given threshold.
The hidden distributions can be estimated using Eq. 5 - 8.
3.3 Learning Evolving LFPN in Cascade

In LFPM all behaviors are assumed to be independent with each
other, and the correlation among the behaviors is ignored, which
will lead to the loss of knowledge carried by the temporal behavior
sequence. To minimizing this loss, we can split the evolving social
network G into ﬁne-grained snapshots G1, G2, ··· , Gt and infer
the LFPM model on each snapshot, and thus we can build the cor-
responding LFPN G1,G2,· ·· ,Gt respectively. However, each Gt
is also a snapshot of the evolving G and only carries the information
of the behaviors in t, but ignores the knowledge of the previous be-
havior history. For learning the complete evolving LFPN, we apply
the LFPM in cascade, during which the later models can inherit the
knowledge learned from the previous models.

The knowledge accumulation in cascade LFPM is achieved by
the prior parameters, which can signiﬁcantly inﬂuence the behaviour
of the model by bringing important priori knowledge[10]. Via the
priors, the knowledge in the previous period can be transferred in-

Algorithm 2 Building Evolving LFPN
Require:

Ensure:

The evolving network G
The evolving LFPNs {Gt} for G

1: Split G into T subgraphs by discrete periods
2: for each period t ∈ T do
3:

Initialize the priors for t using the previous model according
to Eq. 9 – 12
Infer the LFPM on Gt
Initialize LFPN Gt using the structure of Gt−1
{In the following we omit the subscript t of weights and
distributions for brevity}
for each ego u ∈ Gt do

4:
5:
6:

Add new friends of u in t to GL(u)
for each friend z ∈ GL(u)

do

Add cross-layer edge (cid:5)u, z(cid:6) and set wE

t

t

end for
for each LFP Triple (u, z, v) initiated by u do

Add local LFP edge (cid:5)z, v(cid:6) to GL(u)
Set wL(u)

z,v ← p(z|(cid:5)u, v(cid:6))

t

u,z ← θu,z

7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22: end for
23: return G1,G2,··· ,Gt

end for

end for

end for
Add new individuals to GG
for each LFP Pattern (z, v) derived from the LFP Triples do

t

Add global LFP edge (cid:5)z, v(cid:6) to GG
Set wG

z,v ← φz,v

t

to the next period successively. We deﬁne the priors of the LFPM
at time t as the linear combination of the accumulated knowledge
from previous models encoded by the priors and the new knowl-
edge encoded by the statistics in the last period t − 1 as follows:
(9)
(10)
(11)
(12)
where λ is a cascade damping factor. A higher λ means to inherit
more priori information from the earlier models. For the ﬁrst model
the priors are initialized with the default values α0, β0, δ0, γ0.

u,z + Ω(u,z)(t−1)
u,y + Ω(u,v)(t−1)
u,c + Ω(u,c)(t−1)
c,u + Ω(c,y)(t−1)

u,z = λ · αt−1
αt
u,y = λ · βt−1
βt
u,c = λ · δt−1
δt
c,u = λ · γt−1
γt

+ Ω(z,y)(t−1)

u,y

u,y

u,z

u,c

c,u

While cascade LFPM allows knowledge accumulation in the mod-
el inference on the sequential snapshots, the LFPN can also inherit
the structures from previous periods. By adding the new structures
and updating the weights learned from the LFPM for each period,
we can always get the up-to-date evolving LFPN for the evolving
social network. The details are given in Algorithm 2.

4. LFPN-BASED LINK PREDICTION

LFPN adopts the transitivity of friendship to explain the evolu-
tion of social networks and shows the potential friendship propa-
gation in the network. An interesting problem is, to what extent
the LFPN can model the hidden power which drives the growth of
social networks. We study this by applying LFPN in the tradition-
al link prediction problem in social networks. We formulate the
problem as follows:
LFPN based Link Prediction Problem. Given an LFPN Gt
inferred from a snapshot Gt of the evolving social network G at

67Table 2: The statistics of the datasets. V, E: number of existing nodes and edges in each dataset, S: number of egos for prediction, D:
total number of candidate friends for the egos, R: total number of candidate friendships for prediction, E/V: average degree of each
node, R/S: average candidate friendships of each ego.

V

27,348
5,667
3,804
17,615
14,751
4,425

E

72,119
60,425
13,331
78,932
27,299
59,769

S
465
45
216
601
113
167

D

21,266
3,476
3,059
14,943
11,608
3,396

R

274,817
85,447
74,189
529,623
100,717
132,803

Dataset
cond-mat
hep-ex
hep-lat
hep-ph
hep-th
nucl-ex

E/V
2.637
10.663
3.504
4.481
1.851
13.507

R/S

1,182.009
3,797.644
686.935
1,762.473
1,782.603
1,590.455

time t, our problem is to predict the new friendships in period t + 1,
i.e. ΔEt+1.

Here we don’t consider the new-coming vertices in the network.
Random Walk (RW) provides an effective node proximity measure
for predicting new links [31][1]. However, traditional RW regards
the social network as a plain graph while ignoring the motivation of
individuals. Unlike them, we predict new links based on behavior
modeling. We design a new random walk upon the LFPN, LFPN-
RW. In LFPN-RW, we treat the creation of new friendship as the
result of friendship propagation in the network. In this way, LFPN-
RW captures the co-inﬂuence effect of the friend circles on one’s
friend-making behaviors, rather than considering them as indepen-
dent events. Furthermore, the personal interests are also taken into
consideration by being incorporated within the weights of edges.

To predict the new friends of u, consider a random walker who
starts the LFPN-RW from the ego u. Then LFPN-RW operates on
the local and global layer of the LFPN successively, modeling the
2-step friend-making process. The walk on local layer allows one
to ﬁnd an intermediary ﬁrst, and to make new friends via this in-
termediary on the global layer next. The basic assumption for the
random walk on the local layer is that one should prefer the inter-
mediary whom she knows via her preferred intermediaries; and that
for the random walk on the global layer is that one should be likely
to make friends with those recommended by important people.
We introduce the process of LFPN-RW for u as follows. Firstly,
the walker goes to any vertex z ∈ GL(u) with the intermediary
u,z, and walks in GL(u) randomly. At each
preference probability wE
vertex, the walker can go to next vertex along any local LFP edge
with probability 1 − μ, or go back to the ego u with probability μ
and then restart the walk.
When the walker stops at some vertex z ∈ GL(u), before jump-
ing to the ego u, she jumps to the projection of z in the global layer
GG, and starts the random walk on GG to ﬁnd a new friend. Arriv-
ing at any vertex in GG, the walker may go to any of its neighbors
along the global LFP edges with probability 1−μ, or just stop there
with probability μ and then jump back to the ego u directly.

Before proceeding, we revise the weight deﬁnition of the edges
in LFPN to combine the global propagation probabilities and per-
sonal interests in the random walk from u:
z,v = φz,v · p(z|(cid:5)u, v(cid:6)),
wL(u)
v,y = φv,y · (cid:2)
wG(u)

(χu,c · ψc,y),

(13)

(14)

c∈C

where C is the collection of interest areas. Eq. 13 biases the local
layer using global propagation probabilities. Meanwhile, Eq. 14
biases the global layer by incorporating the personal interests, and
thus ensures that the friendship is more likely to propagate to those
with higher reputation in u’s preferred interest areas in the random
walk of u.
Let rL(u)(z) and rG(u)(v) denote the steady-state probabilities
of the random walk initialized from the ego u in GL(u) and GG(u),

respectively. They satisfy: (assuming all the weights in LFPN are
normalized)
rL(u)(z) = (1 − μ) · (cid:2)

· rL(u)(z(cid:3)) + μ · wE(u)

u,z

wL(u)
z(cid:2),z

z(cid:2)∈F (u,z)

rG(u)(v) = (1 − μ) · (cid:2)

v(cid:2)∈F (v)

(15)
v(cid:2),v · rG(u)(v(cid:3)) + μ · rL(u)(v)
wG(u)

(16)
where μ is the restart probability in the walk. rL(u)(z) can be
regarded as the probability that u will select z as the intermediary
in a friend-making behavior, and rG(u)(v) as the probability that u
decides to make friends with v ﬁnally. This can be used to predict
or recommend new friends for u.

5. EXPERIMENTAL EVALUATION

In this section, we demonstrate the effectiveness of our model
through comprehensive experiments on multiple real-world dataset-
s. We introduce our experimental settings in the ﬁrst two subsec-
tions, and afterwards present and discuss the details of the experi-
mental results.
5.1 Datasets

We construct 6 real-world datasets from Arxiv1, an archive for
electronic preprints of scientiﬁc papers in the ﬁelds of mathematics,
physics, etc. The datasets include cond-mat (Condensed Matter),
hep-ex (High Energy Physics - Experiment), hep-lat (High Energy
Physics - Lattice), hep-ph (High Energy Physics - Phenomenolo-
gy), hep-th (High Energy Physics - Theory) and nucl-ex (Nuclear
Experiment). For each dataset, we use the network evolution histo-
ry in 1998–2000 as the training set and predict the new links emerg-
ing in 2001–2003. Here we only make predictions for the egos who
have been in the network up to 1998. And then for each ego, we
select her/his 2-hop neighbors as candidate friends for prediction,
because it’s found that most of the new links connect two individ-
uals with common friends[16][1]. The statistics of the datasets are
shown in Table 2.
5.2 Baselines and Evaluation Methodology

prediction methods, which can be classiﬁed into 5 sorts.

Baselines. We compare our method with other 9 popular link
• Local neighbourhood based measures, including Jaccard Co-
efﬁcient and Adamic / Adar, two best measures reported in
[19].
• Variants of random walk based on global network structures,
including Random Walk with Restarts (RWR) [25] , SimRank
[13] and Maximum Entropy Random Walk (MERW) [4]. R-
WR measures the proximity between two nodes by the prob-
ability that one arrives at another in a random walk. SimRank

1Arxiv: http://arxiv.org/

68Table 3: The performance of various link prediction methods on the six datasets.
AdamicAdar

LaFT-Proximity

MF

Dataset

cond-mat

hep-ex

hep-lat

hep-ph

hep-th

nucl-ex

Metric
MAP
P@10
AUC
MAP
P@10
AUC
MAP
P@10
AUC
MAP
P@10
AUC
MAP
P@10
AUC
MAP
P@10
AUC

0.20119
0.08782
0.69089
0.23527
0.10001
0.65977
0.19878
0.11574
0.73988
0.17418
0.08587
0.71379
0.19384
0.06903
0.68021
0.18049
0.12216
0.71581

Jaccard
0.1743
0.07815
0.62261
0.23922
0.11556
0.6738
0.15381
0.08287
0.67935
0.16228
0.07056
0.66339
0.16609
0.06814
0.63403
0.17826
0.10599
0.67474

0.20796
0.07438
0.70027
0.23388
0.07667
0.67723
0.20324
0.09083
0.74152
0.17627
0.05775
0.72125
0.11209
0.07918
0.69231
0.22870
0.12994
0.75488

SimRank
0.12685
0.05363
0.5658
0.20722
0.12222
0.66678
0.10139
0.05046
0.61405
0.09455
0.03729
0.59292
0.09864
0.03717
0.53306
0.1858
0.11018
0.68996

0.09929
0.04761
0.53794
0.10362
0.06444
0.47561
0.06187
0.02685
0.51185
0.07149
0.04344
0.53282
0.08205
0.02655
0.51608
0.09074
0.0521
0.49876

MF-BL
0.09266
0.04524
0.50567
0.12034
0.06667
0.47822
0.08202
0.04352
0.48524
0.07835
0.06837
0.61038
0.11605
0.03982
0.51852
0.09723
0.06527
0.53021

RWR
0.25933
0.1089
0.74899
0.26752
0.08667
0.6697
0.25117
0.14444
0.78936
0.24014
0.11566
0.76727
0.25992
0.10088
0.74719
0.28525
0.16826
0.76803

MERW
0.2165
0.10901
0.59948
0.20549
0.05111
0.64236
0.19337
0.08093
0.61661
0.1994
0.09274
0.6312
0.21746
0.10133
0.60993
0.29525
0.16581
0.72169

SRW
0.26378
0.10428
0.75552
0.21131
0.08889
0.66543
0.25893
0.09028
0.80564
0.22646
0.11141
0.75767
0.23688
0.09425
0.72813
0.25826
0.18497
0.76481

LFPN-RW
0.24867
0.11191
0.76101
0.26608
0.09778
0.67919
0.27711
0.16019
0.83025
0.27212
0.12830
0.81268
0.25668
0.11239
0.78204
0.31502
0.22515
0.79627

estimates how soon two random walkers will meet each oth-
er in the graph. While both assume the graph is unweighted,
MERW assigns the propagation probabilities proportional to
the eigenvector centrality of nodes [17].
• A state-of-the-art supervised link prediction approach, Su-
pervised Random Walk (SRW) [1], which performs random
walk on a weighted graph with the weights learned as a func-
tion of features.
• Matrix Factorization methods, including the basic MF [30]
which considers the hidden features as the recommendation
of intermediaries, and an improved method, denoted as MF-
BL here, which tries to overcome the imbalance problem
[22].
• LaFT-Proximity, a proximity measure based on the LaFT-
Tree, our previous work which studies the transitivity of friend-
ship in social networks[32].

All of the above methods are based on link structures while SRW

utilizes more external features.

Evaluation Metrics. We evaluate the prediction performance of
the above algorithms using 3 metrics: MAP (Mean Average Pre-
cision), P@10 and AUC (Area Under the ROC Curve). General-
ly, MAP measures how well the algorithm ranks positive instances
above negative instances, P@10 measures the precision of the top
10 predictions given by the algorithm, and AUC measures how
well the algorithm distinguishes positive instances from negative
instances.

Parameter Settings. For LFPM, we set the default priors α0 =
β0 = 1, δ0 = γ0 = 0.1, and the number of interest areas K = 10,
as they are shown appropriate in our experiments. For each LFP-
M, we run Gibbs sampling for 20 iterations at most. The cascade
damping factor for LFPM λ = 0.5.

In LFPN-RW, RWR, MERW and SRW, we set the restart proba-
bility μ = 0.15, and the number of iterations of random walk is
limited to 100. For SimRank, we set the decay factor C = 0.8 and
the maximum number of iterations as 6, as in [13]. For MF and
MF-BL, we set the number of hidden features as 20.

For SRW, we select the Wilcoxon-Mann-Whitney (WMW) loss
function and logical edge strength function, as reported the best in
[1]. We select the two-hop neighbors of each ego as the negative
instances for that in our settings only the two-hop neighbors are
considered as the candidate friends for prediction. We apply the
gradient descent method to solve the optimization problem and the
iteration is executed at most 20 times. The features for SRW include
number of friends of the two individuals, number of their common
friends, Jaccard coefﬁcient and Adamic/Adar score.

5.3 Performance Comparison

We present the evaluation results in Table 3. As highlighted in
bold, LFPN-RW consistently outperforms other methods on most
datasets and most metrics.

LaFT-Proximity is a proximity measure based on the LaFT-Tree,
another work which tries to explain link formation using the tran-
sitivity of friendship. Though LaFT-Proximity shows better perfor-
mance than other local neighbourhood based measures, including
Jaccard and Adamic/Adar, it fails when compared with more com-
plex algorithms which can utilize more global network information.
LaFT-Proximity is always worse than our LFPN-RW, demonstrat-
ing the importance and effectiveness of modeling interests in LFPM
and capturing the co-inﬂuence of friend circles in LFPN-RW.

By utilizing the global network topological structure for proxim-
ity measure, random walk based methods, including RWR, MERW
and SRW, show better performance than other baselines. In most
occasions their performance exceeds Adamic/Adar and Jaccard,
the two best local measures reported in [19]. However, the vari-
ants of RWR, MERW and SRW, are not always better than RWR as
expected. SRW outperforms the RWR on cond-mat and hep-lat on
MAP and AUC, but becomes worse on hep-ph. MERW fails to
improve the performance of RWR on most of our datasets. Both
MERW and SRW try to weight the edges in the graph based on
the topological features; on the contrary, LFPN-RW weights the
edges by modeling the behaviors of individuals and capturing the
co-inﬂuence of friend circles based on the common user interests,
and thus achieves better improvement over RWR than MERW and
SRW. On hep-lat, hep-ph and nucl-ex, LFPN-RW achieves on av-
erage 0.04 higher AUC and 0.03 higher MAP as compared to RWR.
Furthermore, we notice that LFPN-RW is not only accurate but al-
so more stable than others. This convinces us that the LFPN can
capture the important information about the network growth and
people’s friend-making behaviors.

It is important to note that, unlike SRW which requires feature
extraction from both positive and negative instances, LFPN esti-
mates the weighted network from only the “positive instances”, and
no other features are considered.

The performance of LFPN-RW far exceeds that of MF which
tries to capture the effect of intermediary by matrix factorization,
and that of its improved version MF-BL. While in matrix factoriza-
tion we can explain the latent feature space as the intermediation
effect, these methods cannot utilize the internal relations among
individuals’ friend-making behaviors and thus the intermediation
effect cannot be modelled well.

69MAP(cid:3)VS.(cid:3)#(cid:3)TRAINING(cid:3)CASCADES

hep(cid:486)lat

nucl(cid:486)ex

AUC(cid:3)VS.(cid:3)#(cid:3)TRAINING(cid:3)CASCADES

hep(cid:486)lat

nucl(cid:486)ex

MAP(cid:3)VS.(cid:3)μ

hep(cid:486)lat

nucl(cid:486)ex

AUC(cid:3)VS.(cid:3)μ

hep(cid:486)lat

nucl(cid:486)ex

P
A
M

0.34

0.32

0.3

0.28

0.26

0.24

0

1

3

2
6
#(cid:3)TRAINING(cid:3)CASCADES

4

5

C
U
A

0.86

0.84

0.82

0.8

0.78

0.76

0

1

7

8

3

2
6
#(cid:3)TRAINING(cid:3)CASCADES

4

5

P
A
M

0.35

0.33

0.31

0.29

0.27

0.25

7

8

0.1

0.3

0.5
μ

0.7

0.9

C
U
A

0.85

0.83

0.81

0.79

0.77

0.75

0.1

0.3

0.5
μ

0.7

0.9

Figure 3: The effect of knowledge accumulation in Cascade LF-
PM on the link prediction performance of LFPN-RW.

Figure 6: The variance of link prediction performance of
LFPN-RW with different μ in LFPN-RW.

AUC(cid:3)OF(cid:3)YEARLY(cid:3)LINK(cid:3)PREDICTION

AUC(cid:3)OF(cid:3)YEARLY(cid:3)LINK(cid:3)PREDICTION

RWR

LFPN(cid:486)RW

RWR

LFPN(cid:486)RW

0.9

0.85

0.8

0.75

C
U
A

0.7

0.65

0.6

0.55

0.5

1993 1994 1995 1996 1997 1998 1999 2000 2001 2002

YEAR
(a) hep-lat

0.9

0.85

0.8

0.75

C
U
A

0.7

0.65

0.6

0.55

0.5

1995 1996 1997 1998 1999 2000 2001 2002 2003 2004

YEAR
(b) nucl-ex

Figure 4: The performance of dynamic link prediction for each
year.

MAP(cid:3)VS.(cid:3)(cid:585)

hep(cid:486)lat

nucl(cid:486)ex

AUC(cid:3)VS.(cid:3)(cid:585)

hep(cid:486)lat

nucl(cid:486)ex

0.36

0.34

0.32

P
A
M

0.3

0.28

0.26

0.24

0.1

0.3

0.5
(cid:585)

0.7

0.9

0.845

0.84

0.835

C
U
A

0.83

0.825

0.82

0.815

0.1

0.3

0.5
(cid:585)

0.7

0.9

Figure 5: The variance of link prediction performance of
LFPN-RW with different damping factor λ in Cascade LFPM.

5.4 Effect of Knowledge Accumulation

In this subsection, we study to what extent the knowledge accu-
mulation in Cascade LFPM can inﬂuence the learned LFPN and the
link prediction performance based on LFPN. We conduct this study
by three questions: (1) Does a longer training time mean more ac-
cumulated knowledge and thus promise better performance in link
prediction? (2) As time goes by, with more knowledge accumulat-
ed in cascades, will the prediction performance increase continu-
ously? (3) How should we control the amount of the accumulated
knowledge that be passed from one period to the next?

We answer the ﬁrst question by examining the performance vari-
ance of LFPN-RW on the LFPNs with different length of train-
ing time. Longer training time means more earlier knowledge is
learned and accumulated, and afterwards reﬂected in the ﬁnal LFP-
N. Fig. 3 shows the experimental results. Here we split the training
data into multiple cascades by year and each cascade corresponds
to one year. For the sake of readability we only show the results
on hep-lat and nucl-ex, and similar results are observed on other
datasets. When the number of training cascades is 0, our LFPN-RW
decays to RWR. LFPN-RW with one training cascade only utilizes

the knowledge of the current period and outperforms that with no
training cascade, i.e. RWR, on both datasets and both metrics. The
AUC of LFPN-RW increases with the number of training cascades
in the beginning, and then tends to be stable after 4 training cas-
cades. This indicates that the accumulated knowledge in the recent
time can really improve the performance; however, the knowledge
too far in the past has little effect because people’s behaviors and
interests are changing with time. This ﬁnding proves that our ap-
proach is more feasible as when only little training data are given it
can still show promising performance.

To answer the second question, we conduct dynamic link pre-
diction tasks on the datasets. For ﬁxed individuals in the ﬁrst year
in each dataset, we make yearly link prediction which predicts the
new links for the next year given the network in each year, and
study how the performance will vary. As time goes by and the
number of friends of each individual keeps growing, there will be
more candidate friendships than new emerging friendships in each
year, so it’s difﬁcult to compare the performance on a sequential
basis. Thus we compare LFPN-RW with RWR in each year. The
results are presented in Fig. 4. The curves of RWR and LFPN-RW
are quite similar on both datasets. We observe that LFPN-RW is not
only always better than RWR, but also more stable, as shown in the
more smooth curve. RWR will perform worse if there exist outliers
in the network; however, LFPN becomes increasingly robust with
continuous knowledge accumulation. Furthermore, in nucl-ex and
later time of hep-lat, we see the improvement of LFPN-RW over
RWR increases with time.

Finally, we study how we can control the extent of knowledge
accumulation by the cascade damping factor λ in LFPM inference
for better link prediction performance. The choice of λ faces the
trade-off between the knowledge learned in the new period and that
accumulated from previous models. Just think of the extreme cases.
When λ = 0, each LFPM is trained in each period independently,
without the accumulated knowledge; however, when λ = 1, all
previous knowledge is passed to the next model, with equal impor-
tance as the new knowledge. Typically, we set a higher λ when less
data is observed in the speciﬁc period. Otherwise, if we observe
sufﬁcient data for the current model, we can lower the inﬂuence
of the previous models on the current one by setting a smaller λ.
When evaluating on real data we observe that λ plays an important
role in the cascade inference procedure. For the sake of readability,
we only show some representative curves in Fig. 5. We can see λ
in the range from 0.3 to 0.5 seems to be most appropriate.

5.5 Effect of Co-inﬂuence of Friend Circles

In LFPN-RW, we treat the creation of a new friendship as a result
of friendship propagation in the network and model the link predic-
tion as a random walk upon the LFPN, taking the co-inﬂuence ef-

70MAP(cid:3)ON(cid:3)EACH(cid:3)DATASET

AUC(cid:3)ON(cid:3)EACH(cid:3)DATASET

With(cid:3)Interest(cid:3)Awareness Without(cid:3)Interest(cid:3)Awareness
0.35

With(cid:3)Interest(cid:3)Awareness Without(cid:3)Interest(cid:3)Awareness
0.85

0.3

P
A
M

0.25

0.2

0.15

cond(cid:486)mat hep(cid:486)ex

0.8

C
U
A

0.75

0.7

0.65

cond(cid:486)mat hep(cid:486)ex

hep(cid:486)th

nucl(cid:486)ex

hep(cid:486)lat

hep(cid:486)ph

DATASET

hep(cid:486)th

nucl(cid:486)ex

hep(cid:486)lat

hep(cid:486)ph

DATASET

MAP(cid:3)VS.(cid:3)#(cid:3)ITERATIONS IN(cid:3)LFPM

hep(cid:486)lat

nucl(cid:486)ex

AUC(cid:3)VS.(cid:3)#(cid:3)ITERATIONS(cid:3)IN(cid:3)LFPM

hep(cid:486)lat

nucl(cid:486)ex

P
A
M

0.46

0.44

0.42

0.4

0.38

0.36

0.34

0.32

0.3

2

4

6

10 12 14 16 18 20

8
#(cid:3)ITERATIONS

0.9

0.88

0.86

C
U
A

0.84

0.82

0.8

0.78

2

4

6

10 12 14 16 18 20

8
#(cid:3)ITERATIONS

Figure 7: Comparison of link prediction performance of LFPN-
RW with/without interest awareness.

Figure 8: The variance of link prediction performance of
LFPN-RW with increasing number of iterations in LFPM.

fect of the friend circles on one’s friend-making behaviors into con-
sideration naturally. In this subsection we study how we can beneﬁt
from the co-inﬂuence effect.
In the LFPN-RW, the restart prob-
ability μ controls how “far” the walker wanders on the network;
a smaller value allows the walker to walk farther and increases the
co-inﬂuence of the friend circles on one’s friend-making behaviors,
and a larger value enhances the direct inﬂuence of one’s current
friends. As shown in Fig. 6, in our evaluations we see the lower
value of μ tends to achieve better performance. This demonstrates
the importance of the co-inﬂuence captured in our LFPN-RW. Fur-
thermore, the performance will decrease if μ < 0.3 because the
direct inﬂuence from the current friends is reduced too much. To
achieve better performance, one needs to make trade-off between
the inﬂuence from current friends and the co-inﬂuence of friend
circles in speciﬁc networks.
5.6 Effect of Interest Awareness

In LFPM and LFPN-RW, we assume that the creation of friend-
ship is the result of friendship propagation, which would be inﬂu-
enced by both the transitivity of friendship and the personal inter-
ests. In this subsection, we investigate how personal interests will
inﬂuence the link prediction performance. We remove the interest
factors, including χ and ψ, from LFPM and LFPN-RW, and get a
new algorithm denoted by LFPN-RW without Interest Awareness.
Correspondingly, our original algorithm can be denoted by LFPN-
RW with Interest Awareness. We compare the performance of the
new algorithm with our original algorithm on all the datasets and
the results are shown in Fig. 7. We can see the latter outperforms
the former on most datasets. It should be noted that we don’t intro-
duce external personal proﬁles to learn the personal interests. This
convinces us that the personal interests can be well captured from
the social behaviors of the individuals and the topological struc-
ture of the network, and furthermore can beneﬁt the link prediction
using LFPN-RW, i.e. the LFPN-RW with Interest Awareness here,
which models the friendship propagation with interest awareness.
5.7 Convergence Analysis

In this subsection we study the convergence speed of our LFPM

inference and LFPN-RW.

In Fig. 8 we investigate how the performance of LFPN-RW varies
with the number of iterations of LFPM. From the two representative
curves on hep-lat and nucl-ex, we see the performance increases
quickly, and then LFPM converges in nearly 15 iterations.

Fig. 9 shows the performance variance with the number of iter-
ations in LFPN-RW. Experimental results on hep-lat and nucl-ex
demonstrate the LFPN-RW converges in about 30 iterations.

6. RELATED WORK

Link prediction is a classical problem which attracts many at-

MAP(cid:3)VS.(cid:3)#(cid:3)ITERATIONS(cid:3)IN(cid:3)LAFT(cid:486)RW

AUC(cid:3)VS.(cid:3)#(cid:3)ITERATIONS(cid:3)IN(cid:3)LAFT(cid:486)RW

hep(cid:486)lat

nucl(cid:486)ex

hep(cid:486)lat

nucl(cid:486)ex

P
A
M

0.33

0.32

0.31

0.3

0.29

0.28

0.27

0.26

0.25

5

10 15 20 25 30 35 40 45 50

#(cid:3)ITERATIONS(cid:3)

0.85

0.845

0.84

0.835

C
U
A

0.83

0.825

0.82

0.815

0.81

5

10 15 20 25 30 35 40 45 50

#(cid:3)ITERATIONS

Figure 9: The variance of link prediction performance of
LFPN-RW with increasing number of iterations in LFPN-RW.

tentions. The general approach for link prediction is based on the
proximity measuring in the network. One branch of this method
is based on the local neighbourhood structures, such as common
neighbors, Jaccard coefﬁcient and Adamic/Adar, all of which were
surveyed by Liben-Nowell and Kleinberg [19]. Another popular
approach utilizes the random walk to measure the node proximity
on the whole network, including Random Walk with Restarts (R-
WR) [25], SimRank [13] and Katz [14]. Approaches have also been
proposed to improve the traditional random walk by adjusting the
transition probabilities , including randomized shortest-path (RSP)
dissimilarity [29] and Maximum Entropy Random Walk(MERW)
[4][17]. Supervised Random Walk(SRW) was proposed to learn the
transition probabilities with a supervised method [1]. However, su-
pervised methods face the imbalance problem [20][22] and require
elaborate feature extraction; on the contrary, our LFPN-RW models
personal behaviors depending only on the positive instances. Fur-
thermore, we identify personal interests from their social relations
only, without other node-speciﬁc attributes.

It’s also interesting to study how the network evolves [16] and
how people make friends [12]. Researchers have found many in-
teresting patterns, such as preferential attachment [23], triadic clo-
sure [27], reciprocity[24][11] and homophily [5]. The transitivity of
friendship has been noticed long ago [26][28] and used to explain
the phenomenon of triadic closure in social networks [15]. Recent-
ly, the role of triadic closure in the link formation in social networks
was further veriﬁed [7][27][3][6]. However, it hasn’t been studied
that how the triadic closure and the transitivity of friendship drive
the microscopic evolution of social networks. Yin et al. proposed
a matrix factorization approach for link prediction by considering
the hidden features as the recommendation of intermediaries [30].
Their work is a bit similar with ours; however, they ignore the se-
quential relationship among the social behaviors and cannot model
the actual contribution of each intermediary on the link formation.
Our previous work [32] primarily focuses on how to capture the
expansion traces of one’s social network. It does not explore the

71dimension of personal interest and model its impact on network
expansion. Neither does it utilize the concept of friend circles to
capture the co-inﬂuence effect of one’s friends based on interest
awareness as in our paper.

7. CONCLUSION

Modeling people’s social behaviors and furthermore understand-
ing their motivations are important for us to know how the social
network emerges, evolves and vanishes eventually, as the people
are the dominant players in social networks.
In this paper, we
model people’s friend-making behaviors using the LFPM, a gen-
erative model driven by the famous sociological principle of the
transitivity of friendship and personal interests. The inferred LFP-
N incorporates rich knowledge about the patterns of individuals’s
behaviors and the growth potentials of the social network, with the
co-inﬂuence of friend circles and personal interest well modeled.
Furthermore, we propose LFPN-RW, which treats the link predic-
tion task as a random walk on the LFPN, guided by the interest-
aware friendship propagation. Our approach achieves promising
performance in experimental studies, which leads us to draw the
conclusion that the transitivity of friendship really plays important
roles in the evolution of social networks and can be utilized to ana-
lyze the network evolution if well modeled with interest awareness.

8. ACKNOWLEDGMENTS

We would like to thank the anonymous reviewers for their valu-
able comments and suggestions to improve this paper. This work
is supported in part by the National Natural Science Foundation of
China (No. 61170064, No. 61073005, No. 61133002), the Nation-
al High Technology Research and Development Program of Chi-
na (No. 2012AA011002), US NSF through grants IIS-0905215,
CNS-1115234, IIS-0914934, DBI-0960443, and OISE-1129076,
and Huawei grant.
9. REFERENCES
[1] L. Backstrom and J. Leskovec. Supervised random walks:
predicting and recommending links in social networks. In
WSDM ’11, pages 635–644, 2011.

[2] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet

allocation. J. Mach. Learn. Res., 3:993–1022, Mar. 2003.

[3] M. J. Brzozowski and D. M. Romero. Who should I follow?

recommending people in directed social networks. In
ICWSM’11, 2011.

[4] Z. Burda, J. Duda, J. M. Luck, and B. Waclaw. Localization

of the maximal entropy random walk. Phys Rev Lett,
102(16):160602, 2009.

[5] M. De Choudhury. Tie formation on twitter: Homophily and
structure of egocentric networks. In SocialCom/PASSAT ’11,
pages 465 –470, 2011.

[6] M. Doroud, P. Bhattacharyya, S. F. Wu, and D. Felmlee. The

evolution of ego-centric triads: A microscopic approach
toward predicting macroscopic network properties. In
SocialCom/PASSAT ’11, pages 172 –179, 2011.

[7] S. A. Golder and S. Yardi. Structural predictors of tie

formation in twitter: Transitivity and mutuality. In
SocialCom/PASSAT ’10, pages 88–95, 2010.

[8] M. S. Granovetter. The Strength of Weak Ties. The American

Journal of Sociology, 78(6):1360–1380, 1973.

[9] M. A. Hasan, V. Chaoji, S. Salem, and M. Zaki. Link

prediction using supervised learning. In SDM ’06 workshop
on Link Analysis, Counterterrorism and Security, 2006.

[10] G. Heinrich. Parameter estimation for text analysis. Version

2.9, Fraunhofer IGD, 2009.

[11] J. Hopcroft, T. Lou, and J. Tang. Who will follow you back?:

reciprocal relationship prediction. In CIKM ’11, 2011.

[12] H. Hu and X. Wang. How people make friends in social
networking sites - a microscopic perspective. Physica A:
Statistical Mechanics and its Applications, 391(4):1877 –
1886, 2012.

[13] G. Jeh and J. Widom. Simrank: a measure of

structural-context similarity. In KDD ’02, 2002.

[14] L. Katz. A new status index derived from sociometric

analysis. Psychometrika, 18:39–43, 1953.

[15] D. Krackhardt and M. S. Handcock. Heider vs simmel:

emergent features in dynamic structures. In ICML’06, 2006.

[16] J. Leskovec, L. Backstrom, R. Kumar, and A. Tomkins.

Microscopic evolution of social networks. In KDD ’08, 2008.

[17] R.-H. Li, J. X. Yu, and J. Liu. Link prediction: the power of

maximal entropy random walk. In CIKM ’11, 2011.

[18] D. Liben-Nowell and J. Kleinberg. The link prediction

problem for social networks. In CIKM ’03, 2003.

[19] D. Liben-Nowell and J. Kleinberg. The link-prediction

problem for social networks. J. Am. Soc. Inf. Sci. Technol.,
58(7), 2007.

[20] R. N. Lichtenwalter, J. T. Lussier, and N. V. Chawla. New
perspectives and methods in link prediction. In KDD ’10,
2010.

[21] M. McPherson, L. Smith-Lovin, and J. M. Cook. Birds of a
feather: Homophily in social networks. ANNUAL REVIEW
OF SOCIOLOGY, 27:415–444, 2001.

[22] A. K. Menon and C. Elkan. Link prediction via matrix

factorization. In ECML PKDD’11, 2011.

[23] M. E. J. Newman. Clustering and preferential attachment in

growing networks. PHYS.REV.E, 64:025102, 2001.

[24] V.-A. Nguyen, E.-P. Lim, H.-H. Tan, J. Jiang, and A. Sun. Do

you trust to get trust? a study of trust reciprocity behaviors
and reciprocal trust prediction. In SDM ’10, 2010.

[25] J.-Y. Pan, H.-J. Yang, C. Faloutsos, and P. Duygulu.

Automatic multimedia cross-modal correlation discovery. In
KDD ’04, pages 653–658, 2004.

[26] A. Rapoport. Spread of information through a population

with socio-structural bias: I. assumption of transitivity.
Bulletin of Mathematical Biology, 15:523–533, 1953.

[27] D. M. Romero and J. Kleinberg. The directed closure process

in hybrid social-information networks, with an analysis of
link formation on twitter. In ICWSM ’10, 2010.

[28] G. Simmel and K. H. Wolff. The Sociology of Georg Simmel.

Free Press, 1964.

[29] L. Yen, M. Saerens, A. Mantrach, and M. Shimbo. A family
of dissimilarity measures between nodes generalizing both
the shortest-path and the commute-time distances. In KDD
’08, 2008.

[30] D. Yin, L. Hong, and B. D. Davison. Structural link analysis

and prediction in microblogs. In CIKM ’11, 2011.

[31] Z. Yin, M. Gupta, T. Weninger, and J. Han. A uniﬁed

framework for link recommendation using random walks. In
ASONAM ’10, pages 152–159, 2010.

[32] J. Zhang, C. Wang, J. Wang, and P. S. Yu. LaFT-Tree:

Perceiving the expansion trace of one’s circle of friends in
online social networks. In WSDM ’13, 2013.

72