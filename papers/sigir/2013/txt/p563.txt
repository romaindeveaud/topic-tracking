Query Expansion Using Path-Constrained Random Walks 

 
 

Jianfeng Gao 

 
 

Gu Xu 

 
 

Jinxi Xu 

Microsoft Research, Redmond  

Washington 98052, USA 
jfgao@microsoft.com 

Microsoft Bing, Bellevue  
Washington 98004, USA 
guxu@microsoft.com 

Microsoft Bing, Bellevue  
Washington 98004, USA 
jinxixu@microsoft.com 

 

ABSTRACT 
This paper exploits Web search logs for query expansion (QE) by 
presenting  a  new  QE  method  based  on  path-constrained  random 
walks (PCRW), where the search logs are represented as a labeled, 
directed graph, and the probability of picking an expansion term 
for an input query is computed by a learned combination of con-
strained random walks on the graph. The method is shown to be 
generic in that it covers most of the popular QE models as special 
cases  and  flexible  in  that  it  provides  a  principled  mathematical 
framework in which a wide variety of information useful for QE 
can be incorporated in a unified way. Evaluation is performed on 
the Web document ranking task using a real-world data set. Re-
sults show that the PCRW-based method is very effective for the 
expansion  of  rare  queries,  i.e.,  low-frequency  queries  that  are 
unseen in search logs, and that it outperforms significantly other 
state-of-the-art QE methods. 
Categories and Subject Descriptors 
H.3.3 [Information Storage and Retrieval]: Information Search 
and Retrieval; I.2.6 [Artificial Intelligence]: Learning 
General Terms 
Algorithms, Experimentation 
Keywords 
Search Log, Query Expansion, Random Walk, Path Ranking Al-
gorithm, Web Search 

1.  INTRODUCTION 
Term  mismatch  is  one  of  the  fundamental  challenges  in  Web 
search, where a query and its relevant documents are often com-
posed  using  different  vocabularies  and  language  styles.  Query 
expansion (QE) is an effective strategy to address the challenge. It 
expands  a  query  issued  by  a  user  with  additional  related  terms, 
called  expansion  terms,  so  that more  relevant  documents  can  be 
retrieved. 

QE  is  a  long-standing  research  topic  in  information  retrieval 
(IR).  The  methods  based  on  automatic  relevance  feedback  (e.g., 
explicit  feedback  and  pseudo  relevance  feedback  (PRF))  have 

 
Permission  to  make  digital  or  hard  copies  of  all  or  part  of  this  work  for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that copies 
bear this notice and the full citation on the first page. Copyrights for com-
ponents  of  this  work  owned  by  others  than  ACM  must  be  honored.  Ab-
stracting with credit is permitted. To copy otherwise, or republish, to post 
on  servers  or  to  redistribute  to  lists,  requires  prior  specific  permission 
and/or a fee. Request permissions from permissions@acm.org. 
SIGIR’13, July 28–August 1, 2013, Dublin, Ireland. 
Copyright © 2013 ACM  978-1-4503-2034-4/13/07…$15.00. 

been proved to be useful for improving the performance of IR on 
TREC datasets [10, 11, 34, 36, 36, 45, 48]. However, these meth-
ods cannot be applied directly to a commercial Web search engine 
because the relevant documents are not always available and gen-
erating pseudo-relevant documents requires multi-phase retrieval, 
which is prohibitively expensive. 

Recent  studies  demonstrate  the  success  of  exploiting  search 
logs  (i.e.,  clickthrough  data)  for  QE  [7,  14,  15,  19,  22,  41,  42]. 
These methods, called log-based QE, also derive expansion terms 
for a query from its (pseudo-)relevant document set. But, different 
from  the  methods  based  on  automatic  relevance  feedback,  the 
relevant  document  set  is  identified  by  user  clicks  recorded  in 
search logs. For example, the set of (pseudo-)relevant documents 
of  an  input  query  can  be  formed  by  including  the  documents 
which  have  been  previously  clicked  for  the  query  or  its  similar 
queries [1, 7, 46]. Most state-of-the-art log-based QE methods use 
a  global  model  that  is  pre-computed  from  search  logs  [14,  19]. 
The model captures the correlation between query terms and doc-
uments terms and can be used to generate expansion terms for the 
input query on the fly. Despite the effectiveness of log-based QE 
methods, they suffer from two problems. First is data sparseness. 
A large portion of queries have very few or no click in search logs, 
as stated by Zipf’s law. Second is the ambiguity of search intent. 
For example, a term correlation model may fail to distinguish the 
search intent of the query term “book” in “school book” from that 
in “hotel booking”. Although the problem can be partially allevi-
ated by using the improved correlation models based on phrases 
and concepts [19], there are plenty of cases where the search in-
tent can only be identified correctly via global context. For exam-
ple, the query “why 6 bottles in one wrap” is about package, and 
the intent of the query “acme baked bread” is to look for the bak-
ery in CA. In such cases, a (pseudo-)relevant document set of an 
input  query,  if  available,  is  more  likely  to  preserve  the  original 
search intent than any pre-computed global correlation model. 

In this paper we address the two problems by proposing a new 
log-based  QE  method  based  on  path-constrained  random  walks 
[32].  We  represent  the  search  logs,  consisting  of  billions  of 
clicked query-document pairs, as a labeled, directed graph, where 
there are three types of nodes,  representing respectively queries, 
documents,  and words  (i.e., candidate expansion  terms), and the 
edges between nodes are labeled by relations. An example graph, 
which will be described in detail in Section 3.1, is shown in Fig-

ure 1.  For each path in the graph that links the input query (cid:1843) to a 
candidate expansion term (cid:1875), there is a path type (cid:2024), defined by a 
ticular process of generating (cid:1875) from (cid:1843), and the generation proba-
bility (cid:1842)(cid:4666)(cid:1875)|(cid:1843),(cid:2024)(cid:4667) is  computed  by  random  walks  along  the  paths 
that  instantiate  the  path  type (cid:2024),  as  known  as  path-constrained 

sequence of edge labels. Each path type can be viewed as a par-

random  walks  (PCRW).  Many  log-based  QE  models  proposed 

563previously can be formulated in the framework of PCRW by de-
fining  particular  path  types.  For  example,  the  method  based  on 

(cid:1731)(cid:1871)(cid:1861)(cid:1865)(cid:1861)(cid:1864)(cid:1853)(cid:1870)_(cid:1843)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1830)2(cid:1875)(cid:1732). 

relevance  feedback,  where  the  pseudo-relevant  documents (cid:1830) are 
defined  as  the  ones  that  have  clicks  for  the  input  query (cid:1843) or  its 
similar queries (cid:1843)(cid:1314), can be presented using the following path type 
 (cid:1871)(cid:1861)(cid:1865)(cid:1861)(cid:1864)(cid:1853)(cid:1870)_(cid:1843)2(cid:1843)(cid:1314)  .  The  second  follows  any  edges  labeled  by 
(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830) .  The 
(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1830)2(cid:1875). These relations are summarized in Table 1, and 

This is a three-step random walk. The first step retrieves similar 
queries  by  a  random  walk  on  edges  labeled  by  the  relation 

follows  any  edges 

labeled  by 

third 

 

will be described in detail in Section 3. 

We  will  show  that  PCRW  provides  a  generic  and  flexible 
modeling framework in that it not only covers most of the popular 
log-based QE models as special cases, but also allows us to devise 
new QE models that can potentially use much richer information 
than that of previous models. For example, we can define a rich 
set  of  walk  behaviors  that  support  a  variety  of  labeled  edges 
where different information can be used at different stages of the 
walk. Some examples will be presented in Section 3.2. 

Moreover, because different QE methods often rely on differ-
ent  sources  and  are  potentially  complimentary,  it  is  desirable  to 
combine  them  to  address  data  sparseness  and  help  disambiguate 
search intent. For example, while the automatic feedback methods 
using (pseudo-)relevant documents are good to retain search intent 
but  suffer  from  data  sparseness  especially  for  rare  queries,  the 
methods based on global term correlation models can be applied 
equally well to both common and rare queries but, due to the lim-
ited  context  information  it  captures,  may  lead  to  an  unexpected 
shift of search intent. We will show that PCRW provides a flexi-
ble mathematical framework in which different QE features, spec-

ified by path types (cid:2024), can be incorporated in a unified way. For-
(cid:1875) for a given (cid:1843), (cid:1842)(cid:4666)(cid:1875)|(cid:1843)(cid:4667), is computed by a learned combination 
of  path-constrained  random  walks  on  the  graph,  i.e., (cid:1842)(cid:4666)(cid:1875)|(cid:1843)(cid:4667)(cid:3404)
∑
(cid:2019)(cid:3095)(cid:1842)(cid:4666)(cid:1875)|(cid:1843),(cid:2024)(cid:4667)
,  where (cid:2019)(cid:3095)(cid:1314)(cid:1871)  are  the  combination  weights 
(cid:3095)(cid:1488)(cid:3003)

mally, in the PCRW-based QE method the probability of picking 

learned on training data.   

Our experiments (Section 4) show that the use of PCRW not 
only makes QE robust to data sparseness but also help disambigu-
ate search intents, leading to a significant improvement over pre-
vious state-of-the-art QE methods. 

In the rest of the paper, Section 2 reviews briefly PCRW. Sec-
tion 3 describes in detail the PCRW-based QE method. Sections 4 
and  5  present  experiments  and  related  work,  respectively.  The 
paper is concluded in Section 6. 

2.  PRELIMINARIES 
This  section  briefly  reviews  the  path-constrained  random  walk 
model. Readers are referred to [32] for a more detailed treatment. 
The model used in this study is a variant of the one described in 
[32, 33]. Modifications are made for the QE task. 

Consider a directed, labeled graph (cid:1833)(cid:3404)(cid:4666)(cid:1829),(cid:1846)(cid:4667) where (cid:1846)(cid:1603)(cid:1829)(cid:3400)
(cid:1844)(cid:3400)(cid:1829) is the set of labeled edges (also known as triples) (cid:4666)(cid:1855),(cid:1870),(cid:1855)(cid:1314)(cid:4667). 
Each  triple  represents  an  instance (cid:1870)(cid:4666)(cid:1855),(cid:1855)(cid:4593)(cid:4667) of  the  relation (cid:1870)(cid:1488)(cid:1844). 
duce for each relation (cid:1870) a separate probabilistic model (cid:2016)(cid:3045) , which 
of reaching (cid:1855)’ from (cid:1855) with a one-step random walk with edge type 
(cid:1870), (cid:1842)(cid:4666)(cid:1855)’|(cid:1855),(cid:2016)(cid:3045)(cid:4667).  In  Section  3  we  will  see  how  the  use  of  relation-

is used to assign a score to the edge. The score is the probability 

For the QE task considered in this study it will be useful to intro-

 

 

Figure 1. Search logs as a graph 

Each  path  type  specifies  a  real-value  feature.  For  a  given  node 

known as a path-constrained random walk. Specifically, suppose 

specific  models allows  us  to  build  significantly more  expressive 
QE models.  

A path type in (cid:1833) is a sequence (cid:2024)(cid:3404)(cid:1731)(cid:1870)(cid:2869),…,(cid:1870)(cid:3040)(cid:1732). An instance of 
the path type is sequence of nodes (cid:1855)(cid:2868),…,(cid:1855)(cid:3040) such that (cid:1870)(cid:3036)(cid:4666)(cid:1855)(cid:3036)(cid:2879)(cid:2869),(cid:1855)(cid:3036)(cid:4667). 
pair (cid:4666)(cid:1871),(cid:1872)(cid:4667), where (cid:1871) is source node and (cid:1872) is target node, the value 
of  the  feature (cid:2024) is (cid:1842)(cid:4666)(cid:1872)|(cid:1871),(cid:2024)(cid:4667),  i.e.,  the  probability  of  reaching (cid:1872) 
from (cid:1871) by  a  random  walk  that  instantiates  the  path  type,  also 
that  the  random  walk  has  just  reached (cid:1855)(cid:3036) by  traversing  edges  la-
beled   (cid:1870)(cid:2869),…,(cid:1870)(cid:3036) with (cid:1843)(cid:3404)(cid:1855)(cid:2868).  Then (cid:1855)(cid:3036)(cid:2878)(cid:2869) is  drawn  at  random,  ac-
cording to (cid:2016)(cid:3045)(cid:3284)(cid:3126)(cid:3117) , from all nodes reachable by edges labeled (cid:1870)(cid:3036)(cid:2878)(cid:2869). 
A path type (cid:2024) is active for pair (cid:4666)(cid:1871),(cid:1872)(cid:4667) if (cid:1842)(cid:4666)(cid:1872)|(cid:1871),(cid:2024)(cid:4667)(cid:3408)0. 
Let (cid:1828)(cid:3404)(cid:4668)(cid:1635),(cid:2024)(cid:2869),…,(cid:2024)(cid:3041)(cid:4669) be the set of all path types of length no 
greater  than (cid:1864) that  occur  in  the  graph  together  with  the  dummy 
type (cid:1635),  which  represents  the  bias  feature.  It  is  convenient  to  set 
(cid:1842)(cid:4666)(cid:1872)|(cid:1871),(cid:1635)(cid:4667)(cid:3404)1 for any nodes (cid:1871), (cid:1872). The score of whether target node 
(cid:1872) is related to source node (cid:1871) is given by 
(cid:1842)(cid:4666)(cid:1872)|(cid:1871)(cid:4667)(cid:3404)(cid:3533)(cid:2019)(cid:3095)(cid:1842)(cid:4666)(cid:1872)|(cid:1871),(cid:2024)(cid:4667)
, 
where (cid:2019)(cid:3095) is the weight of feature (cid:2024). The model parameters to be 
learned are the vector (cid:2245)(cid:3404)(cid:1731)(cid:2019)(cid:3095)(cid:1732)(cid:3095)(cid:1488)(cid:3003). The construction of (cid:1828) and the 
estimation  of (cid:2245) are  application  specific.  For  the  QE  task  source 
node  is  the  input  query  to  be  expanded (cid:1843) and  target  node  is  a 
candidate expansion term (cid:1875). Thus, Equation (1) gives the proba-
bility of whether (cid:1875) is a good expansion term of (cid:1843). This is the QE 

(cid:3095)(cid:1488)(cid:3003)

(1) 

model we will describe in detail in Section 3. 

3.  PCRW-BASED QE MODEL 
3.1  Search Logs as a Graph 
The  search  logs  used  in  this  study  consist  of  a  list  of  query-
document pairs, also known as clickthrough data. Each pair con-
tains a query and a document which has one or more user clicks 

for the query. We represent the search logs as a graph (cid:1833)(cid:3404)(cid:4666)(cid:1829),(cid:1846)(cid:4667), 
and documents. While a query in the search logs, denoted by (cid:1843)’, 
denoted  by (cid:1843) ,  could  be  a  new,  low-frequency  query  without 
paper. (cid:1843) and (cid:1843)(cid:1314) are treated as different nodes in (cid:1833). 

as shown in Figure 1. We define three types of nodes to represent 
respectively queries, documents, and words that occur in queries 

clicked  documents.  Such  a  query  is  called  a  rare  query  in  this 

always has clicked document(s), an input query to be expanded, 

 
 

564 

 

 

 

 

 

 

10 

11 

12 

13 

14 

Scoring function 

1 

2 

3 

4 

5 

6 

7 

8 

9 

cosine similarity between the term vectors of (cid:1843) and (cid:1843)’, where term weights are assigned using the BM25 function.  
log(cid:3537) (cid:3533) (cid:1842)(cid:3047)(cid:3040)(cid:4666)(cid:1869)(cid:4593)|(cid:1869)(cid:4667)(cid:1872)(cid:1858)(cid:4666)(cid:1869);(cid:1843)(cid:4667)
|(cid:1843)|
(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)(cid:4666)(cid:1843),(cid:1830)(cid:4667)
(cid:3044)(cid:4593)(cid:1488)(cid:3018)(cid:4593)
(cid:3044)(cid:1488)(cid:3018)
log(cid:1842)(cid:4666)(cid:1830)|(cid:1843)(cid:4667)(cid:3404)log
∑
(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)(cid:4666)(cid:1843),(cid:1830)(cid:3036)(cid:4667)
(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)(cid:4666)(cid:1843),(cid:1830)(cid:4667)
(cid:3005)(cid:3284)(cid:1488)(cid:1778)
log(cid:1842)(cid:4666)(cid:1843)|(cid:1830)(cid:4667)(cid:3404)log
∑
(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)(cid:4666)(cid:1843)(cid:3036),(cid:1830)(cid:4667)
log(cid:3437)(cid:4666)1(cid:3398)(cid:2009)(cid:4667)(cid:1872)(cid:1858)(cid:4666)(cid:1875);(cid:1843)(cid:4667)
|(cid:1843)| (cid:3397)(cid:2009)(cid:1855)(cid:1858)(cid:4666)(cid:1875)(cid:4667)
(cid:3018)(cid:3284)(cid:1488)(cid:1791)
|(cid:1829)| (cid:3441) 
log(cid:3533) (cid:1842)(cid:3047)(cid:3040)(cid:4666)(cid:1875)|(cid:1869)(cid:4667)(cid:1872)(cid:1858)(cid:4666)(cid:1869);(cid:1843)(cid:4667)
|(cid:1843)|
(cid:3044)(cid:1488)(cid:3018)
log(cid:3437)(cid:4666)1(cid:3398)(cid:2009)(cid:4667)(cid:1872)(cid:1858)(cid:4666)(cid:1875);(cid:1843)(cid:4593)(cid:4667)
|(cid:1843)(cid:4593)| (cid:3397)(cid:2009)(cid:1855)(cid:1858)(cid:4666)(cid:1875)(cid:4667)
|(cid:1829)| (cid:3441) 
log(cid:3533) (cid:1842)(cid:3047)(cid:3040)(cid:4666)(cid:1875)|(cid:1869)(cid:1314)(cid:4667)(cid:1872)(cid:1858)(cid:4666)(cid:1869)(cid:1314);(cid:1843)(cid:1314)(cid:4667)
|(cid:1843)(cid:1314)|
(cid:3044)(cid:4593)(cid:1488)(cid:3018)(cid:4593)
(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)(cid:4666)(cid:1843)(cid:4593),(cid:1830)(cid:4667)
log(cid:1842)(cid:4666)(cid:1830)|(cid:1843)(cid:4593)(cid:4667)(cid:3404)log
∑
(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)(cid:4666)(cid:1843)(cid:4593),(cid:1830)(cid:3036)(cid:4667)
(cid:3005)(cid:3284)(cid:1488)(cid:1778)
log(cid:3437)(cid:4666)1(cid:3398)(cid:2010)(cid:4667)(cid:1872)(cid:1858)(cid:4666)(cid:1875);(cid:1830)(cid:4667)
|(cid:1830)| (cid:3397)(cid:2010)(cid:1855)(cid:1858)(cid:4666)(cid:1875)(cid:4667)
|(cid:1829)| (cid:3441) 
log(cid:3533) (cid:1842)(cid:3047)(cid:3040)(cid:4666)(cid:1875)|(cid:1875)(cid:3036)(cid:4667)(cid:1872)(cid:1858)(cid:4666)(cid:1875)(cid:3036);(cid:1830)(cid:4667)
|(cid:1830)|
(cid:3050)(cid:3284)(cid:1488)(cid:3005)
(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)(cid:4666)(cid:1843)(cid:4593),(cid:1830)(cid:4667)
log(cid:1842)(cid:4666)(cid:1843)(cid:4593)|(cid:1830)(cid:4667)(cid:3404)log
∑
(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)(cid:4666)(cid:1843)(cid:3036)(cid:4593),(cid:1830)(cid:4667)
(cid:3018)(cid:3284)(cid:4594)(cid:1488)(cid:1791)
(cid:1842)(cid:3039)(cid:3040)(cid:4666)(cid:1875)|(cid:1830)(cid:4667)(cid:1842)(cid:4666)(cid:1830)(cid:4667)
log(cid:1842)(cid:4666)(cid:1830)|(cid:1875)(cid:4667)(cid:3404)log
(cid:1842)(cid:3039)(cid:3040)(cid:4666)(cid:1875)|(cid:1830)(cid:3036)(cid:4667)(cid:1842)(cid:4666)(cid:1830)(cid:3036)(cid:4667)
∑
(cid:3005)(cid:3284)(cid:1488)(cid:1778)
(cid:1842)(cid:3039)(cid:3040)(cid:4666)(cid:1875)|(cid:1843)(cid:1314)(cid:4667)(cid:1842)(cid:4666)(cid:1843)(cid:1314)(cid:4667)
log(cid:1842)(cid:4666)(cid:1843)(cid:4593)|(cid:1875)(cid:4667)(cid:3404)log
(cid:1842)(cid:3039)(cid:3040)(cid:4666)(cid:1875)|(cid:1843)(cid:3036)(cid:4667)(cid:1842)(cid:4666)(cid:1843)(cid:4667)
∑
(cid:3018)(cid:3284)(cid:4594)(cid:1488)(cid:1791)

ID  Relation (cid:2200) 
(cid:1871)(cid:1861)(cid:1865)(cid:1861)(cid:1864)(cid:1853)(cid:1870)_(cid:1843)2(cid:1843)’ 
(cid:1872)(cid:1870)(cid:1853)(cid:1866)(cid:1871)(cid:1864)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)2(cid:1843)(cid:1314) 
(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)2(cid:1830) 
(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1830)2(cid:1843) 
(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)2(cid:1875) 
(cid:1872)(cid:1870)(cid:1853)(cid:1866)(cid:1871)(cid:1864)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)2(cid:1875) 
(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)(cid:1314)2(cid:1875) 
(cid:1872)(cid:1870)(cid:1853)(cid:1866)(cid:1871)(cid:1864)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)(cid:1314)2(cid:1875) 
(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830) 
(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1830)2(cid:1875) 
(cid:1872)(cid:1870)(cid:1853)(cid:1866)(cid:1871)(cid:1864)(cid:1853)(cid:1872)(cid:1857)_(cid:1830)2(cid:1875) 
(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1830)2(cid:1843)(cid:1314) 
 and (cid:1842)(cid:4666)(cid:1830)(cid:4667)(cid:3404)∑
(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)(cid:4666)(cid:1843),(cid:1830)(cid:4667)
|(cid:1830)| (cid:3397)(cid:2010)(cid:1855)(cid:1858)(cid:4666)(cid:1875)(cid:4667)
(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1875)2(cid:1830) 
|(cid:1829)|
(cid:3018)(cid:1488)(cid:1791) (cid:1840)
|(cid:1843)| (cid:3397)(cid:2009)(cid:1855)(cid:1858)(cid:4666)(cid:1875)(cid:4667)
|(cid:1829)| and (cid:1842)(cid:4666)(cid:1843)(cid:4667)(cid:3404)∑
(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)(cid:4666)(cid:1843),(cid:1830)(cid:4667)
(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1875)2(cid:1843)(cid:1314) 
(cid:3005)(cid:1488)(cid:1778) (cid:1840)
Table 1: Relations and their scoring functions used in the graph in Figure 1. Here, (cid:2202)(cid:2188)(cid:4666)(cid:2199);(cid:2173)(cid:4667) is the number of times term q occurs 
in query (cid:2173), and |(cid:2173)| is the length of query (cid:2173). (cid:2202)(cid:2188)(cid:4666)(cid:2205);(cid:2160)(cid:4667) is the number of times term (cid:2205) occurs in (cid:2160), and |(cid:2160)| is the length of docu-
ment (cid:2160). The (cid:2185)(cid:2188)(cid:4666)(cid:2205)(cid:4667) and |(cid:2159)| values are analogously defined on the collection level, where the collection consists of all the docu-
ments in search logs. (cid:2172)(cid:2202)(cid:2195)(cid:4666).(cid:4667) is word translation probability assigned by a translation model trained on query-title pairs derived 
from clickthrough data. (cid:2172)(cid:2202)(cid:2195)(cid:4666)(cid:2199)(cid:4593)|(cid:2199)(cid:4667) in #2 is also assigned by the same query-title translation model based on the assumption that a 
good expansion term (cid:2199)’ is likely to occur in the titles of the clicked documents [19]. (cid:2185)(cid:2194)(cid:2191)(cid:2185)(cid:2193)(cid:4666)(cid:2173)(cid:4593),(cid:2160)(cid:4667) is the number of times document 
(cid:2160) is clicked for (cid:2173)(cid:1314) in search logs. In #13, (cid:1778) is the full set of documents in search logs. (cid:1791) in #12 and #14 is the full set of queries in 
search logs. (cid:2170) in #13 and #14 is the total number of clicks in search logs, i.e., (cid:2170)(cid:3404)∑
. Finally, (cid:2235) and (cid:2236) are 
(cid:2173)(cid:1488)(cid:1791)
where I(cid:4666)(cid:1870)(cid:4666)(cid:1871),(cid:1872)(cid:4667)(cid:4667) is an indicator function that takes value 1 if there 
Each edge in the graph is labeled by a relation (cid:1870), and is scored 
exists  an  edge  with  type (cid:1870) that  connects (cid:1871) to (cid:1872).  Introducing (cid:2016)(cid:3045) 
using a relation-specific model (cid:2016)(cid:3045). The edge score is the probabil-
ity  of  reaching  target  node (cid:1872) from  source  node (cid:1871) with  a  one-step 
random  walk  with  edge type (cid:1870), (cid:1842)(cid:4666)(cid:1872)|(cid:1871),(cid:2016)(cid:3045)(cid:4667).  The  set  of  relations (cid:1870) 
and their corresponding scoring functions (cid:1871)(cid:1855)(cid:1867)(cid:1870)(cid:1857)(cid:3087)(cid:3293)(cid:4666)(cid:1871)(cid:1372)(cid:1872)(cid:4667), which 
The first is the functions for the (cid:1871)(cid:1861)(cid:1865)(cid:1861)(cid:1864)(cid:1853)(cid:1870)_(cid:1499) relation (e.g., #1), and 
edge score is a probability, (cid:1842)(cid:4666)(cid:1872)|(cid:1871),(cid:2016)(cid:3045)(cid:4667) is computed via softmax as 
tions  for  the  relations  of (cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1499) (e.g.,  #5),  uses  unigram 
[49]. The third, including functions for (cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1499) (e.g., #3), uses a 
Note that in the original PCRW model [32] there is no (cid:2016)(cid:3045), and the 
(cid:1872)(cid:1870)(cid:1853)(cid:1866)(cid:1871)(cid:1864)(cid:1853)(cid:1872)(cid:1861)(cid:1867)(cid:1866)_(cid:1499) (e.g.,  #6),  uses  translation  models  [5,  17,  19], 
word  translation  probabilities (cid:1842)(cid:3047)(cid:3040)  are  estimated  on  query-

,where(cid:1842)(cid:3039)(cid:3040)(cid:4666)(cid:1875)|(cid:1830)(cid:4667)(cid:3404)(cid:4666)1(cid:3398)(cid:2010)(cid:4667)(cid:1872)(cid:1858)(cid:4666)(cid:1875);(cid:1830)(cid:4667)
,where(cid:1842)(cid:3039)(cid:3040)(cid:4666)(cid:1875)|(cid:1843)(cid:4667)(cid:3404)(cid:4666)1(cid:3398)(cid:2009)(cid:4667)(cid:1872)(cid:1858)(cid:4666)(cid:1875);(cid:1843)(cid:4667)

(cid:1842)(cid:4666)(cid:1872)|(cid:1871),(cid:2016)(cid:3045)(cid:4667)(cid:3404) exp(cid:4672)(cid:1871)(cid:1855)(cid:1867)(cid:1870)(cid:1857)(cid:3087)(cid:3293)(cid:4666)(cid:1871)(cid:1372)(cid:1872)(cid:4667)(cid:4673)
∑ exp(cid:4672)(cid:1871)(cid:1855)(cid:1867)(cid:1870)(cid:1857)(cid:3087)(cid:3293)(cid:4666)(cid:1871)(cid:1372)(cid:1872)(cid:3036)(cid:4667)(cid:4673)
(cid:3047)(cid:3284)
(cid:1842)(cid:4666)(cid:1872)|(cid:1871),(cid:1870)(cid:4667)(cid:3404) I(cid:4666)(cid:1870)(cid:4666)(cid:1871),(cid:1872)(cid:4667)(cid:4667)
∑ I(cid:4666)(cid:1870)(cid:4666)(cid:1871),(cid:1872)(cid:4593)(cid:4667)(cid:4667)
(cid:3047)(cid:4594)

 

model hyperparameters that control smoothing for query and document language models, respectively. 
 

allows us to easily incorporate well-established models that have 
been  developed for  QE  and  document  ranking models  in  the IR 
community. The scoring functions in Table 1 lie in four categories. 

document pairs by assuming that a query is parallel to the docu-
ments clicked on for that query [17].  

where,  if  clickthrough  data  is  available  for  model  training,  the 

click  model  [13].  The  last  category,  including  functions  for 

language models with Bayesian smoothing using Dirichlet priors 

are used in this study, are summarized in Table 1. To ensure that 

is  based  on  the  BM25  model  [39].  The  second,  including  func-

(cid:2185)(cid:2194)(cid:2191)(cid:2185)(cid:2193)(cid:4666)(cid:2173),(cid:2160)(cid:4667)

edge score is computed by  

∑
(cid:2160)(cid:1488)(cid:1778)

 

 

 

 

(2) 

 

565query-document graph) 

document graph, as in [31]) 

Path type (cid:2250) (Comments) 
(cid:1731)(cid:1872)(cid:1870)(cid:1853)(cid:1866)(cid:1871)(cid:1864)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)2(cid:1875)(cid:1732) ((cid:1875) is generated using clickthrough-based translation model from (cid:1843) as in [19]) 
(cid:1731)(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)2(cid:1875),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1875)2(cid:1830),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1830)2(cid:1875)(cid:1732) (variant of TM1 where translation model is trained via 2-step random walks on word-
(cid:1731)(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)2(cid:1875),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1875)2(cid:1830),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1830)2(cid:1875),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1875)2(cid:1830),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1830)2(cid:1875)(cid:1732) (variant of TM2 where 4-step random walks are used) 
(cid:1731)(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)2(cid:1875),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1875)2(cid:1843)(cid:1314),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)(cid:1314)2(cid:1875)(cid:1732) (variant of TM2 where random walks are performed on word-query graph) 
(cid:1731)(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)2(cid:1875),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1875)2(cid:1843)(cid:1314),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)(cid:1314)2(cid:1875),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1875)2(cid:1843)(cid:1314),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)(cid:1314)2(cid:1875)(cid:1732) (variant of TM4 where 4-step random walks are used) 
(cid:1731)(cid:1871)(cid:1861)(cid:1865)(cid:1861)(cid:1864)(cid:1853)(cid:1870)_(cid:1843)2(cid:1843)(cid:1314),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)(cid:1314)2(cid:1875)(cid:1732) ((cid:1875) is generated from similar queries (cid:1843)’ of (cid:1843), where query similarity is based on BM25) 
(cid:1731)(cid:1872)(cid:1870)(cid:1853)(cid:1866)(cid:1871)(cid:1864)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)2(cid:1843)(cid:1314),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)(cid:1314)2(cid:1875)(cid:1732) (variant of SQ1 where query similarity is based on clickthrough-based translation model) 
(cid:1731)(cid:1871)(cid:1861)(cid:1865)(cid:1861)(cid:1864)(cid:1853)(cid:1870)_(cid:1843)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1830)2(cid:1843)(cid:1314),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)(cid:1314)2(cid:1875)(cid:1732) (variant of SQ1 where similar query set is enriched by 2-step random walks on 
(cid:1731)(cid:1871)(cid:1861)(cid:1865)(cid:1861)(cid:1864)(cid:1853)(cid:1870)_(cid:1843)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1830)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1830)2(cid:1843)(cid:1314),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)(cid:1314)2(cid:1875)(cid:1732) (variant of SQ3 where 4-step random walks are used) 
(cid:1731)(cid:1872)(cid:1870)(cid:1853)(cid:1866)(cid:1871)(cid:1864)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1830)2(cid:1843)(cid:1314),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)(cid:1314)2(cid:1875)(cid:1732)  (variant of SQ2 where similar query set is enriched by 2-step random walks on 
(cid:1731)(cid:1872)(cid:1870)(cid:1853)(cid:1866)(cid:1871)(cid:1864)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1830)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1830)2(cid:1843)(cid:1314),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)(cid:1314)2(cid:1875)(cid:1732) (variant of SQ5 where 4-step random walks are used) 
(cid:1731)(cid:1871)(cid:1861)(cid:1865)(cid:1861)(cid:1864)(cid:1853)(cid:1870)_(cid:1843)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1830)2(cid:1875)(cid:1732) ((cid:1875) is generated from pseudo-relevant documents (cid:1830) clicked for similar queries (cid:1843)(cid:1314) of (cid:1843)) 
(cid:1731)(cid:1872)(cid:1870)(cid:1853)(cid:1866)(cid:1871)(cid:1864)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1830)2(cid:1875)(cid:1732) (variant of RD1 where query similarity is computed via translation model) 
(cid:1731)(cid:1871)(cid:1861)(cid:1865)(cid:1861)(cid:1864)(cid:1853)(cid:1870)_(cid:1843)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1872)(cid:1870)(cid:1853)(cid:1866)(cid:1871)(cid:1864)(cid:1853)(cid:1872)(cid:1857)_(cid:1830)2(cid:1875)(cid:1732) (variant of RD1 where (cid:1875) is generated from (cid:1830) using translation model) 
(cid:1731)(cid:1871)(cid:1861)(cid:1865)(cid:1861)(cid:1864)(cid:1853)(cid:1870)_(cid:1843)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1830)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1830)2(cid:1875)(cid:1732) (variant of RD1 where set of (cid:1830) is enriched by 2-step random walks on 
(cid:1731)(cid:1871)(cid:1861)(cid:1865)(cid:1861)(cid:1864)(cid:1853)(cid:1870)_(cid:1843)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1830)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1830)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1830)2(cid:1875)(cid:1732) (variant of RD1 where 4-step random walks are 
(cid:1731)(cid:1872)(cid:1870)(cid:1853)(cid:1866)(cid:1871)(cid:1864)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1830)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1830)2(cid:1875)(cid:1732) (variant of RD2 where set of (cid:1830) is enriched by 2-step random walks on 
(cid:1731)(cid:1872)(cid:1870)(cid:1853)(cid:1866)(cid:1871)(cid:1864)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1830)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1830)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1830)2(cid:1875)(cid:1732) (variant of RD6 where 4-step random walks 
(cid:1731) (cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)2(cid:1830),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1830)2(cid:1875)(cid:1732) ((cid:1875) is generated from relevant documents (cid:1830) clicked for query (cid:1843)) 
(cid:1731) (cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)2(cid:1830),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1830)2(cid:1843),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)2(cid:1830),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1830)2(cid:1875)(cid:1732) (variant  of  RD8  where  the  set  of (cid:1830)  is  enriched  by  2-step  random  walks  on  query-
(cid:1731) (cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)2(cid:1830),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1830)2(cid:1843),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)2(cid:1830),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1830)2(cid:1843),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)2(cid:1830),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1830)2(cid:1875)(cid:1732) (variant of RD9 where 4-step random walks are used) 

query-document graph) 

query-document graph) 

query-document graph) 

document graph) 

used) 

are used) 

ID 
TM1 
TM2 

TM3 
TM4 
TM5 
SQ1 
SQ2 
SQ3 

SQ4 
SQ5 

SQ6 
RD1 
RD2 
RD3 
RD4 

RD5 

RD6 

RD7 

RD8 
RD9 

RD10 

Table 2: Some examples of path types, each used as a feature in the PCRW model for QE. 

3.2  Feature as Path Type 

Given  a  graph,  any  path  type (cid:2024) that  starts  with  the  input  query 
node (cid:1843) and ends with a word node (cid:1875) defines a real-value feature, 
value  is  the  probability  of  picking (cid:1875)  as  an  expansion  term 
(cid:1842)(cid:4666)(cid:1875)|(cid:1843),(cid:2024)(cid:4667) by PCRWs of type (cid:2024). In what follows we illustrate the 

which can be viewed as a QE model (or QE feature). The feature 

capability  of  the  PCRW  model  using  examples  in  Table  2.  We 
focus our discussion on three categories of QE features: (1) TM 
features,  which  perform  QE  using  translation  models  (i.e.,  the 
corresponding path types are specified by IDs from TM1 to TM5 
in  Table  2),  (2)  SQ  features,  which  perform  QE  using  similar 
queries  (i.e.,  SQ1  to  SQ6),  and (3)  RD  features,  which  perform 
QE using (pseudo-)relevant documents (i.e., RD1 to RD10). 

Many log-based QE methods use clickthrough-based transla-
tion models where term correlations are pre-computed using que-
ry-document pairs extracted from clickthrough data [14, 19, 22]. 
Compared to the methods that are based on thesauri either com-
piled  manually  [38]  or  derived  from  document  collections  [28], 
such log-based methods are superior in that the translation models 
explicitly capture the correlation between query terms and docu-
ment terms. One example is the word translation model described 

Rare queries present a big challenge for Web search [45]. The 

in  [19],  which  can  be  encoded  by  the  path  type  TM1, 

data for model training, Lafferty and Zhai [31] present a method 
using  Markov  chains,  where  the  translation  probability  between 
two  words  is  computed  by  random  walks  on  a  document-word 
graph. The method can be encoded by the path types of TM2 and 
TM3 in Table 2. 

(cid:1731)(cid:1872)(cid:1870)(cid:1853)(cid:1866)(cid:1871)(cid:1864)(cid:1853)(cid:1872)(cid:1861)(cid:1867)(cid:1866)_(cid:1843)2(cid:1875)(cid:1732).  In  case  there  is  not  (enough)  clickthrough 
expansion  of  a  rare  query (cid:1843) is  often  performed  by  adding  terms 
from common queries (cid:1843)(cid:1314) which are similar to (cid:1843) [45].  The PCRW 
type  SQ1, (cid:1731)(cid:1871)(cid:1861)(cid:1865)(cid:1861)(cid:1864)(cid:1853)(cid:1870)_(cid:1843)2(cid:1843)(cid:1314),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)(cid:1314)2(cid:1875)(cid:1732).  [6,  21,  35]  show 
with  types (cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)2(cid:1830) and (cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1830)2(cid:1843).  SQ3  and  SQ4  in  Table  2 
A set of relevant documents (cid:1830) of an input query (cid:1843) that is seen 

that (more) similar queries can be retrieved by performing random 
walks on a query-document click graph. Thus, rare query expan-
sion could be improved using a larger set of similar queries identi-
fied  by  repeatedly  applying  random  walks  following  the  edges 

model  achieves  this  by  a  random  walk  that  instantiates  the  path 

are two examples of such improved models. 

in the search logs can be formed by collecting all the documents 
that have clicks for that query. Thus, the relevance feedback QE 
method can be represented as e.g., RD8, 

566(cid:1731)(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)2(cid:1830),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1830)2(cid:1875)(cid:1732). 

relevant  documents  through  its  similar  queries (cid:1843)(cid:1314) that  are  in  the 

If the input query is a rare query, we can form the set of pseudo-

(cid:1731)(cid:1871)(cid:1861)(cid:1865)(cid:1861)(cid:1864)(cid:1853)(cid:1870)_(cid:1843)2(cid:1843)(cid:1314),(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)(cid:1314)2(cid:1830),(cid:1859)(cid:1857)(cid:1866)(cid:1857)(cid:1870)(cid:1853)(cid:1872)(cid:1857)_(cid:1830)2(cid:1875)(cid:1732). 

search logs, e.g., RD1, 

 

 

To  conquer  the  data  sparseness  problem,  more  pseudo-relevant 
documents  can  be  retrieved  by  performing  random  walks  on  a 
query-document click graph, such as RD4 and RD5 in Table 2. 

where the probability is calculated from clicks as in #3 in Table 1. 

where the probability is calculated from clicks as in #4 in Table 1. 

sponding  probability,  which  is  used  to  measure  query-to-query 

the  search  intent  shifts  from  the  initial  query,  as  the  probability 
quickly spreads out over all queries. Thus, in our experiments we 

3.3  QE as Path Ranking 
For QE, we rewrite the PCRW model of Equation (1) as 

(cid:1842)(cid:4666)(cid:1875)|(cid:1843)(cid:4667)(cid:3404)(cid:3533)(cid:2019)(cid:3095)(cid:1842)(cid:4666)(cid:1875)|(cid:1843),(cid:2024)(cid:4667)
, 

Following previous work [12, 21, 31], in our experiments the 
random  walks  are  implemented  as  matrix  multiplication.  As  an 
example,  we  consider  the  task  of  retrieving  similar  queries  by 

repeatedly  applying  random  walks  following (cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1843)2(cid:1830)  and 
(cid:1855)(cid:1864)(cid:1861)(cid:1855)(cid:1863)_(cid:1830)2(cid:1843).  Let (cid:1840) be  the  number  of  query  nodes  in (cid:1833) and (cid:1839) be 
the  number  of  document  nodes. Let (cid:2157) be  the (cid:1840)(cid:3400)(cid:1839) matrix  with 
entries (cid:2157)(cid:3018),(cid:3005)(cid:3404)(cid:1842)(cid:4666)(cid:1830)|(cid:1843)(cid:4667), called query-document transition matrix, 
Also,  let (cid:2158) be  the (cid:1839)(cid:3400)(cid:1840)  matrix  with  entries (cid:2158)(cid:3005),(cid:3018)(cid:3404)(cid:1842)(cid:4666)(cid:1843)|(cid:1830)(cid:4667), 
(cid:2157) and (cid:2158) are called transition matrices. It is easy to see that using 
(cid:2159)(cid:3404)(cid:2157)(cid:2158) we can compute the probability of walking from an ini-
tial  query (cid:1843)(cid:2868)  to  any  other  query (cid:1843) in 2(cid:1863) steps,  and  the  corre-
similarity, is  given  by (cid:1842)(cid:4666)(cid:1843)|(cid:1843)(cid:2868)(cid:4667)(cid:3404)(cid:2159)(cid:3018)(cid:3116),(cid:3018)(cid:3038)
.  Because  the  matrices (cid:2157) 
and (cid:2158) are  sparse,  the  matrix  product (cid:2159)(cid:3404)(cid:2157)(cid:2158) can  be  computed 
efficiently.  As (cid:1863)  increases, (cid:2159)(cid:3038)  quickly  becomes  dense  and  the 
powers cannot be computed efficiently. However, as (cid:1863) increases, 
limit (cid:1863) to 1 and 2.  
which  is  weighted  linear  combination  of  path  features (cid:2024) in (cid:1828). 
bined paths, each for one pair of (cid:1843) and (cid:1875) (i.e., a candidate expan-
sion term). This section presents the way (cid:1828) is constructed and the 
next two sections present the way parameters (cid:2019)(cid:3095) are estimated. 
Given a graph, the total number of path types |(cid:1828)| grows expo-
as shown in Table 1. Given a path type (cid:2024), due to the large number 
of nodes in (cid:1833), even with a length limit, the total number of paths 
that instantiate (cid:2024) could be extremely large. For example, since a 
lation model, any node pair (cid:4666)(cid:1843)(cid:4593),(cid:1843)(cid:4667) would have a non-zero-score 
relation (cid:1872)(cid:1870)(cid:1853)(cid:1866)(cid:1871)(cid:1864)(cid:1853)(cid:1872)(cid:1857)_(cid:1843)2(cid:1843)(cid:1314) (#2 in Table 1), thus making the transi-
The  training  data  used  for  the  estimation  of  parameters (cid:2019)(cid:3095)  in 
Equation (3) is denoted as (cid:4668)(cid:4666)(cid:1824)(cid:3036),(cid:1877)(cid:3036)(cid:4667)(cid:4669), where (cid:1824)(cid:3036) is a vector of all the 
path features for the pair (cid:4666)(cid:1843)(cid:3036),(cid:1875)(cid:3036)(cid:4667). That is, the j-th component of 
(cid:1824)(cid:3036) is (cid:1842)(cid:4666)(cid:1875)(cid:3036)|(cid:1843)(cid:3036),(cid:2024)(cid:3037)(cid:4667), and (cid:1877)(cid:3036) is a Boolean variable indicating whether 

tion matrix extremely dense. For efficiency, we keep the (multi-
plication of) transition matrices sparse by retaining only top-1000 
(partial) paths after each step of random walk.  
3.4  Training Data Generation 

nentially with the increase of path length. To make the computa-
tion feasible, in our experiments we set the maximum length to 7, 
and only consider a small set of relations that are highly selective, 

word could translate to any other word based on a smoothed trans-

Thus,  the  PCRW  model  performs  QE  by  ranking  a  set  of  com-

(cid:3095)(cid:1488)(cid:3003)

(3) 

 

 

 

(4) 

(5) 

the following ranking model 

ed via MLE with Dirichlet smoothing as  

erated  using  a  method  similar  to  [10],  which  will  be  described 
below. 

timated  via  MLE  (maximum  likelihood  estimation)  without 
smoothing as 

Assume we have developed a relevance judgment set. The set 
consists of a set of queries. Each query is associated with a set of 
documents.  Each  query-document  pair  has  a  relevant  label.  The 

(cid:3044)(cid:1488)(cid:3018)
(cid:1842)(cid:3435)(cid:1869)(cid:3627)(cid:2016)(cid:3018)(cid:3439)(cid:3404)(cid:1872)(cid:1858)(cid:4666)(cid:1869);(cid:1843)(cid:4667)
|(cid:1843)|
(cid:1842)(cid:4666)(cid:1875)|(cid:2016)(cid:3005)(cid:4667)(cid:3404)(cid:1872)(cid:1858)(cid:4666)(cid:1875);(cid:1830)(cid:4667)(cid:3397)(cid:2020)(cid:1842)(cid:4666)(cid:1875)|(cid:1829)(cid:4667)
|(cid:1830)|(cid:3397)(cid:2020)

(cid:1875)(cid:3036) is a good expansion term for (cid:1843)(cid:3036). In our experiments (cid:1830) is gen-
effectiveness  of  a  document  ranking  model (cid:1845)(cid:1855)(cid:1867)(cid:1870)(cid:1857)(cid:4666)(cid:1830),(cid:1843)(cid:4667) can  be 
evaluated on the set. We determine whether a word (cid:1875) is a good 
expansion for a query (cid:1843) by examining whether expanding (cid:1843) with 
(cid:1875) leads to a better document ranking result. Specifically, we use 
(cid:1845)(cid:1855)(cid:1867)(cid:1870)(cid:1857)(cid:4666)(cid:1830),(cid:1843)(cid:4667)(cid:3404)(cid:2009)log(cid:1842)(cid:4666)(cid:1875)|(cid:2016)(cid:3005)(cid:4667)(cid:3397)(cid:3533)(cid:1842)(cid:3435)(cid:1869)(cid:3627)(cid:2016)(cid:3018)(cid:3439)log(cid:1842)(cid:4666)(cid:1869)|(cid:2016)(cid:3005)(cid:4667)
where (cid:1875) is the expansion term under consideration, (cid:2009) is its weight, 
(cid:1869) is a term in the original query (cid:1843), and (cid:2016)(cid:3018) and (cid:2016)(cid:3005) are query and 
document  models,  respectively.  The  query  model (cid:1842)(cid:3435)(cid:1869)(cid:3627)(cid:2016)(cid:3018)(cid:3439) is  es-
where (cid:1872)(cid:1858)(cid:4666)(cid:1869);(cid:1843)(cid:4667) is  the  number  of  times (cid:1869) occurs  in (cid:1843),  and |(cid:1843)| is 
the query length. The document model, e.g., (cid:1842)(cid:4666)(cid:1875)|(cid:2016)(cid:3005)(cid:4667), is estimat-
where (cid:1872)(cid:1858)(cid:4666)(cid:1875);(cid:1830)(cid:4667) is  the  number  of  times (cid:1875) occurs  in (cid:1830), |(cid:1830)| is  the 
document length, (cid:2020) is the Dirichlet prior (set to 2000 in our exper-
iments),  and (cid:1842)(cid:4666)(cid:1875)|(cid:1829)(cid:4667) is  the  probability of (cid:1875) on  the  collection (cid:1829), 
single term. It is used to label whether (cid:1875) is a good expansion term 
for (cid:1843). To simplify the training data generation process, we assume 
that (cid:1875)  acts  on  the  query  independently  from  other  expansion 
terms, and each expansion term is added into (cid:1843) with equal weight, 
i.e., (cid:2009)(cid:3404)0.01 or (cid:2009)(cid:3404)(cid:3398)0.01.  
The training data is generated as follows. For each query (cid:1843) in 
(cid:4668)(cid:1875)(cid:3036)(cid:4669) is formed by collecting all terms that occur in the documents 
that are paired with (cid:1843) but do not occur in (cid:1843). Then (cid:1875)(cid:3036) is labeled as 
a  good  expansion  term  for (cid:1843) if  it  improves  the  effectiveness  of 
ranking  document  when  (cid:2009)(cid:3404)0.01  and  hurt  the  effectiveness 
when (cid:2009)(cid:3404)(cid:3398)0.01. (cid:1875)(cid:3036) is labeled as bad if it produces an opposite 
effect or produces similar effect when (cid:2009)(cid:3404)0.01 or (cid:2009)(cid:3404)(cid:3398)0.01. 
Given training data (cid:4668)(cid:4666)(cid:1824)(cid:3036),(cid:1877)(cid:3036)(cid:4667)(cid:4669), the model parameters (cid:2245)(cid:3404)(cid:1731)(cid:2019)(cid:3095)(cid:1732)(cid:3095)(cid:1488)(cid:3003) 
(cid:2272)(cid:4666)(cid:2245)(cid:4667)(cid:3404) (cid:3533) (cid:1858)(cid:4666)(cid:1824),(cid:1877);(cid:2755)(cid:4667)
(cid:3398)(cid:2009)(cid:2869)(cid:1313)(cid:2245)(cid:1313)(cid:2869)(cid:3398)(cid:2009)(cid:2870)(cid:1313)(cid:2245)(cid:1313)(cid:2870)(cid:2870) 
where (cid:2009)(cid:2869) and (cid:2009)(cid:2870)  respectively  control  the  strength  of  the  L1-
regularization  which  helps  prevent  overfitting. (cid:1858)(cid:4666)(cid:1824),(cid:1877);(cid:2755)(cid:4667) is  the 
log-likelihood of the training sample (cid:4666)(cid:1824),(cid:1877)(cid:4667), and is defined as 

regularization,  which  helps  with  structure  selection,  and  L2-

the  relevance  judgment  set,  a  set  of  candidate  expansion  terms 

Equation (4) can be viewed as a simplified form of QE with a 

can be optimized by maximizing the following objective [32] 

3.5  Parameter Estimation 

estimated via MLE without smoothing. 

(cid:4666)(cid:1824),(cid:3052)(cid:4667)(cid:1488)(cid:4668)(cid:4666)(cid:1824)(cid:3284),(cid:3052)(cid:3284)(cid:4667)(cid:4669)

(6) 

(7) 

567(cid:1858)(cid:4666)(cid:1824),(cid:1877);(cid:2755)(cid:4667)(cid:3404)(cid:1877)log(cid:1842)(cid:4666)(cid:1824),(cid:2245)(cid:4667)(cid:3397)(cid:4666)1(cid:3398)(cid:1877)(cid:4667)log(cid:4666)1(cid:3398)(cid:1842)(cid:4666)(cid:1824),(cid:2245)(cid:4667)(cid:4667) 
and   (cid:1842)(cid:4666)(cid:1824),(cid:2245)(cid:4667)(cid:1568)(cid:1842)(cid:4666)(cid:1877)(cid:3404)1|(cid:1824),(cid:2245)(cid:4667)(cid:3404) exp(cid:4666)(cid:2245)(cid:3021)(cid:1824)(cid:4667)
1(cid:3397)exp(cid:4666)(cid:2245)(cid:3021)(cid:1824)(cid:4667) 

(8) 

(9) 

is the model-predicted probability. In our experiments the maxi-
mization is performed using the OWL-QN algorithm [2], which is 
a  special  version  of  L-BFGS  designed  to  deal  with  non-
differentiable L1 norm. 

The  PCRW-based  model  of  Equation  (3)  assigns  each  path 
type a weight. Such a parameterization is called one-weight-per-
path-type. An alternative way of parameterizing the model is one-
weight-per-edge-label [11, 37]. [32] argue that the former is supe-
rior  in  that  it  takes  into  account  the  context  in  which  a  relation 
appears. In our experiments we compare these two parameteriza-
tion options. Following [32], we use the same objective function 
and  optimization  procedure  for  the  parameter  estimation  of  the 
one-weight-per-edge-label model. Because the model can be seen 
as  the  combination  of  all  the  PCRWs  with  each  path  having  its 
weight set to the product of all the edge weights along the path, 
we can calculate the gradient of edge weights by first calculating 
the gradient with respect to the paths, and then applying the chain 
rule of derivative. 

4.  EXPERIMENTS 
4.1  Dataset and Evaluation Method 
In  this  study  the  effectiveness  of  a  QE  method  is  evaluated  by 
issuing a set of queries which are expanded using the method to a 
search  engine  and  then  measuring  the  Web  search  performance. 
Better  QE  methods  are  supposed  to  lead  to  better  Web  search 
results using the correspondingly expanded query set. 

Due to the characteristics of our QE methods, we cannot con-
duct  experiments  on  standard  test  collections  such  as  the  TREC 
data  because  they  do  not  contain  related  search  logs  we  need. 
Therefore,  following  previous  studies  of  log-based  QE  [e.g.,  14, 
19, 40], we used the proprietary datasets that have been developed 
for  building  a  commercial  search  engine,  and  demonstrated  the 
effectiveness of our methods by comparing them against several 
state-of-the-art  QE  methods  that  are  originally  developed  using 
TREC data [45, 34, 36]. For comparison, we also reproduced on 
our  datasets  the  results  of  several  previous  state-of-the-art  log-
based QE methods [14, 19, 41]. 

Our relevance judgment set consists of 12,000 rare queries in 
English. On average, each query is associated with 33 Web docu-
ments  (URLs). Each  query-document pair  has a  relevance  label.  
The label is human generated and is on a 5-level relevance scale, 

0 to 4, with 4 meaning document (cid:1830) is the most relevant to query 
(cid:1843) and 0 meaning (cid:1830) is not relevant to (cid:1843).  

The  relevance  judgment  set  is  constructed  as  follows.  First, 
the  rare  queries  are  sampled  from  one  day  of  search  engine 
logs. Adult,  spam,  and  bot  queries  are  all  removed. To  reflex  a 
natural  distribution  of  rare  queries,  we  do  not  try  to  control  the 
quality of these queries. We found that in comparison with com-
mon  queries,  rare  queries  are  longer  and  contain  more  spelling 
errors.  For  example,  in  our  rare  query  set,  the  average  query 
length  is  5  (vs.  3-word  for  a  common  query  set),  and  there  are 

around  20%  misspelled  queries  (vs.  12%  for  a  common  query 
set). Second,  for  each  query,  we  collect  Web  documents  to  be 
judged  by  issuing  the  query  to  several  popular  search  engines 
(e.g.,  Google,  Bing)  and  fetching  top-10  retrieval  results  from 
each. Finally, the query-document pairs are judged by a group of 
well-trained  assessors.  In  this  study  all  the  queries  are  prepro-
cessed  as  follows.  The  text  is  white-space  tokenized  and  lower-
cased, numbers are retained, and no stemming/inflection treatment 
is performed. Since all the document ranking and QE models test-
ed in our experiments contain free parameters that must be esti-
mated  empirically  on  data,  we  used  two-fold  cross  validation  to 
report results: a set of results on one half of the relevance judg-
ment set is obtained using the parameter settings optimized on the 
other half, and global retrieval results are combined from those of 
the two sets. 

The search logs used in this study consist of approximately 3 
billion  query-document  pairs  sampled  from  the  search  logs  of  a 
commercial search engine. The Web document collection consists 
of around 730 million Web pages. In the retrieval experiments we 
use the index based on the content fields (i.e., body and title text) 
of each Web page. 

The edges between nodes are labeled using the relations defined 
in Table 1. Since rare queries are unseen in search logs, the edges 

The  performance  of  Web  search  is  evaluated  by  mean  Nor-
malized  Discounted  Cumulative  Gain  (NDCG)  [26].  We  report 
NDCG  scores  at  truncation  levels  1,  3,  and  10.    We  also  per-
formed a significance test, i.e., a t-test with a significance level of 
0.05. A significant difference should be read as significant at the 
95% level. 
4.2  System 

We  constructed  the  graph (cid:1833) using  the  search  logs  described  in 
Section  4.1. (cid:1833)  consists  of  730  million  document  nodes (cid:1830),  1.8 
billion query nodes (cid:1843)(cid:1314), and 100 million word nodes (cid:1875). To repre-
sent the rare queries in the relevant judgment set, we extend (cid:1833) by 
generated  12,000  input  query  nodes (cid:1843),  each  for  one  rare  query. 
between (cid:1843) and (cid:1830), as in Figure 1, have a zero score, and all path 
and the node of an input query (cid:1843), we perform random walks in (cid:1833) 
in (cid:1828). We then generate a list of candidate expansion term nodes (cid:1875) 
together with their scores (cid:1842)(cid:4666)(cid:1875)|(cid:1843)(cid:4667), as computed by Equation (3). 
We  sort  all  the  predictions (cid:4666)(cid:1843),(cid:1875)(cid:4667) by  the  scores  in  descending 
order, and pick the top-(cid:1866) words that are not in the input query for 
QE.  In  our  experiments  we  set (cid:1866)(cid:3404)10(cid:3400)|(cid:1843)|,  where |(cid:1843)| is  the 
term is set to 1.0(cid:3398)0.9(cid:3400)(cid:1861)/(cid:1866), where (cid:1861) the rank of the term in the 
sorted list of top-(cid:1866) candidates. 

length  of  the  input  query.  The  terms  in  the  expanded  query  are 
weighted using the method described in [45]. The weights of the 
terms in the original query are set to 2, and the weight of a new 

types  that  include  zero-score  edges  are  inactive,  such  as  RD8, 
RD9 and RD10 in Table 2. 

following all possible paths that instantiate the path types defined 

QE  is  performed  as  follows.  Given  a  trained  PCRW  model 

We use the unigram language model with Dirichlet smoothing 
to  perform  document  ranking  [49].  The  model  is  defined  as  the 
second term on the right-hand-side of Equation (4).  
4.3  Main Results 
Table 3 summarizes the main results using different QE methods, 
evaluated on the relevance judgment set described in Section 4.1.  

568NDCG@1 
0.2648 
0.2742α 
0.2689α 
0.2695α 
0.2811αβ 
0.2803αβ 
0.2837 αβ 
0.2959αβγ 

#  QE Methods 
0.3905 
1  NoQE 
0.4075 α 
2  LCA (PRF) 
0.4068 α 
3  RM (PRF) 
0.4098 α 
4  LCE 
0.4132 αβ 
5  TC 
0.4199 αβγ 
6  SMT 
0.4183 αβγ 
7  TM 
0.4265 αβγ 
8  PCRW 
Table 3: Document ranking results using different QE meth-

NDCG@3  NDCG@10 
0.2985 
0.3107 α 
0.3077 α 
0.3069 α 
0.3198 αβ 
0.3230 αβγ 
0.3212 αβ 
0.3302 αβγ 

ods. The superscripts (cid:2235),(cid:2236), and  (cid:2237) indicate statistically signifi-
cant improvements ((cid:2198)(cid:3407)(cid:2777).(cid:2777)(cid:2782)) over NoQE, LCA, and TC, 
sion terms for a query (cid:1843) is set to (cid:1866)(cid:3404)10(cid:3400)|(cid:1843)| for all QE methods.  

Row 1 in Table 3 (i.e., NoQE) is the baseline that uses the raw 
input queries without expansion. Rows 2 to 6 are the QE methods 
proposed previously. For fair comparison, the number of expan-

respectively.  
 

LCA (Row 2) is local context analysis [45]. RM (Row 3) is 
relevance  model  [34].  LCA  and  RM  are  state-of-the-art  PRF 
methods,  developed  respectively  for  the  vector  space  and  lan-
guage modeling IR frameworks. LCE (Row 4) is latent concept 
expansion [36], which is a generalization of RM in that it explicit-
ly models term dependencies for QE. Unfortunately, the generali-
zation does not lead to any significant improvement in our exper-
iments (Row 4 vs. Rows 2 and 3). 

TC (Row 5) is the log-based QE method based on our imple-
mentation  of  the  term  correlation  model  [14].  We  see  that  both 
TC  and  PRF  methods  improve  the  effectiveness  of  Web  search 
significantly, and the log-based method outperforms significantly 
the RPF methods that do not use query logs. The results confirm 
the conclusion of [14].  

SMT (Row 6) is a statistical machine translation (SMT) based 
QE system. Following Riezler et al. [41], the system is an imple-
mentation of a standard phrase-based SMT system with a set of 
features derived from a translation model and a language model, 
combined  under  the  log-linear  model  framework  [29].  To  apply 
the system to QE, expansion terms of a query are taken from those 
terms in the 10-best translations of the query that have not been 
seen  in  the  original  query  string.  The  results  show  that  SMT  is 
also effective (Row 6 vs. Row 1), outperforming significantly TC 
in NDCG at 3 and 10 (Row 6 vs. Row 5). This result is more or 
less consistent with what is reported in Riezler et al. [41], despite 
the  difference  in  training  data  we  used,  (i.e.,  Riezler  et  al.  used 
query-snippet pairs while we used query-title pairs). 

TM  (Row  7)  is  the  QE  method  using  a  clickthrough-based 
translation model [17, 19]. TM and TC models are trained on the 
same clickthrough data that consists of 3 billion query-title pairs. 
The  result  that  TM  outperforms  TC  confirms  the  conclusion  of 
[19] that a translation model trained using the EM algorithm [8, 
16] is better than a correlation model estimated purely based on 
frequency counting as in TC. 

TC, SMT and TM, considered as state-of-the-art QE methods, 

have been frequently used for comparison in related studies. 

Row 8 is the PCRW-based method, described in Section 3. It 
outperforms significantly the baseline (Row 1) and the other QE 
methods we used for comparison (Rows 2 to 6). Since the PCRW 
model  combines  a  wide  variety  of  features,  each  encoded  by  a 
path  type,  it  is  instructive  to  investigate  the  QE  performance  of 
individual features and the impact of how these features are com-
bined. 

NDCG@1  NDCG@3 NDCG@10 
0.2648 
0.2959 
0.2837 
0.2714 
0.2705 
0.2680 
0.2688 
0.2768 
0.2793 
0.2806 
0.2793 
0.2796 
0.2778 
0.2844 
0.2893 
0.2871 
0.2873 
0.2870 
0.2841 
0.2835 

 
ID (path length) 
NoQE  
PCRW 
TM1 (1) 
TM2 (3) 
TM3 (5) 
TM4 (3) 
TM5 (5) 
SQ1 (2) 
SQ2 (2) 
SQ3 (4) 
SQ4 (6) 
SQ5 (4) 
SQ6 (6) 
RD1 (3) 
RD2 (3) 
RD3 (3) 
RD4 (5) 
RD5 (7) 
RD6 (5) 
RD7 (7) 
Table 4: Document ranking results using different QE  
features, each encoded by a path type whose ID is defined  
in Table 2. The IDs NoQE, PCRW and TC are defined in  
Table 3. 

0.3905 
0.4265 
0.4183 
0.3995 
0.3989 
0.4031 
0.4030 
0.4084 
0.4127 
0.4109 
0.4103 
0.4107 
0.4102 
0.4133 
0.4167 
0.4213 
0.4163 
0.4175 
0.4122 
0.4119 

0.2985 
0.3302 
0.3212 
0.3101 
0.3100 
0.3050 
0.3051 
0.3139 
0.3159 
0.3164 
0.3146 
0.3151 
0.3140 
0.3200 
0.3242 
0.3245 
0.3221 
0.3234 
0.3194 
0.3176 

4.4  Individual Features 
Recall that in Section 3.2 we group path types into three catego-
ries: (1) TM features, (2) SQ features, and (3) RD features. They 
generate  expansion  terms  using  different  data  sources,  and  thus 
are  expected  to  be  complimentary.  Table  4  presents  QE  results 
using individual features, where the best feature in each category 
is in bold and italic. Comparing the results of individual features 
with  that  of  the  PCRW  model  reveals  that  combining  features 
significantly improves the QE performance. 

Figures  2  and  3  present  respectively  two  example  queries, 
where different QE features give complimentary expansion terms 
and the combined achieves the best result. The query “acme baked 
bread” in Figure 2 is issued to search for the homepage of a bak-
ery  company  in  Berkeley,  CA.  The  expanded  query  based  on 
clickthrough-based  translation  model  (TM1  in  Table  2)  leads  to 
worse  document  ranking  results  than  that  of  NoQE  because  the 
model generates expansion terms from query terms in a word-by-
word fashion, e.g., generating “bakery” or “bread” from “baked”. 
But, without knowing that the entire query refers to an entity (i.e., 
company),  it  cannot  generate  expansion  terms  relating  to  the 
properties of the entity (e.g., the location of the company). How-
ever,  using  features  based  on  similar  queries  (SQ1)  location 
names such as “san francisco” and “berkeley” are selected as ex-
pansion terms. It is also encouraging to see that its relevant docu-
ment (www.acmebread.com) is ranked top in its pseudo-relevant 
document set obtained via similar queries (RD1). 

The  query  “waterfall  glass  in  dallax  tx”  in  Figure  3  contain 
two  common  terms  “waterfall”  and  “glass”.  The  search  intent 
suggested by the two terms when they occur in the same query is 
very  different  from  that  when  only  one  of  them  occurs.  As  ex-
pected,  the  QE  method  using  a  word  translation  model  (TM1) 
fails  to  improve  the  search  performance.  Neither  do  the  similar 
queries retrieved via random walks (SQ1 and SQ3) provide very 
useful expansion terms since most of the similar queries are simp-
ly  different  permutations  of 
terms.

set  of 

same 

the 

569company 0.00280 
co 0.00203 
berkeley 0.00203 
recipes 0.00628 
sf 0.00203 
oven 0.00395 
bakery 0.00167 
home 0.00280 
recipe 0.00280 
san 0.00280 
francisco 0.00280 
fresh 0.00280 
ferry 0.00203 
building 0.00203 
garlic 0.00203 
pudding 0.00280 
pita 0.00203 
mountain 0.00203 
food 0.00167 
… … 
(b) 

company 0.00280 
markets 0.00199 
groceries 0.00143 
coupons 0.00143 
weekly 0.00143 
ad 0.00143 
recipes 0.00825 
pharmacy 0.00143 
bakery 0.00143 
grocery 0.00167 
stores 0.00167 
homemade 0.00143 
oven 0.00395 
baked 0.00729 
yeast 0.00143 
breads 0.00239 
ehow 0.00333 
grandmothers 0.0017 
recipe 0.00283 
… … 
(c) 

recipe 0.03239 
recipes 0.01685 
bake 0.01675 
oven 0.00886 
baking 0.00705 
cooks 0.00611 
company 0.00598 
html 0.00543 
food 0.00451 
set 0.00439 
bakery 0.00432 
breads 0.00324 
rec 0.00317 
search 0.00293 
make 0.00289 
ff 0.00272 
home 0.002168 
markets 0.0018 
honeybaked 0.0014 
… … 
(a) 
 
acme  bread;  acme  bread  company;  acme  bread  co;  acme  bread  berkeley; 
acme recipes; acme bread sf; baked bread recipes; oven baked bread; acme 
bakery; home baked bread; oven baked bread recipe; acme bread san fran-
cisco; oven baked bread recipes; home baked bread recipes;  
acme bread company san francisco; acme bread ferry building 
… … 
(d) 
 
1. the acme bread company   
http://www.acmebread.com 

 

 

 

 

 

2. acme markets groceries coupons weekly ad recipes and pharmacy  

http://www.acmemarkets.com 

3. bakery acme markets grocery stores 

http://www.acmemarkets.com/departments/bakery.jsp 

4. acme bread company 

http://www.ferrybuildingmarketplace.com/acme_bread_company.php 

5. homemade oven baked yeast breads 

http://baking.about.com/od/yeastbreads/Yeast_Breads.htm 

6. how to make home baked bread ehow com 

http://www.ehow.com/how_4794468_home-baked-bread.html 

7. grandmothers oven baked bread recipe best recipes 

http://www.bestrecipes.com.au/recipe/... 

8. how to bake bread bread recipes healthy breads 

http://bread-by-yia-yia.com 

9. bread baking 

http://breadbaking.about.com 

lounge 3.993E-05 
house 3.424E-05 
club 3.424E-05 
uptown 2.802E-05 
auto 2.031E-05 
stained 2.031E-05 
bar 2.031E-05 
blowing 2.031E-05 
door 2.031E-05 
oregon 2.031E-05 
coldplay 2.031E-05 
hiking 2.031E-05 
flat 2.031E-05 
tile 2.031E-05 
nightclub 2.031E-05 
… … 

windsor 7.85E-05 
texas 6.19E-05 
apartments 4.69E-05 
house 4.69E-05 
communities 4.69E-05 
real 2.39E-05 
estate 2.39E-05 
travel 2.39E-05 
hotels 2.10E-05 
profile 2.03E-05 
population 2.03E-05 
maps 2.03E-05 
averages 2.03E-05 
homes 2.03E-05 
statistics 2.03E-05 
relocation 2.03E-05 
hospitals 2.03E-05 
restaurants 1.99E-05 
events 1.85E-05 
… … 
(c) 

texas 0.05671 
waterfalls 0.01893 
falls 0.01093 
water 0.00592 
city 0.00401 
home 0.00362 
dfw 0.00267 
fall 0.00258 
worth 0.00255 
center 0.00238 
fort 0.00220 
company 0.00191 
wikipedia 0.00187 
wiki 0.00186 
park 0.00186 
houston 0.00185 
county 0.00168 
glasses 0.00158 
north 0.00157 
… … 
(a) 
 
glass dallas; dallas glass; glass dallas tx; waterfall glass; glass waterfall;  
dallas auto glass; glass house dallas; stained glass dallas; glass dallas club;  
glass club dallas; glass lounge dallas tx; the glass house dallas; glass bar dallas; 
dallas glass blowing; glass dallas uptown; dallas glass and door; 
dallas glass oregon; coldplay dallas tx; hiking dallas tx; glass lounge dallas 
… … 
(d) 

(b) 

1. welcome to the city of dallas texas city web portal 

http://dallascityhall.com/ 

2. dallas wikipedia the free encyclopedia 

http://en.wikipedia.org/wiki/Dallas 

3. dallas hotels restaurants events and things to do dallas cvb 

http://www.visitdallas.com 

4. dallas tx apartments glass house by windsor windsor communities 

http://www.windsorcommunities.com/apartments/dallas/glasshouse 

5. dallas texas tx profile population maps real estate … 

http://www.city-data.com/city/Dallas-Texas.html 

6. dallas city guide hotels restaurants nightlife attractions real estate 

http://www.dallas.com 

7. glass lounge uptown dallas tx 

http://www.yelp.com/biz/glass-lounge-dallas 

8. glass uptown uptown dallas tx 

http://www.yelp.com/biz/glass-uptown-dallas 
9. the dallas glass club dallas texas dgc home 

http://dallasglassclub.org/ 

10. bread recipes allrecipes com 

… … 
(e) 
 

http://allrecipes.com/Recipes/Bread 

Figure 2: QE results of (cid:2173)(cid:3404) acme baked bread. (a), (b) and (c) 
are top expansion terms and their scores (cid:2172)(cid:4666)(cid:2205)|(cid:2173)(cid:4667) generated 

using features TM1, SQ1 and RD1, respectively; (d) are top 
similar queries generated using SQ1; (e) are top pseudo rele-
vant documents generated using RD1. Features are defined in 
Table 2. 
Fortunately, as shown in Figure 3 (e), these permuted queries lead 
to a set of clicked documents (RD1) from which effective expan-
sion terms are generated.  

Results in Table 4 reveal the effectiveness of individual fea-
tures,  some  of  which  have  not  been  studied  previously.  TM1, 
which is also reported in Row 7 in Table 1, is the best among all 
TM features. Although the translation probabilities in TM2, TM3, 
TM4  and  TM5  are  estimated  via  random  walks,  rather  than  on 
query-document pairs as in TM1, these models still improve the 

10. glass uptown lounge website coming soon 

 

… … 
(e) 

http://glassuptown.com/ 

  Figure 3: QE results of (cid:2173)(cid:3404) waterfall glass in dallas tx. (a), (b) 
and (c) are top expansion terms their scores (cid:2172)(cid:4666)(cid:2205)|(cid:2173)(cid:4667) generated 

using features TM1, SQ1 and RD1, respectively; (d) are top 
similar queries generated using SQ1; (e) are top pseudo relevant 
documents generated using RD1. Features are defined in Table 2. 

baseline NoQE, although not as effective as TM1, thus providing 
an alternative way of obtaining translation models without train-
ing data.  

Results of the SQ features suggest that (1) it is more effective 
to  retrieve  semantically  similar  queries  for  QE,  and  this  can  be 
achieved either by applying a translation model (SQ2 vs. SQ1) or 
by  applying  random  walks  on  query-document  graph  (SQ3  vs. 
SQ1);  and  (2)  taking  a  2-step  random  walk  is  useful  but  taking 
longer steps is not (e.g., SQ3 vs. SQ1 and SQ4). 

570untrained ((cid:2019)(cid:3095)=1) 

Parameterization 

NDCG@1  NDCG@3  NDCG@10

0.2910 
0.2924 
0.2959 

0.3263 
0.3277 
0.3302 

one-weight-per-edge-label 
one-weight-per-path-type 
Table 5: Comparison with different parameterization  
methods. 

0.4233 
0.4249 
0.4265 

Results of the RD features show that (1) it is more effective to 
use a translation model to retrieve similar queries (RD2 vs. RD1) 
or  to  generate  expansion  terms  from  pseudo-relevant  documents 
(RD3  vs.  RD1);  and  (2)  random  walks  cannot  significantly  im-
prove the quality of the pseudo-relevant document set (e.g., RD6 
and RD7 vs. RD2).  
4.5  Impact of Parameter Estimation 
Table  5  compares  the  PCRW  model  parameterized  using  one-
weight-per-path-type  with  two  baselines.  We  see  that  (1)  the 
trained  models  outperform  the  untrained  model;  and  (2)  one-
weight-per-path-type is  slightly better than  one-weight-per-edge-
label, but the difference is not statistically significant, except for 
NDCG  score  at  1,  indicating  that  capturing  context  information 
between relations in a path is useful, although the impact on QE is 
marginal. 

 

5.  RELATED WORK  
Our  work  is  a  significant  extension  to  the  random  walk  models 
described  in  [11]  in  two  aspects.  First,  while  we  use  a  PCRW 
model, [11] uses a more traditional Markov chain model, similar 
to [23, 37, 43], where random walks are not constrained by path 
types and their models are parameterized as one-weight-per-edge-

label. As discussed in Section 3.5, paths in (cid:1833) provide more useful 
Second, while (cid:1833) in our model is constructed on search logs, (cid:1833) in 

features for QE than edges since the former captures more context 
information.  Although  it  is  difficult  for  us  to  perform  a  direct 
comparison between our model and the model in [11] due to the 
dramatically  different  data  sources  that  these  two  models  are 
based on respectively, the result in Table 5 suggests that given the 
same search logs as thesauri, our model is likely to perform better. 

[11] is constructed on thesauri that are compiled manually or de-
rived  from  document  collections.  Our  design  decision  of  using 
search  logs  rather  than  pre-complied  thesauri  is  motivated  by 
those studies that show that log-based QE methods [e.g., 15, 19, 
22, 42] often lead to a superior performance to the QE methods 
that use human-compiled thesauri [e.g., 24, 38] largely due to the 
fact that models trained on search logs explicitly capture the cor-
relation between query terms and document terms, thus bridging 
the lexical gap between them more effectively. On the other hand, 
Web  scale  thesauri  such  as  ConceptNet  and  Wikipedia  have  re-
cently  been  explored  for  QE,  leading  to  some  promising  results 
[30, 47]. The graph representation and the PCRW-based inference 
we  proposed  provide  a  flexible  framework  to  incorporate  such 
new thesauri. We leave it to future work.  

In  addition  to  QE,  random  walk  models  have  also  been  ap-
plied on other Web search applications, such image search [12], 
query suggestion [6, 35], query translation for cross-lingual IR [9], 
click model smoothing [21], and email search [37]. Our method 
bears some resemblance to all these previous works. 

Previous studies on QE can be roughly grouped into two cate-
gories: the automatic relevance feedback methods [10, 11, 34, 36, 
40,  45,  48]  developed  mainly  on  TREC  data  and  the  log-based 
methods  [14,  15,  19,  22,  41,  42]  where  the  correlation  between 

query terms and document terms is learned from clickthrough data. 
Most of the features used in our PCRW model, as in Table 2, are 
inspired by these QE models. 

Search logs have been proved to be a valuable data source for 
many  Web  search tasks.  In  addition  to  QE,  they have  also  been 
used  for  document  ranking  [1,  20,  27],  query  processing  and 
spelling correction [18, 25], user query clustering [3, 4, 44], etc. 
6.  CONCLUSIONS 
This  paper  exploits  search  logs  for  QE  for  Web  search  ranking. 
We present a QE method based on path-constrained random walks, 
where the search logs are represented as a labeled, directed graph, 
and  the  probability  of  selecting  an  expansion  term  for  an  input 
query is computed by a learned combination of constrained ran-
dom walks on the graph. We show that our method is generic and 
flexible in that it not only represents most of popular QE models 
as features, but also allows us to easily devise new features, which 
can  potentially  use  much  richer  information  than  previous  QE 
models, by defining path types with a rich set of walk behaviors. 
The  PCRW  model  also  provides  a  principled  mathematical 
framework  in  which  different  QE  models,  i.e.,  defined  as  path 
types or features, can be incorporated in a unified way, thus mak-
ing it less susceptible to the sparseness issue of clickthrough data 
and ambiguous search intent of user queries. The evaluation on a 
real-world  data  set  shows  that  the  PCRW-based  method  signifi-
cantly outperforms other state-of-the-art QE methods. 

One area in future work is to adapt the PCRW-based method 
for Web document ranking directly. For example, we might model 

the relevance score of a query (cid:1843) and a document (cid:1830) as the proba-
random  walks  from (cid:1843) to (cid:1830),  where  different  document  ranking 
struct (cid:1833),  such  as  link  graphs  and  the  category  structure  of  Web 

models  can  be  incorporated  as  path  types.  In  addition  to  click-
through  data,  we  need  to  incorporate  other  data  source  to  con-

bility,  computed  by  a  learned  combination  of  path-constrained 

documents. 

7.  REFERENCES 
[1]  Agichtein, E., Brill, E., and Dumais, S. 2006. Improving web 

search ranking by incorporating user behavior information. 
In SIGIR, pp. 19-26. 

[2]  Andrew, G., and Gao, J. 2007. Scalable training of L1-

regularized log-linear models. In ICML. 

[3]  Baeza-Yates, R. 2007. Graphs from search engine queries. In 

Jan van Leeuwen et al. (Eds.): SOFSEN 2007, LNCS 4362, 
pp. 1-8. 

[4]  Baeza-Yates, R., and Tiberi, A. 2007. Extracting semantic 

relations from query logs. In SIGKDD, pp. 76-85. 

[5]  Berger, A., and Lafferty, J. 1999. Information retrieval as 

statistical translation. In SIGIR, pp. 222-229. 

[6]  Boldi, P., Bonchi, F., Castillo, C., Donato, D., and Vigna, S. 

2009. Query suggestions using query-flow graphs. In 
WSDM’09. 

[7]  Broder, A., Ciccolo, P., Gabrilovich, E., Josifovski, V., 

Metzler, D., Riedel, L., and Yuan, J. 2009. Online expansion 
of rare queries for sponsored search. In WWW 2009. 

[8]  Brown, P. F., Della Pietra, S. A., Della Pietra, V. J., and 

Mercer, R. L. 1993. The mathematics of statistical machine 
translation: parameter estimation. Computational Linguistics, 
19(2): 263-311. 

571[9]  Cao, G., Gao, J., Nie, J-Y., and Bai, J. 2007. Extending query 

translation to cross-language query expansion with Markov 
chain models. In CIKM’07. 

[10]  Cao, G., Nie, J-Y., Gao, J., and Robertson, S. 2008. Selecting 

good expansion terms for pseudo-relevance feedback. In 
SIGIR, pp. 289-305. 

[11]  Collins-Thompson, K., and Callan, J. 2005. Query expansion 

using random walk models. In CIKM’05. 

[12]  Craswell, N., and Szummer, M. 2007. Random walks on the 

click graph. In SIGIR’07, pp. 239-246. 

[13]  Craswell, N. Zoeter, O., Taylor, M. J., and Ramsey, B. 2008. 

An experimental comparison of click position-bias models. 
In WSDM 2008, pp. 87-94. 

[14]  Cui, H., Wen, J-R., Nie, J-Y. and Ma, W-Y. 2002. 

Probabilistic query expansion using query logs. In WWW, pp. 
325-332.  

[15]  Cui, H., Wen, J-R., Nie, J-Y. and Ma, W-Y. 2003. Query 
expansion by mining user log. IEEE Trans on Knowledge 
and Data Engineering. Vol. 15, No. 4. pp. 1-11. 

[16]  Dempster, A., Laird, N., and Rubin, D. 1977. Maximum 
likelihood from incomplete data via the EM algorithm. 
Journal of the Royal Statistical Society, 39: 1-38. 

[17]  Gao, J., He, X., and Nie, J-Y. 2010. Clickthrough-based 
translation models for web search: from word models to 
phrase models. In CIKM, pp. 1139-1148. 

[18]  Gao, J., Li, X., Micol, D., Quirk, C., and Sun, X. 2010. A 

large scale ranker-based system for query spelling correction. 
In COLING, pp. 358-366. 

[19]  Gao, J., Nie, J-Y. 2012. Towards concept-based translation 

models using search logs for query expansion. In CIKM. 

[20]  Gao, J., Toutanova, K., and Yih, W-T. 2011. Clickthrough-
based latent semantic models for web search. In SIGIR, pp. 
675-684.  

[21]  Gao, J., Yuan, W., Li, X., Deng, K., and Nie, J-Y. 2009. 
Smoothing clickthrough data for web search ranking. In 
SIGIR, pp. 355-362. 

[22]  Gao, J., Xie, S., He, X., and Ali, A. 2012. Learning lexicon 
models from search logs for query expansion. In EMNLP. 

[23]  Haveliwala, T. H.  2002. Topic-sensitive pagerank. In WWW, 

pp. 517-526. 

[24]  Hovy, E., Gerber, L., Hermjakob, U. Junk, M., and Lin, C-Y. 

2000. Question answering in webclopedia. In TREC 9. 

[25]  Huang, J., Gao, J., Miao, J., Li, X., Wang, K., and Behr, F. 

2010. Exploring web scale language models for search query 
processing. In WWW, pp. 451-460. 

[26]  Jarvelin, K. and Kekalainen, J. 2000. IR evaluation methods 
for retrieving highly relevant documents. In SIGIR, pp. 41-48 

[27]  Joachims, T. 2002. Optimizing search engines using click-

through data. In SIGKDD, pp. 133-142. 

[28]  Jing, Y., and Croft., B. 1994. An association thesaurus for 

information retrieval. In RIAO, pp. 146-160. 

[29]  Koehn, P., Och, F., and Marcu, D. 2003. Statistical phrase-

based translation. In HLT/NAACL, pp. 127-133. 

 

[30]  Kotov, A., and Zhai, C. 2012. Tapping into knowledge base 

for concept feedback: leveraging conceptnet to improve 
search results for difficult queries. In WSDM. 

[31]  Lafferty, J., and Zhai, C. 2001. Document language models, 

query models, and risk minimization for information 
retrieval. In SIGIR’01, pp. 111-119. 

[32]  Lao, N., and Cohen, W. W. 2010. Relational retrieval using a 

combination of path-constrained random walks. Machine 
Learning, 81:53-67. 

[33]  Lao, N., Subramanya, A., Pereira, F., Cohen, W. W. 2012. 
Reading the web with learned syntactic-semantic inference 
rules. In EMNLP-CoNLL-2012, pp. 1017-1026. 

[34]  Lavrenko, V., and Croft, B. 2001. Relevance-based language 

models. In SIGIR, pp. 120-128. 

[35]  Mei, Q., Zhou, D., and Church, K. 2008. Query suggestion 

using hitting time. In CIKM’08. 

[36]  Metzler, D., and Croft, B. 2007. Latent concept expansion 

using markov random fields. In SIGIR‘07, pp. 311-318. 

[37]  Minkov, E., Cohen, W. W., and Ng, A. Y. 2006. Contextual 
search  and  name  disambiguation  in  email  using  graphs.  In 
SIGIR’06. 

[38]  Prager,  J.,  Chu-Carroll,  J.,  and  Czuba,  K.  2001.  Use  of 
Wordnet  hypernyms  for  answering  what  is  questions.  In 
TREC 10. 

[39]  Robertson, S., and Zaragoza, H. 2009. The probabilistic 

relevance framework: BM25 and beyond. Foundations and 
Trends in Information Retrieval, Vol. 3, No. 4 (2009) 333-
389. 

[40]  Rocchio, J. 1971. Relevance feedback in information 

retrieval. In The SMART retrieval system: experiments in 
automatic document processing, pp. 313-323, Prentice-Hall 
Inc. 

[41]  Riezler, S., Liu, Y. and Vasserman, A. 2008. Translating 
queries into snippets for improving query expansion. In 
COLING 2008. 737-744. 

[42]  Riezler, S., and Liu, Y. 2010. Query rewriting using 

monolingual statistical machine translation. Computational 
Linguistics, 36(3): 569-582. 

[43]  Toutanova, K., Manning, C. D., and Ng, A. Y. 2004. 

Learning random walk models for inducing word 
dependency distributions. In ICML. 

[44]  Wen, J., Nie, J-Y., and Zhang, H. 2002. Query clustering 

using user logs. ACM TOIS, 20(1): 59-81. 

[45]  Xu, J., and Croft, B. 1996. Query expansion using local and 

global document analysis. In SIGIR. 

[46]  Xu, J., and Xu, G. 2011. Learning similarity function for rare 

queries. In WSDM’11. 

[47]  Xu, Y. Jones, G.J.F., and Wang, B. 2009. Query dependent 

pseudo-relevance feedback based on Wikipedia. In SIGIR. 

[48]  Zhai, C., and Lafferty, J. 2001a. Model-based feedback in the 

kl-divergence retrieval model. In CIKM, pp. 403-410. 
[49]  Zhai, C., and Lafferty, J. 2001b. A study of smoothing 

methods for language models applied to ad hoc information 
retrieval. In SIGIR, pp. 334-342.

572