Exploiting Hybrid Contexts for Tweet Segmentation

Chenliang Li†, Aixin Sun†,

Jianshu Weng‡, Qi He§

†School of Computer Engineering, Nanyang Technological University, Singapore

{lich0020,axsun}@ntu.edu.sg
‡Independent Researcher, Singapore

jianshu@acm.org

§IBM Almaden Research Center, USA

heq@us.ibm.com

ABSTRACT

Twitter has attracted hundred millions of users to share and dissem-
inate most up-to-date information. However, the noisy and short
nature of tweets makes many applications in information retrieval
(IR) and natural language processing (NLP) challenging. Recently,
segment-based tweet representation has demonstrated eﬀectiveness
in named entity recognition (NER) and event detection from tweet
streams. To split tweets into meaningful phrases or segments, the
previous work is purely based on external knowledge bases, which
ignores the rich local context information embedded in the tweets.
In this paper, we propose a novel framework for tweet segmentation
in a batch mode, called HybridSeg. HybridSeg incorporates local
context knowledge with global knowledge bases for better tweet
segmentation. HybridSeg consists of two steps: learning from oﬀ-
the-shelf weak NERs and learning from pseudo feedback. In the
ﬁrst step, the existing NER tools are applied to a batch of tweets.
The named entities recognized by these NERs are then employed to
guide the tweet segmentation process. In the second step, Hybrid-
Seg adjusts the tweet segmentation results iteratively by exploiting
all segments in the batch of tweets in a collective manner. Ex-
periments on two tweet datasets show that HybridSeg signiﬁcantly
improves tweet segmentation quality compared with the state-of-
the-art algorithm. We also conduct a case study by using tweet
segments for the task of named entity recognition from tweets. The
experimental results demonstrate that HybridSeg signiﬁcantly ben-
eﬁts the downstream applications.

Categories and Subject Descriptors

H.3.1 [Information Systems]: Content Analysis and Indexing—
Linguistic processing
Keywords

Twitter, Tweet, Tweet segmentation, Named Entity Recognition

1.

INTRODUCTION

Twitter has become one of the most important channels for peo-
ple to ﬁnd, share, and disseminate timely information. As of March

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
SIGIR’13, July 28–August 1, 2013, Dublin, Ireland.
Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

2012, there are more than 140 million active Twitter users with over
340 million tweets posted in a day1. Due to its large volume of
timely information generated by its millions of users, it is impera-
tive to understand tweets’ language for the tremendous downstream
applications like named entity recognition (NER) [12,14,21], event
detection and summarization [5, 15, 22], opinion mining [16, 17],
sentiment analysis [4, 13, 25], etc.

Given the limited length (i.e., 140 characters) of a tweet and no
restrictions on its writing styles, tweets often contain grammatical
errors, misspellings, and informal abbreviations. The error-prone
and short nature of tweets makes the word-level language models
for tweets not reliable. For example, given a tweet “I call her, no
answer. Her phone in the bag, she dancin.”, there is no clue to
guess its true theme with the word independent assumption. Very
recently, a segment-based tweet representation model has been pro-
posed to partially overcome the adverse features of tweets [12]. Af-
ter splitting a tweet into a sequence of consecutive n-grams (n ≥ 1),
each of which is called a segment, the latent topics of the tweet can
be better captured. For example, the segment “she dancin” in the
previous example tweet is actually a key concept – it classiﬁes this
tweet into the family of tweets talking about the song “She Dancin",
a trend topic in Bay Area in Jan, 2013.

A segment can be a named entity (e.g., a movie title “ﬁnding
nemo”), a semantically meaningful information unit (e.g., “oﬃ-
cially released”), or any other type of phrase which appears “more
than chance” [12]. Because segments preserve more semantics of
tweets than words do, they have been used as the language units
for the tasks of NER and event detection [11, 12]. Segment-based
representation has shown its eﬀectiveness over word-based repre-
sentation particularly in the event detection task.

However, developing a high quality tweet segmentation is not
trivial, because the prevalence of grammatical errors and unreli-
able linguistic features makes classic Natural Language Processing
(NLP) techniques including part-of-speech (POS) tagging [7] and
NER less applicable to tweets. For example, classic POS taggers
may fail in recognizing “she dancin” as a noun phrase in the pre-
vious example tweet. The seminal tweet segmentation algorithm
in [12] mainly relies on external knowledge bases (e.g., Wikipedia
and Microsoft Web N-Gram corpus). The main assumption is that
the core semantic information is well preserved in tweets in the
form of named entities or semantic phrases for information shar-
ing, despite the noise nature of tweets, and those named entities and
semantic phrases can be largely found in aforementioned external
knowledge bases. We categorize this method into global context
based solution, since it utilizes the language-generic information
contained in the external knowledge bases.

1

http://blog.twitter.com/2012/03/twitter-turns-six.html

523Purely relying on external knowledge bases for tweet segmen-
tation has two major weaknesses. First, tweets are highly time-
sensitive so that many recently appeared terms like “She Dancin”
can not be found in external knowledge bases. Another example is
“Tin Pei Ling”, a new politician who gained her reputation in Sin-
gapore General Election 20112. No entry about her had been cre-
ated in Wikipedia until 4th, April 2011, about a week later than the
time her name appeared in tweets. Second, by deﬁning other tweets
published within the same short time window (i.e., an hour/a day)
as the local context, a tween can only be well understood within
its local context. For example, “Dancin” could be a typo if it only
appears in a single tweet. But it may refer to some named entity if
it appears in lots of tweets in a short term.

In this paper, we propose a hybrid tweet segmentation framework
incorporating local contexts into the existing external knowledge
bases, and name our method HybridSeg. HybridSeg conducts tweet
segmentation in batch mode. Following the same scope of [12],
we only segment tweets from a targeted Twitter stream. A targeted
Twitter stream receives tweets based on user deﬁned criteria (e.g.,
tweets containing some predeﬁned hashtags or keywords, tweets
published by a predeﬁned list of users, or tweets published by users
from a speciﬁc geographical region). Tweets from a targeted Twit-
ter stream are grouped into batches by their publication time using
a ﬁxed time interval (e.g., an hour or a day). Each batch of tweets
are then segmented by HybridSeg collectively.

HybridSeg conducts tweet segmentation in an iterative manner.
At the ﬁrst iteration, HybridSeg segments the tweet by utilizing the
local linguistic features of the tweet itself. To avoid implementation
from scratch, we simply apply a set of existing NER tools trained
over general English languages on tweets. These existing NER
tools provide an initial collection of conﬁdent segments by voting.
Initializing HybridSeg with a set of oﬀ-the-shelf NER tools is based
on the observation that some tweets from oﬃcial accounts of news
agencies, organizations, advertisers, and celebrities are likely well
written. A small set of named entities extracted from these tweets
based on voting of classic NER tools can be a high precise yet low
recall solution of tweet segmentation. For example, although “Tin
Pei Ling” is a new ﬁgure, it can be recognized as people name by
classic NERs with high conﬁdence because there are many well-
written tweets about her generated by news agencies.

After that, HybridSeg learns better segmentation iteratively based
on the conﬁdent segments extracted from the batch of tweets in the
last iteration. The iterative process stops when no more changes are
observed from the resulted segments. The philosophy is the con-
ﬁdent segments of one tweet can aﬀect the segmentation of other
tweets in the same batch. External knowledge bases are also inte-
grated here to better measuring the cohesiveness of segments. To
the best of our knowledge, this paper proposes a novel framework
by leveraging both global and local contexts in tweet segmentation
for targeted Twitter streams.

We conduct extensive experimental analysis on two tweet datasets
and compare HybridSeg with the approach purely relying on global
knowledge bases [12], known as GlobalSeg in this paper. Our ex-
perimental results show that HybridSeg achieved signiﬁcant im-
provement on tweet segmentation quality by comparing to the set
of manually labeled tweets. We further split named entities from
valid segments and only compared these named entities to human
labels. Again, HybridSeg improved the NER quality compared to
GlobalSeg.

The rest of the paper is organized as follows. Section 2 surveys
the related works such as NLP, collocation measures, noun phrase

2

http://en.wikipedia.org/wiki/Tin_Pei_Ling

extraction, and text segmentation. Section 3 gives an overview of
the global knowledge guided segmentation process. The proposed
hybrid-context based segmentation algorithm is presented in Sec-
tion 4. In Section 5, we conduct experimental evaluation of the pro-
posed HybridSeg framework and provide detailed algorithm analy-
sis. Section 6 concludes this paper.

2. RELATED WORK

Many conventional NLP techniques are designed for formal text.
Many of these techniques are supervision based and heavily rely on
the local linguistic features, such as POS tags, word capitalization,
trigger words (e.g., Mr., Dr.), and dictionary lookup like gazetteers,
etc. These linguistic features, together with eﬀective supervised
learning algorithms (e.g., hidden Markov model (HMM) and con-
ditional random ﬁeld (CRF)), achieve state-of-the-art performance
on formal text corpus [6, 19, 26]. However, these techniques cannot
be directly applied to tweets because of the noisy and short nature
of the latter. The error-prone and short nature of tweets (and other
user-generated short text) has attracted renewed interests in con-
ventional tasks in NLP including POS tagging [7], named entity
recognition (NER) [12, 14, 21], etc.

To improve POS tagging on tweets, Gimple et al.

incorporate
tweet-speciﬁc features including at-mentions, hashtags, URLs, and
emotions [7]. In their approach, they measure the conﬁdence of
capitalized words and apply phonetic normalization for ill-formed
words to address possible peculiar writings in tweets. Normaliza-
tion of ill-formed words in tweets has established itself as an impor-
tant research problem. A supervised approach is employed in [8]
to ﬁrst identify the ill-formed words. Then, the correct normaliza-
tion of the ill-formed word is selected based on a number of lexical
similarity measures.

Both supervised and unsupervised approaches have been pro-
posed for named entity recognition in tweets. T-NER is a part of
the tweet-speciﬁc NLP framework in [21]. T-NER ﬁrst segments
named entities using a CRF model with orthographic, contextual,
and dictionary features, and then labels the named entities using a
LDA (Latent Dirichlet allocation) model. The NER solution pro-
posed in [14] is also based on a CRF model. The unsupervised ap-
proach named TwiNER recognizes named entities with two steps:
tweet segmentation and segment ranking [12]. The tweets from a
Twitter stream are processed in batch mode. Member tweets in a
batch are segmented and each tweet segment is a candidate named
entity (see Section 3). Collocation measure between words is uti-
lized in tweet segmentation together with the global knowledge
bases. Experimental results show that the collocation measure Sym-
metric Conditional Probability (SCP) is much more eﬀective than
Pointwise Mutual Information (PMI). To recognize named entities
from the candidate segments, a segment graph is built based on
segment co-occurrences. The segments are then ranked by apply-
ing random walk on the segment graph (see Section 5.4.1). Chua
et al. [3] propose to extract noun phrases from tweets using an un-
supervised approach which is mainly based on POS tagging. Each
extracted noun phrase is a candidate named entity.

Tweet segmentation is conceptually similar to the task of text
segmentation despite the unit for segmentation (words vs sentences)
is signiﬁcantly diﬀerent. Text segmentation divides a given text
document into consecutive non-overlapping topically cohesive seg-
ments [1]. Each segment consists of several consecutive sentences.
Most existing works follow a similar idea that the boundaries of
consecutive segments correspond to a change in word usage. The
boundaries between segments are often detected by monitoring the
drop of the lexical similarity. The proposed solutions diﬀer widely
in the way of calculating the sentence-pair similarity (i.e., topical

524Figure 1: The framework of global knowledge bases guided
tweet segmentation [12], named GlobalSeg.

cohesiveness). Measures based on word co-occurrence [2, 9, 10]
and generative models [1, 18, 20, 23] have been extensively stud-
ied. The determination of the segment boundaries may not only
be purely based on the local sentence-pair similarities but also be
based on the global information derived from the distribution of the
lexical similarities of the far neighboring sentences [2,10]. Concep-
tually, the idea of incorporating the global information for bound-
ary determination is similar to our idea of exploiting local context
in tweets for tweet segmentation. However, the two problems (text
segmentation and tweet segmentation) are diﬀerent by deﬁnition
and the techniques for text segmentation cannot be directly applied
in tweet segmentation.

3. GLOBAL KNOWLEDGE GUIDED TWEET

SEGMENTATION

Global knowledge bases like Wikipedia and Microsoft Web N-
Gram corpus [24] have been successfully utilized to guide the tweet
segmentation, which is named GlobalSeg by this paper.
In this
section, we brieﬂy review its process, as illustrated by Figure 1.

The input of GlobalSeg is a tweet d = w1w2 . . . wℓ, and its output
is m (m ≤ ℓ) non-overlapped segments, d = s1s2 . . . sm, where a
segment si is a n-gram (n ≥ 1). The optimal segmentation is to
maximize the sum of stickiness scores of m segments:

arg max
s1,...,sm

m

Xi=1

C(si),

where C(s) denotes a stickiness function, deﬁned as:

C(s) = L(s) · eQ(s) ·

2

1 + e−SCP(s) .

(1)

(2)

Eq. 2 encodes three factors for measuring the stickiness of each
segment. They are: 1) the normalized segment length L(s) = 1
if |s| = 1 and L(s) = |s|−1
if |s| > 1 which moderately alleviates
|s|
the penalty on long segments; 2) the probability that s is inside
an anchor text in Wikipedia Q(s); 3) the Symmetric Conditional
Probability (SCP) measure deﬁned by

Pr(s)2

i=1 Pr(w1 . . . wi) Pr(wi+1 . . . w|s|)

,

(3)

SCP(s) = log

1

|s|−1 P|s|−1

Pr(s) is the n-gram probability provided by Microsoft Web N-Gram
service. If s is a single word w, SCP(s) = 2 log Pr(w). If s contains
more words, SCP tends to keep a cohesive s while all its possible
binary partitions are not cohesive.

4. HYBRID-CONTEXT BASED TWEET SEG-

Figure 2: The framework of Hybrid-context based tweet seg-
mentation, named HybridSeg.

Figure 3: The iterative process of HybridSeg.

Despite its successful application in named entity recognition, it
has two inherent limitations based on the below observations.

Observation 1. Tweets are not topically independent to each

other within a time window.

In GlobalSeg, all tweets are segmented independently. This as-
sumption is too strong as tweets published closely in time often
talk about the same theme. These similar tweets largely share the
same segments. For example, similar tweets have been grouped
together to collectively detect events from tweets, and the event is
usually represented by the common discriminative segments across
tweets [11]. However, there is no mechanism in GlobalSeg to force
similar tweets to be segmented consistently.

Observation 2. Linguistic features of the tweets are not always

useless.

In GlobalSeg, the local linguistic features of a segment in its tweet
has been abandoned completely. This assumption is mostly true
especially when tweets contain many unreliable linguistic features
like misspellings, informal abbreviations and unreliable capitaliza-
tions [21]. However, there indeed exist tweets composed in proper
English. For example, some tweets are published by oﬃcial ac-
counts of news agencies, organizations, advertisers, and celebrities.
For these tweets, the local linguistic features can be an informative
source for tweet segmentation.

The two observations essentially reveal the same phenomenon:
except for the external knowledge bases, local information like the
other similar tweets within a time window or the linguistic features
in the current tweet can also help in segmenting tweets. As both
similar tweets and linguistic features refer to the local contexts of
tweets, they lead to our novel idea of incorporating local contexts
into the existing external knowledge bases for better tweet segmen-
tation. Accordingly, we name our new method HybridSeg, short for
a hybrid-context based segmentation for tweets.

MENTATION

4.1 Framework of HybridSeg

GlobalSeg deﬁnes a tweet segmentation method solely based on
external knowledge bases (e.g., Wikipedia and Microsoft Web N-
Gram corpus). Its main assumption is that the external knowledge
bases provide more robust segmentation features for tweets than
their original natural languages which tend to be error-prone [12].

The general framework of HybridSeg is given in Figure 2. Com-
pared to Figure 1, the major novelty is that we would examine the
segment likelihood in a batch of tweets (including the tweet to be
segmented) based on local contexts. That is to say, given a batch
of tweets T within a certain time window, we are going to utilize

525Algorithm 1: Tweet Segmentation by HybridSeg

input :

output:

A tweet batch: T = {t1, t2, ...};
Oﬀ-the-shelf NERs: ri, r2, ..., rm;
µNER(λ): function for learning λ from weak NERs;
µIter(λ): function for learning λ from pseudo feedback;
Rλ: the search space of λ;

An optimal segmentation for the batch T :

S = {ti = si,1si,2...si,m};
/* iteration 0: learning from weak NERs

1 foreach ri do

*/

*/

/* apply NER ri to the tweet batch T
Sri ← recognize named entities by using NER ri;

2
3 M0 ← calculate ˆPNE (s) based on {Sri |i = 1, 2, ...m};
4 N∩ ← extract the named entities that are recognized by all m NERs.

/* apply λ learning with µNER(λ)

5 S0 ← segmentation with the optimal λ by using µNER(λ) and Rλ;

/* iteration 1, 2, ...: iterative learning

*/

*/

6 i=1;
7 while true do

8

9

10
11

12

13

i

(s) based on Si−1;

Mi ← calculate ˆPr
/* apply λ learning with µIter(λ)
*/
Si ← segmentation with the optimal λ by using µIter(λ) and Rλ;
/* calculate Jensen-Shannon divergence between the
segments in the last and current iterations
*/
jsd ← JSD(Si−1, Si)
if jsd < ε then

/* the stop criterion is met
break;

*/

i + +;

14 S ← Si;
15 return S as the optimal segmentation;

their local linguistic features collectively for each member tweet’s
segmentation.

However, how to separate valid segments from the chaﬀs in a
batch of tweets only based on local contexts is a challenging task
itself. To tackle this problem, we design an iterative process in our
framework, as shown in Figure 3.

Starting from a set of oﬀ-the-shelf NERs trained on classic En-
glish texts, we generate a collection of seed segments from T only
based on local linguistic features by voting. The seed segment
collection can be small yet highly conﬁdent. Then, we combine
the seed segment collection with the external knowledge bases in
HybridSeg to segment each tweet member. After that, only those
segments ranked high by HybridSeg are used to replace the seed
segment collection. The same process is then repeated until the
segmentation results of HybridSeg do not change any more.

There are a couple of advantages in our design. First, existing
NERs have already captured most known local linguistic features
so that we do not need to implement from scratch. Second, most
existing NERs are trained on formal texts. Applying them directly
on tweets will easily cause the overﬁtting error. A voting algorithm
can partially alleviate the error of training. Third, during each iter-
ation, only top segments with high conﬁdence scores are fed into
HybridSeg in a pseudo feedback manner, further alleviating the er-
rors caused by overﬁtting.

The tweet segmentation process of HybridSeg is outlined in Al-

gorithm 1. In the following, we elaborate HybridSeg step by step.

4.2 Learning from weak NERs

In this section, we apply m weak NERs on T to generate the ini-
tial collection of seed segments. Based on the truth that a named

entity is always a valid segment, we directly select the seed seg-
ments from the output of NERs.

Given a segment s, let fs be its total frequency in T . One NER
ri may recognize s as a named entity fri,s times. Note that fri,s ≤ fs
since a NER may only recognize some of s’s occurrences as named
entity. Assuming there are multiple oﬀ-the-shelf NERs r1, r2, . . . , rm,
we further denote f R
s
at least one occurrence of s as named entity,
I( fri,s) = 1 if fri,s > 0; I( fri,s) = 0 otherwise.

to be the number of NERs that have detected
i I( fri,s):

s = Pm

f R

We approximate the probability of s being a seed segment using

a voting algorithm deﬁned by Eq. 4:

m

1
m

ˆPrri (s),

ˆPr(s) = w(s, m) ·

Xi
w(s, m) = 1/(cid:16)1 + e−β( f R
s −m/2)(cid:17) ,
fri,s + ε!−
ˆPrri (s) =  1 +

fri ,s +ε

α

fs

.

(4)

(5)

(6)

Pm

Our approximation contains two parts. The right part of Eq. 4 (rf.
Eq. 6) is the average conﬁdence that one weak NER recognizes s as
named entity. A biased estimation of the right part is simply 1/m ·
i=1 fri,s/ fs as each fri,s/ fs is a noisy version of the true probability.
However, such simple average ignores the absolute value of fri,s
which can also play an important role here. For example, for a party
name in an election event, it can appear hundreds of times within a
tweet batch. However, due to the free writing styles of tweets, only
tens of the party name’s occurrences can be recognized by weak
NERs as named entity. In this case, fri,s/ fs is relatively small yet
fri,s is relatively high. Thus, we design a function that can favor
both fri,s/ fs and fri,s. The favor scale is controlled by a factor α.
When α is large, our function is more sensitive to the change of
fri,s/ fs; when α is small, a reasonably large fri,s can lead ˆPrri (s) to
be close to 1 despite of a relatively small value of fri,s/ fs. In this
paper we empirically set α = 0.2 in experiments. A small constant
ε is set to avoid dividing by zero.

The left part of Eq. 4, w(s, m) (rf. Eq. 5) uses a sigmoid function
to control the impact of the majority degree of m weak NERs on
seed segments, which is tuned by a factor β. For example, in our
paper we set β = 10 so that as long as more than half of weak NERs
recognize s as named entity, w(s, m) is close to 1. With a small β,
w(s, m) is getting closer to 1 only when more and more weak NERs
recognize s as named entity.

The learning from weak NERs is summarized in lines 1 - 5 in
Algorithm 1. Next, we discuss the combination of global knowl-
edge bases and seed segments. The learning of λ will be detailed
in Section 4.5.

4.3 Combination of knowledge bases and seed

segments

After computing the probability of s being a valid segment, we
can select top conﬁdent segments to be included in the seed seg-
ment collection. The next question is: how can we combine seed
segments with knowledge bases for better tweet segmentation?

Recall that GlobalSeg encodes three factors: segment length,
Wikipedia knowledge, and SCP measure based on Microsoft Web
N-gram corpus, among which the text partition mainly relies on
SCP measure. Now, the seed segment collection naturally provides
another information source to guide the text partition. The idea can
be as simple as assigning a high stickiness score to a partition in
the seed segment collection. Accordingly, we modify the partition
likelihood Pr(s) in SCP measure using a linear combination:

Pr(s) = (1 − λ)PrMS(s) + λ ˆPr(s),

(7)

526where ˆPr(s) is deﬁned by Eq. 4 with a coupling factor λ ∈ [0, 1),
and PrMS(·) is the n-gram probability provided by Microsoft Web
N-Gram service.

4.4 Pseudo feedback on seed segments

The last step of HybridSeg is to iteratively improve the seed seg-
ments using the output of HybridSeg, with the ﬁnal goal of improv-
ing its output in the end. The whole process will terminate until no
more changes are observed in the output of HybridSeg.

Suppose at iteration i, HybridSeg outputs a set of segments {hs, f i
where f i
s is the number of times s is a segment at iteration i. Then,
f i
s / fs relatively records the segmentation conﬁdence of HybridSeg
on s at iteration i (recall that fs denotes the frequency of s in current
batch T ). Similar to Eq. 6, we denote

s i},

i

ˆPr

(s) =  1 +

α

s + ε!−

f i

fs
f i
s +ε

.

Following the same combination strategy deﬁned by Eq. 7, we

have the following iterative updating function:

Pri+1(s) = (1 − λ)PrMS(s) + λ ˆPr

i

(s),

(8)

Interestingly, we can treat learning weak NERs as the 0th iteration
and change Eq. 7 to:

Pr1(s) = (1 − λ)PrMS(s) + λ ˆPr

0

(s),

0

where ˆPr
(s) is the voting result on m weak NERs only. The it-
eration process will stop when predeﬁned criterion is met. Here,
we deﬁne the stop criterion based on Jensen-Shannon divergence
(JSD) of the frequency distributions of tweet segments in two con-
secutive iterations. Note that, in the 0th iteration, some segments
may be wrongly segmented because of the errors introduced by the
weak NERs. These errors could be further propagated at later itera-
tions. For this reason, we do not consider the segments detected by
weak NER whose frequency is smaller than 3 in the 0th iteration.

The learning from pseudo feedback is summarized in lines 7 - 13

in Algorithm 1.

4.5 Learning the parameter λ

Eq. 8 deﬁnes the iterative learning process of HybridSeg. The
coupling factor λ is crucial to control the convergence of learning
and the segment re-ranking performance of the next iteration. To
guarantee the convergence and quality of our algorithm, we need a
systematic way to learn λ.

Our idea is: a good λ must ensure that top conﬁdent segments
from the previous iteration should be detected more times in the
next iteration. Note that at each iteration we do not classify text
partitions into binary classes (i.e., segment and non-segment), but
simply assign a stickiness score to each text partition and then treat
segmentation as a ranking problem. Therefore, our idea is equiva-
lent to maximizing the sum of detected frequency of top conﬁdent
segments (weighted by their stickiness scores, rf. Eq. 2) extracted
from the previous iteration. Accordingly, learning the parameter λ
is converted to an optimization problem as follows:

Table 1: Statistics of SIN and SGE datasets

Dataset

Collection period

SIN
SGE

Jun 01 - Jun 30, 2010
Apr 13 - May 13, 2011

#Tweets
4,331,937
226,744

#Annotations

4,422
3,328

Therefore, the optimal λ is intractable. In our experiments, we used
brute-force search strategy to ﬁnd the optimal λ for each iteration
and each tweet batch. Fortunately, as the size of each tweet batch is
controllable, the eﬃciency is not our concern in the current work.
Note that for the 0th iteration, λ must be learned diﬀerently be-
cause there do not exist top conﬁdent segments from the previous
iteration. Since we use the voting results of m weak NERs as the
seed segments in the 0th iteration, a good λ must ensure that the
conﬁdent segments voted by m weak NERs can be detected more
times by HybridSeg.

Let N∩ be the segments that are recognized by all m NER sys-
tems (i.e., N∩ = {s| f R
s = m}). For each segment s ∈ N∩, we con-
sider its conﬁdent frequency to be the minimum number of times
that s is recognized by a NER as named entity among all m NERs.
Let the conﬁdent frequency of s be fc,s. fc,s = minm
i fri,s. Then λ is
learnt as follows in the 0th iteration:

ˆλ = arg max

λ

µNER(λ) = arg max

λ Xs∈N∩

0

ˆPr

(s) · fc,s · f 0

s

(10)

0

(s) is the value computed using Eq. 4; ˆPr

0

0

0

(s) is low, or fc,s is small, or both conditions hold, then f 0

In this equation, ˆPr
(s) ·
fc,s serves as a weighting factor to adjust the importance of f 0
in
s
learning λ. If segment s is very likely to be a named entity (i.e.,
ˆPr
(s) is high) and it has been detected many times by all NERs
(i.e., fc,s is large), then the number of times s is successfully seg-
mented f 0
s has a big impact to the selection of λ. On the other hand,
if ˆPr
s is
less important to λ setting.
By deﬁning fc,s = minm

i fri,s, Eq. 10 conservatively considers seg-
ments recognized by all weak NERs because of the noisy nature of
tweets. This helps to reduce the possible oscillations resulted from
diﬀerent λ settings, since λ is a global factor (i.e., not per-tweet
dependent). On the other hand, we also assume that all the oﬀ-
the-shelf NERs are reasonably good, e.g., when they are applied on
formal text. If there is a large number of NERs, then the deﬁni-
tion of fc,s could be relaxed to avoid having too small values for all
segments, due to one or two poor-performing NERs among them.

5. EVALUATION

In this section, we evaluate HybridSeg against GlobalSeg as the
baseline. We conducted experiments on two datasets, i.e., the SIN
and SGE datasets that were used to evaluate GlobalSeg in [12].
Three weak NERs, namely, LBJ-NER, Standford-NER, and T-NER
were used as input in HybridSeg for learning local context. We
compare segmentation accuracy of HybridSeg against GlobalSeg.
Because GlobalSeg was used to detect named entities in [12], we
also report the accuracy of named entity recognition using Hybrid-
Seg and GlobalSeg respectively.

ˆλ = arg max

λ

µIter(λ)

= arg max

λ

Xs∈top-k at iteration i

Ci(s) · f i+1(s).

(9)

5.1 Dataset and Setting

Ci(s) is the stickiness score of s output by HybridSeg and used for
segment ranking at the previous iteration. Based on it, top-k seg-
ments can be retrieved. f i+1(s) is the detected frequency of s at the
current iteration, which is an unknown function of the variable λ.

Tweet Datasets. The SIN and SGE datasets were originally col-
lected for simulating two targeted Twitter streams in [12]. The for-
mer was a stream consisting of tweets from users in a speciﬁc ge-
ographical region (i.e., Singapore in this case), and the latter was
a stream consisting of tweets matching some predeﬁned keywords

527SIN Dataset
SGE Dataset

s
e
c
n
e
r
r
u
c
c
o

 
f

o

 
r
e
b
m
u
N

 1644

 256

 49

 16

 4

 1

 1

 4

 16

 64  128

 413  746

Named entity ID by frequency in descending order

Figure 4: Frequency distribution of the annotated NEs

and hashtags for a major event (i.e., Singapore General Election
2011 in this case).

Reported in Table 1, named entities in 4, 422 tweets from SIN
and 3, 328 tweets from SGE have been manually annotated to eval-
uate tweet segmentation and named entity recognition performance
in [12]. Table 2 reports the statistics of the annotated NEs in the
two datasets where f g
s denotes the number of occurrences (or fre-
quency) of segment s in the annotated ground truth G. The fre-
quency distributions of the NEs are plotted in Figure 4.

All the annotated tweets in each dataset were published on the
same day, making it possible to evaluate batch-mode tweet seg-
mentation using a day as the time interval. To fairly compare with
the results reported in [12], we conduct our experiments using all
the annotated tweets in each dataset as a batch so as not to take ad-
ditional context from other unlabeled tweets published in the same
day.

We also used the same Wikipedia dump (released on 30 Jan,
20103) as in [12]. This dump contains 3, 246, 821 articles and there
are 4, 342, 732 distinct entities appeared as anchor texts in these
articles.

Evaluation Metric. Recall that the task of tweet segmentation is
to split a tweet into semantically meaningful segments.
Ideally,
a tweet segmentation method shall be evaluated by comparing its
segmentation result against manually segmented tweets. However,
manual segmentation of a reasonably sized data collection is ex-
tremely expensive and requires good understanding of the tweets.
We therefore choose to follow [12] to evaluate a tweet segmenta-
tion method based on whether the manually annotated named enti-
ties are correctly segmented (i.e., split as segments). Because each
named entity is a valid segment, the annotated named entities in
this case serve as partial ground truth for the evaluation. We use
two measures, namely Recall and Frequency-biased Recall.

• Recall, denoted by Re, quantiﬁes the percentage of the man-
ually annotated named entities that are correctly split as seg-
ments. Because a segmentation method outputs exactly one
possible segmentation for each tweet, using annotated named
entities as partial ground truth, recall is the same as precision
in this setting. In fact, the same measure is named as pre-
cision in [12]. Note that each named entity appearing in a
speciﬁc position of a tweet is considered as one distinct in-
stance. For example, the phrase “pap pap pap!”, commonly
used to express a user’s strong support to the PAP party4 in
Singapore general election, consists of three distinct named
entity instances “pap”.

Table 2: The annotated named entities in SIN and SGE datasets

s max f g

#NEs s.t. f g

s > 1

Dataset

SIN
SGE

#NEs min f g
746
413

1
1

s P f g

s
1234
4073

49

1644

136
161

• Frequency-biased Recall, denoted by ReF , factors in the fre-
quency of the named entities in a batch of tweets. Because
the frequent named entities are often related to hot topics
or emerging events in the targeted Twitter stream, correctly
identifying these named entities as segments is critical for
downstream applications, like user opinion mining, topic dis-
covery, and event detection.
Let f g
s be the frequency of segment s in the ground truth G.
Let Re(s) be the recall of segment s ∈ G which is the per-
centage of segment s being correctly extracted from all oc-
currences of s in the annotated tweets. The frequency-biased
recall is deﬁned as follows:

ReF =

1

Z Xs∈G

log( f g

s + ε) · Re(s)

(11)

In this equation, Z is a normalization factor assuming all

named entities are corrected segmented (i.e., Z = Ps∈G log( f g

ε)). The logarithm function is applied to avoid domination of
few extremely frequent named entities, because of the power-
law like distribution of the NEs (see Figure 4). ε is a small
constant to avoid zero values for the named entities that have
only single appearance (ε = 0.001 in our experiments).

s +

Methods and Parameter Setting. We compare our HybridSeg
method with GlobalSeg method in [12] as the baseline. Note that
the method proposed in [12] is named TwiNER for named entity
recognition and segmentation was one of its intermediate step. In
this paper, GlobalSeg refers to the segmentation step in TwiNER.

The following three weak NERs are used in HybridSeg to de-
rive the local context knowledge (i.e., m = 3). Note that, we used
the version downloaded from their corresponding websites. These
NERs are not trained using our data.

• LBJ-NER is based on the regularized averaged perceptron
approach for learning and inference. It uses gazetteers ex-
tracted from Wikipedia, word class models derived from un-
labeled text corpus, and expressive non-local features [19].

• Stanford-NER is a NER system based on CRF model for
learning and inference. Besides the conventional linguistic
features, it also incorporates long-distance information [6].

• T-NER is a NER system designed for tweet corpus. It em-
ploys some tweet-speciﬁc features as well as the widely used
conventional features for formal text [21].

For parameter settings, α in Eq. 6 is set to α = 0.2; the top-K
segments in Eq. 9 for λ adaption is set to K = 50. The search space
for λ is set to be [0, 0.95] with a step 0.05.

5.2 Segmentation Accuracy

In this section we ﬁrst report the accuracy of the three weak
NERs in detecting named entities. We then compare HybridSeg
and GlobalSeg on segmentation accuracy.

3

4

http://dumps.wikimedia.org/enwiki/

http://en.wikipedia.org/wiki/People’s_Action_Party

Accuracy of three Weak NERs. The accuracy of the three weak
NERs in recognizing named entities is evaluated by three standard

528Table 3: Accuracy of the three weak NERs; N∩ denotes the set
of NEs detected by all three weak NERs. The best results are in
boldface.

Table 4: Performance of tweet segmentation algorithms, where
∗ indicates the diﬀerence against the baseline is statistically sig-
niﬁcant by paired t-test.

Method

Pr

0.335
LBJ-NER
0.273
T-NER
Stanford-NER 0.447
All NERs N∩
0.578

SIN
Re

0.357
0.523
0.448
0.233

F1

0.346
0.359
0.447
0.332

Pr

0.674
0.696
0.685
0.876

SGE
Re

0.402
0.341
0.623
0.192

F1

0.504
0.458
0.653
0.315

Method

GlobalSeg
HybridSegNER
HybridSegNER+Iter

SIN

SGE

Re
0.758
0.857∗
0.858∗

ReF
0.799
0.932∗
0.940∗

Re
0.874
0.942∗
0.946∗

ReF
0.756
0.879∗
0.885∗

metrics: Precision (Pr), Recall (Re), and F1. Pr measures the per-
centage of the recognized named entities that are true named enti-
ties; Re measures the percentage of the true named entities that are
correctly recognized; and F1 = 2 · Pr · Re/(Pr + Re) is the harmonic
mean of Pr and Re. The type of the named entity (e.g., person,
location, and organization) is ignored as in [12]. Similar to the seg-
mentation recall measure, each occurrence of a named entity in a
speciﬁc position of a tweet is considered as one instance for the
three measures Pr, Re, and F1.

Table 3 reports the performance of the three weak NERs on the
two datasets SIN and SGE respectively. Observed from the table,
all three weak NERs perform poorly on the two tweets collections.
The results are consistent with that reported in [12]. However, if
consider the set of NEs that are recognized by all three NERs N∩,
the precision is much higher than any of the individual weak NER.
In particular, the precision on SGE dataset is 0.876. That is, the
set of NEs detected by all the three NERs are of good precision
and can be used as local context knowledge in improving tweet
segmentation. On the other hand, the recall of N∩ is much lower
than any of the three NERs as expected.

Segmentation Accuracy. We report two sets of results for Hybrid-
Seg and compare them with the baseline GlobalSeg. Speciﬁcally, in
Table 4, we report the results of HybridSegNER after learning from
weak NERs, and the results of HybridSegNER+Iter after the iterative
learning converges in HybridSeg. We make three observations from
the results:

1. Learning from the local context brought in by weak NERs,
HybridSegNER signiﬁcantly improves tweet segmentation ac-
curacy on both datasets;

2. HybridSegNER+Iter further improves Re and ReF on both datasets.

However, the amount of improvement on top of HybridSegNER
is relatively small on both datasets; and

3. Compared with the baseline method GlobalSeg, the proposed
HybridSegNER+Iter improves Re by 13.2% and 8.2% respec-
tively on SIN and SGE datasets. Considering segment fre-
quency in the evaluation using ReF measure, much larger im-
provements are achieved, 17.6% on SIN and 17.1% on SGE.

Our experimental results show that, incorporating local context
knowledge in a batch of tweets greatly improves tweet segmenta-
tion accuracy. More importantly, the local context knowledge can
be obtained with almost no cost with oﬀ-the-shelf NERs and lo-
cally derived statistics. On the other hand, the improvement made
by learning from pseudo feedback is relatively small compared to
the improvement made by learning from weak NERs. In the next
section, we conduct a detailed analysis of HybridSeg for possible
reasons.

l
l

a
c
e
R
d
n
a

 

 
y
t
i
l
i
t

 

U
d
e
z

i
l

a
m
r
o
N

l
l

a
c
e
R
d
n
a

 

 
y
t
i
l
i
t

 

U
d
e
z

i
l

a
m
r
o
N

 1

 0.95

 0.9

 0.85

 0.8

 0.75

 1

 0.95

 0.9

 0.85

 0.8

 0.75

µNER(λ)
Recall
Frequency-baised Recall

 0

 0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9

Value of λ

(a) SIN dataset

µNER(λ)
Recall
Frequency-baised Recall

 0

 0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9

Value of λ

(b) SGE dataset

Figure 5: Re, ReF and µNER(λ) (%) values of HybridSegNER with
varying λ in the range of [0, 0.95].

5.3 Algorithm Analysis

Impact of λ Adaption. We exploit the local context by using lin-
ear combination in the calculation of SCP score (rf. Eq. 7 and 8).
The choice of λ largely aﬀects the performance of the tweet seg-
mentation process. While a small λ may not suﬃciently exploit the
local context, a very large λ could make the local context dominate
the segmentation process which may adversely aﬀect the segments
with weak local context because of their limited number of occur-
rences.

Figure 5 demonstrates the impact of varying λ on HybridSegNER
in terms of Re and ReF in the 0th iteration (rf Eq. 10). For easy
demonstration, we plot the normalized score obtained by Eq. 10
with diﬀerent λ, denoted by µNER(λ) in the ﬁgure. Observe that
µNER(λ) is positively correlated with the performance metrics Re
and ReF on both datasets. In our experiments, we set the parameter
λ to be the smallest value leading to the best µNER(λ), i.e., λ = 0.5
on SIN and λ = 0.7 on SGE. Because λ is a global factor for all
member tweets in the batch and µNER(λ) is computed based on a
small set of seed segments. A larger λ may not aﬀect the segmen-
tation of the seed segments because of their conﬁdent local context,
but may cause some other segments to be wrongly split due to their
noisy local context. Observe there is minor degradation for both Re
and ReF on SIN dataset when λ > 0.45 although µNER(λ) remains

529Table 5: The performance of HybridSegNER+Iter up to 4 itera-
tions.

Iteration

0
1
2
3

SIN
ReF
0.932
0.940
0.940
0.940

Re

0.857
0.857
0.858
0.858

JSD

–

0.0059
0.0001

0

Re

0.942
0.946
0.946
0.946

SGE
ReF
0.879
0.885
0.885
0.885

JSD

–

0.0183
0.0003

0

the maximum. The impact of varying λ in the following iterations
is not plotted for the interests of space. Similar observations hold.

Analysis of the Iterative Learning. HybridSeg employs an itera-
tive strategy to learn from the segments produced in the previous
iteration. Table 5 reports the performance of HybridSeg and JSD
between the frequency distributions of the segments from two iter-
ations.

It is observed that HybridSeg converges after the second itera-
tion. To understand the possible reasons for the quick convergence,
we analyze the segments detected in each iteration. There are three
categories of them:

• Fully detected segments (FS): all occurrences of the seg-
ments are detected from the batch of tweets. Their Pr(s) is
further increased by considering their local context. No more
occurrences can be detected on this category of segments in
the next iteration.

• Missed segments (MS): not a single occurrence of the seg-
ment is detected from the previous iteration. In this case, no
local context information can be derived for them to increase
their Pr(s). They will be missed in the next iteration.

• Partially detected segments (PS): some but not all occurrences
of the segments are detected. For this category of segments,
local context can be derived from the detected occurrences.
Depending on the local context, Pr(s) will be adjusted. More
occurrences may be detected or missed in the next iteration.

Table 6 reports the number of segments and their number of oc-
currences in each of the three sets (FS, MS, and PS). For partially
detected segments, the number of detected and missed occurrences
are reported.

As shown in the table, very few segments are partially detected
after learning from weak NERs in 0th iteration (19 for SIN and 24
for SGE). The possible improvement can be made in the next itera-
tion is to further detect the total 25 missed occurrences in SIN (resp.
67 in SGE), which accounts for 2.03% (resp. 1.64%) of all anno-
tated NEs in the dataset. That is, the room for further performance
improvement by iterative learning is marginal.

Consider the SIN dataset, on average, there are about 6 detected
occurrences to provide local context for each of the 19 partially
detected segments. With the local context, HybridSeg manages to
reduce the number of partially detected segments from 19 to 11 in
the next iteration and the total number of their missed instances are
reduced from 25 to 14. No changes are observed for the remain-
ing 11 partially detected segments in iteration 2. Interestingly, the
number of fully detected instances increased by 2 in the last iter-
ation. The best segmentation of a tweet is the one maximizes the
stickness of its member segments (rf Eq. 1). The change in the
stickness C(s) of other segments leads to the detection of these two
new segments in the fully detected category, each occurs once in
the dataset.

In SGE dataset, the 24 partially detected segments reduce to 12
in the next iteration by learning from pseudo feedback. No change
to these 12 partially detected segments are observed in the next it-
eration, despite some of these segments have very strong local con-
text based on their detected occurrences. A manual investigation
show that the missed occurrences are wrongly detected as part of
some other longer segments. For example, “NSP”5 becomes part of
“NSP Election Rally” and the latter is not annotated as a named en-
tity. A further investigation shows that, probably based on its cap-
italization, “NSP Election Rally” is detected by weak NERs with
strong conﬁdence (i.e., all its occurrences are detected). Because of
its strong conﬁdence, “NSP” cannot be separated from this longer
segment in the next iteration regardless the setting of λ. We note
that although “NSP Election Rally” is not annotated in the ground
truth as named entity, it is indeed a semantically meaningful phrase.
On the other hand, a large portion of the occurrences for these 12
partially detected segments have been successfully detected from
other tweets.

Compared to the baseline GlobalSeg which does not take local
context, HybridSeg signiﬁcantly reduces the number of missed seg-
ments from 195 to 152, which is 22% reduction on SIN dataset. On
SGE dataset, the reduction is 20% from 140 to 112. Many of these
segments are fully detected in HybridSeg.

5.4 Application: Named Entity Recognition

In this section, we use Named Entity Recognition as a down-
stream application to evaluate the impact of tweet segmentation.
We ﬁrst brieﬂy review the TwiNER method for NER [12] and then
propose our own NER method taking tweet segment as input.

5.4.1 NER by Random Walk

TwiNER recognizes named entities by applying Random Walk on
the segments from a batch of tweets. The main assumption is that
a named entity often co-occurs with other named entities in a batch
of tweets while non-entity segments rarely co-occurs with named
entities. The weight of the co-occurrence between two segments
is measured by Jaccard Coeﬃcient. A random walk model is then
applied to the segment graph. Let ρs be the stationary probability of
segment s by applying random walk, the segment is then weighted
by:

y(s) = eQ(s) · ρs

(12)

In this equation, eQ(s) carry the same semantic as in Eq. 2, indicating
that a segment that frequently appears in Wikipedia as an anchor
text is more likely to be a named entity. With the weighting y(s),
the top K segments are considered as named entities.

5.4.2 NER by POS Tagger

Due to the short nature of tweets, the gregarious property could
be very weak in tweets. As shown in Table 2, 82% of the annotated
named entities appear only once in SIN (and 61% in SGE). We
choose to explore the part-of-speech tags in tweets for named entity
recognition by considering noun phrases as named entities.

We estimate the likelihood of a segment being a noun phrase
(NP) by considering the POS tags of its constituent words. Table 7
lists three POS tags that are considered as the indicators of a seg-
ment being a noun phrase. Let ws
i, j be the jth word of segment s in
its i-th occurrence, we calculate the probability of segment s being
an noun phrase as follow:

ˆPNP(s) = PiP j[ws

|s| · fs

i, j]

·

1

1 + e−5

( fs − ¯fs )
σ( fs )

(13)

5

http://en.wikipedia.org/wiki/National_Solidarity_Party_

(Singapore)

530Table 6: Fully detected, missed, and partially detected segments for GlobalSeg and HybridSeg (3 iterations). #NE: number of distinct
segments, #Occur: number of occurrences, #Detect: number of detected occurrences, #Miss: number of missed occurrences.

Dataset
Method/
Iteration

0
1
2

GlobalSeg

SIN dataset

SGE dataset

Fully detected
#NE #Occur
581
581
583
504

944
959
961
647

Missed

Partially detected

#NE #Occur
146
154
152
195

152
163
161
214

#NE #Detect
19
11
11
47

113
98
98
113

#Miss

25
14
14
85

Fully detected
#Appr
#NE
1464
295
291
1858
1856
289
234
708

Missed

Partially detected

#NE #Occur
94
110
112
140

168
191
193
336

#NE #Detect
24
12
12
40

2374
1996
1996
2850

#Miss

67
28
28
179

Table 7: Three POS tags as the indicator of a segment being a
noun phrase, reproduced from [7]

Tag
N
ˆ
$

Deﬁnition

common noun (NN, NNS)
proper noun (NNP, NNPS)

numeral (CD)

Examples

books; someone
lebron; usa; iPad
2010; four; 9:30

This equation considers two factors. The ﬁrst factor estimates the
probability as the percentage of the constituent words being labeled
with an NP tag for all the occurrences of segment s, where [w] is 1
if w is labeled as one of the three POS tags in Table 7, and 0 oth-
erwise; For example, “chiam see tong”, the name of a Singaporean
politician and lawyer6, is labeled as ˆˆˆ (66.67%), NVV (3.70%),
ˆVˆ (7.41%) and ˆVN (22.22%)7. By considering the types of all
words in a segment, we can obtain a high probability of 0.877 for
“chiam see tong”. The second factor of the equation introduces a
scaling factor to give more preference to frequent segments, where
¯fs and σ( fs) are the mean and standard deviation of segment fre-
quency.

The segments are then ranked by y(s) = eQ(s) · ˆPNP(s), i.e., replac-

ing ρs in Eq 12 by ˆPNP(s).

With two named entity recognition approaches, namely Random
Walk (RW) and POS tagging respectively, and two segmentation
methods, namely GlobalSeg and HybridSeg, we have four com-
binations to evaluate: GlobalSegRW , HybridSegRW , HybridSegPOS,
and GlobalSegPOS. Note that, GlobalSegRW is the same method
named TwiNER in [12].

We introduce another baseline method U nigramPOS, which use
POS Tagging without segmentation. Similar to the work in [3], we
extract noun phrases from the batch of tweets by using the follow-
ing regular expression.

NP := [ˆN][ˆN$]∗

The regular expression states that a noun phrase can be a combi-
nation of common noun, proper noun and numeral, which begins
with common or proper noun. The conﬁdence of a noun phrase is
computed using a modiﬁed version of Eq. 13 by removing its ﬁrst
component.

In summary, we have ﬁve methods to evaluate: GlobalSegRW ,

HybridSegRW , HybridSegPOS, GlobalSegPOS, and U nigramPOS.

5.4.3 Experimental Results

Table 8 reports the performance of the 5 methods. The results
reported is the highest F1 of each method achieved for varying K >
50 following the same setting in [12]. Three observations are made.

6
http://en.wikipedia.org/wiki/Chiam_See_Tong
7V:verb including copula, auxiliaries; for example, might, gonna, ought, is, eats.

Table 8: The performance of GlobalSeg and HybridSeg with
Random Walk and POS for NER
SIN dataset

SGE dataset

Pr

0.516
0.576
0.618
0.647
0.685

Re

0.190
0.335
0.343
0.306
0.352

F1

0.278
0.423
0.441
0.415
0.465

Pr

0.845
0.929
0.907
0.903
0.911

Re

0.333
0.646
0.683
0.657
0.686

F1

0.478
0.762
0.779
0.760
0.783

Method

U nigramPOS
GlobalSegRW
HybridSegRW
GlobalSegPOS
HybridSegPOS

1. Tweet segmentation greatly improves NER. U nigramPOS is
the worst performer on all three evaluation metric Pr, Re, F1
among all methods.

2. For a speciﬁc NER approach, either Random Walk or POS
based, better segmentation results lead to better NER accu-
racy. That is, HybridSegRW performed better than GlobalSegRW
and HybridSegPOS performed better than GlobalSegPOS on all
evaluation metrics.

3. Without local context in segmentation GlobalSegPOS is slightly
worse than GlobalSegRW by F1. However, with much bet-
ter segmentation results, HybridSegPOS is much better than
HybridSegRW . By F1 measure, HybridSegPOS achieves the
best NER result.

Figure 6 plots the Precision@K for the 5 methods on the two
datasets with varying K from 20 to 100. The Precision@K reports
the ratio of named entities among the top-K ranked segments by
each method. Note that, Precision@K measures the ranking of the
segments detected from a batch of tweets; the occurrences of each
segment in the ranking are not considered. This is diﬀerent from
the measures (e.g., Pr) reported in Table 8 where the occurrences
of the named entities are considered (i.e., whether a named entity is
correctly detected at a speciﬁc position in a given tweet). We made
the following observations from Figure 6.

On SIN dataset, it is clear that all methods using POS tagging
for NER enjoy much better precision. RW based methods deliver
much poorer precisions due to the lack of co-occurrences in the
tweets. As reported in Table 2, 82% of the annotated named enti-
ties appear only once in SIN. Among the three POS based methods,
HybridSegPOS dominates the best precisions on all K values from 20
to 100. On SGE dataset, the diﬀerences in precisions between POS
based methods and RW based methods become smaller compared
to those on SIN dataset. The reason is that in SGE dataset, about
39% of named entities appear more than once, which makes a much
larger chance of co-occurrences. Between the two best performing
methods HybridSegPOS and GlobalSegPOS, the former outperformed
the latter on 6 K values plotted between 40 and 90. Without seg-
mentation U nigramPOS performed poorly in terms of Precison@K
measure on SGE dataset.

531K
@
n
o
s
c
e
r
P

i

i

K
@
n
o
s
c
e
r
P

i

i

UnigramPOS
GlobalSegRW
HybridSegRW
GlobalSegPOS
HybridSegPOS

 1

 0.9

 0.8

 0.7

 0.6

 0.5

 0.4

 20

 30

 40

 50

 60

 70

 80

 90

 100

Value of K

(a) SIN

UnigramPOS
GlobalSegRW
HybridSegRW
GlobalSegPOS
HybridSegPOS

 1

 0.9

 0.8

 0.7

 0.6

 0.5

 0.4

 0.3

 20

 30

 40

 50

 60

 70

 80

 90

 100

Value of K

(b) SGE

Figure 6: Precision@K on two datasets

6. CONCLUSION

Recently, tweet segmentation has been proven to be eﬀective in
the tasks of NER, event detection, and summarization. In this pa-
per, we present a novel framework HybridSeg, which aggregates
both the local context knowledge and the global knowledge bases
in the process of tweet segmentation. First, HybridSeg exploits the
local linguistic features in a collective manner by using the exist-
ing NER tools. The recognized named entities with high conﬁ-
dence positively enhance the performance of tweet segmentation.
Moreover, information that has not been well captured in the global
knowledge bases is derived based on all segments from the tweets.
Then, HybridSeg iteratively learns a better segmentation by consid-
ering conﬁdent seed segments in the previous iteration. Through
extensive experiments, we show that HybridSeg signiﬁcantly out-
performs the existing state-of-the-art algorithm on tweet segmenta-
tion. We also show that the better segmentation beneﬁts the named
entity recognition application in tweets. In future, we plan to take
more local factors into consideration for tweet segmentation, such
as local word dependency.

7. REFERENCES
[1] D. Beeferman, A. Berger, and J. Laﬀerty. Statistical models

for text segmentation. Mach. Learn., 34(1-3):177–210, 1999.

[2] F. Y. Y. Choi. Advances in domain independent linear text

segmentation. In NAACL, pages 26–33, 2000.

[3] F. C. T. Chua, W. W. Cohen, J. Betteridge, and E.-P. Lim.

Community-based classiﬁcation of noun phrases in twitter.
In CIKM, pages 1702–1706, 2012.

[4] J. E. Chung and E. Mustafaraj. Can collective sentiment
expressed on twitter predict political elections? In AAAI,
2011.

[5] A. Cui, M. Zhang, Y. Liu, S. Ma, and K. Zhang. Discover
breaking events with popular hashtags in twitter. In CIKM,
pages 1794–1798, 2012.

[6] J. R. Finkel, T. Grenager, and C. Manning. Incorporating

non-local information into information extraction systems by
gibbs sampling. In ACL, pages 363–370, 2005.

[7] K. Gimpel, N. Schneider, B. O’Connor, D. Das, D. Mills,
J. Eisenstein, M. Heilman, D. Yogatama, J. Flanigan, and
N. A. Smith. Part-of-speech tagging for twitter: annotation,
features, and experiments. In ACL-HLT, pages 42–47, 2011.

[8] B. Han and T. Baldwin. Lexical normalisation of short text

messages: Makn sens a #twitter. In ACL, pages 368–378,
2011.

[9] M. A. Hearst. Texttiling: segmenting text into

multi-paragraph subtopic passages. Comput. Linguist.,
23(1):33–64, Mar. 1997.

[10] A. Kazantseva and S. Szpakowicz. Linear text segmentation
using aﬃnity propagation. In EMNLP, pages 284–293, 2011.

[11] C. Li, A. Sun, and A. Datta. Twevent: segment-based event

detection from tweets. In CIKM, pages 155–164, 2012.

[12] C. Li, J. Weng, Q. He, Y. Yao, A. Datta, A. Sun, and B.-S.
Lee. Twiner: Named entity recognition in targeted twitter
stream. In SIGIR, pages 721–730, 2012.

[13] K.-L. Liu, W.-J. Li, and M. Guo. Emoticon smoothed

language models for twitter sentiment analysis. In AAAI,
2012.

[14] X. Liu, S. Zhang, F. Wei, and M. Zhou. Recognizing named

entities in tweets. In ACL, pages 359–367, 2011.

[15] X. Liu, X. Zhou, Z. Fu, F. Wei, and M. Zhou. Exacting social

events for tweets using a factor graph. In AAAI, 2012.
[16] Z. Luo, M. Osborne, and T. Wang. Opinion retrieval in

twitter. In ICWSM, 2012.

[17] X. Meng, F. Wei, X. Liu, M. Zhou, S. Li, and H. Wang.
Entity-centric topic-oriented opinion summarization in
twitter. In KDD, pages 379–387, 2012.

[18] H. Misra, F. Yvon, J. M. Jose, and O. Cappe. Text

segmentation via topic modeling: an analytical study. In
CIKM, pages 1553–1556, 2009.

[19] L. Ratinov and D. Roth. Design challenges and

misconceptions in named entity recognition. In CoNLL,
pages 147–155, 2009.

[20] M. Riedl and C. Biemann. Topictiling: a text segmentation

algorithm based on lda. In ACL 2012 Student Research
Workshop, pages 37–42, 2012.

[21] A. Ritter, S. Clark, Mausam, and O. Etzioni. Named entity
recognition in tweets: An experimental study. In EMNLP,
pages 1524–1534, 2011.

[22] A. Ritter, Mausam, O. Etzioni, and S. Clark. Open domain

event extraction from twitter. In KDD, pages 1104–1112,
2012.

[23] M. Utiyama and H. Isahara. A statistical model for

domain-independent text segmentation. In ACL, pages
499–506, 2001.

[24] K. Wang, C. Thrasher, E. Viegas, X. Li, and P. Hsu. An

overview of microsoft web n-gram corpus and applications.
In HLT-NAACL, pages 45–48, 2010.

[25] X. Wang, F. Wei, X. Liu, M. Zhou, and M. Zhang. Topic

sentiment analysis in twitter: a graph-based hashtag
sentiment classiﬁcation approach. In CIKM, pages
1031–1040, 2011.

[26] G. Zhou and J. Su. Named entity recognition using an

hmm-based chunk tagger. In ACL, pages 473–480, 2002.

532