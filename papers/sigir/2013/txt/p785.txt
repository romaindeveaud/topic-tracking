Optimizing Top-N Collaborative Filtering via Dynamic

Negative Item Sampling

Weinan Zhang†, Tianqi Chen‡, Jun Wang†, Yong Yu‡

†Dept. of Computer Science, University College London

‡Dept. of Computer Science and Engineering, Shanghai Jiao Tong University
{w.zhang, j.wang}@cs.ucl.ac.uk, {tqchen, yyu}@apex.sjtu.edu.cn

ABSTRACT
Collaborative ﬁltering techniques rely on aggregated user
preference data to make personalized predictions. In many
cases, users are reluctant to explicitly express their prefer-
ences and many recommender systems have to infer them
from implicit user behaviors, such as clicking a link in a
webpage or playing a music track. The clicks and the plays
are good for indicating the items a user liked (i.e., positive
training examples), but the items a user did not like (nega-
tive training examples) are not directly observed. Previous
approaches either randomly pick negative training samples
from unseen items or incorporate some heuristics into the
learning model, leading to a biased solution and a prolonged
training period.
In this paper, we propose to dynamical-
ly choose negative training samples from the ranked list
produced by the current prediction model and iteratively
update our model. The experiments conducted on three
large-scale datasets show that our approach not only reduces
the training time, but also leads to signiﬁcant performance
gains.

Categories and Subject Descriptors
H.3.3 [Information Systems]: Information Search and Re-
trieval—Information Filtering

General Terms
Algorithms, Experimentation

Keywords
Ranking-Oriented Collaborative Filtering, Recommender Sys-
tems, Negative Item Sampling

1.

INTRODUCTION

Recommender systems have been widely used in various
Internet services. Collaborative Filtering (CF) is one of
the most widely used techniques for recommender systems.
It leverages the user-item preference (or rating) patterns
derived from a large amount of historic data to make the
recommendation. Diﬀerent recommendation scenarios could
result in diﬀerent CF models. Top-N recommendation is

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for proﬁt or commercial advantage and that copies bear
this notice and the full citation on the ﬁrst page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior speciﬁc permission and/or a fee. Request
permissions from permissions@acm.org.
SIGIR’13, July 28–August 1, 2013, Dublin, Ireland.
Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

one of the most common scenarios, where it delivers a top-
N ranked list of the most relevant items to the user for
each recommendation interaction. Thus the goal of top-N
CF modelling is to produce an optimal item rank function
given a user proﬁle [2]. As the rankings of the top items are
more important than lower ones, which is consistent with the
users’ top-down browsing behaviors, similar to the Learning
to Rank problem in text retrieval, rank biased performance
evaluation measures, such as NDCG and MAP, have been
used to evaluate the performance of top-N recommendation.
However, there is a signiﬁcant diﬀerence between CF and
text retrieval. There has been a large body of research
on ranking-oriented CF. Most solutions rely on pair-wise
comparison. Generally speaking, pair-wise CF approaches
ﬁrst sample some positive-negative item pairs for each us-
er, and then train the model parameters with the target
of correctly identifying the positive/negative item in each
pair [5]. Diﬀerent from the Learning to Rank problem in
text retrieval, where a candidate set of documents has been
given by the retrieval module, for ranking-oriented CF on
implicit user feedback there are always a huge number of
unobserved items (which the target user has not rated or
clicked) to be considered. Thus there is a signiﬁcant need
for sampling negative items from the unseen samples in the
collection1. For example, for each item with positive feed-
back, a number (usually between 1 and 5) of the unobserved
items are randomly sampled to act as the negative ones in
the training data of the pair-wise ranking model. In addition
to the pair-wise CF approaches, the list-wise approaches
inspired by Learning to Rank techniques for text retrieval
have also been introduced (e.g., [8]). However, due to their
diﬃculty in modeling the inter-list loss and ineﬃciency on
large scale datasets, list-wise CF approaches are not widely
used compared to pair-wise in ranking-oriented CF. In this
paper, we focus on pair-wise CF approaches using implicit
feedback data.

A popular pair-wise CF algorithms is Bayesian Personal-
ized Ranking (BPR) [5]. BPR uniformly samples negative
items for each positive item and optimizes the AUC mea-
sure, which is, unfortunately, not a rank biased performance
measure. Therefore, BPR does not distinguish the rank-
ing performance between the items ranked 1st and 1000th.
However, as discussed above, the rank biased performance
measures such as NDCG and MAP are more suitable as
top-N recommendation evaluation measures. Therefore, if
we want to optimize such measures, BPR actually performs

1As a training process, an acceptable target is to rank the
observed items (with positive feedback) higher than the
unobserved ones for each user, which makes it reasonable
to treat the unobserved items as negative samples.

785biased training. One intuitive solution to such problem
might be adding a learning weight for each pair. However,
we argue that such approach is almost useless because ran-
domly picking negative training items among such a huge
unobserved item set will make most pairs uniformly low
weight.

In this paper, we propose dynamic negative item sampling
strategies to optimize the rank biased performance measures
for top-N CF tasks. We hypothesize that during the train-
ing, any unobserved item should not be ranked higher than
any observed positive training items because 1) given the
fact that the large amount of unseen items in the collection
are negative, it is unlikely that an unobserved yet positive
item is to be selected from a sampling procedure; and 2) even
if it is a positive item, it should not be ranked higher than the
known positive ones, as long as it is ranked higher than other
unobserved items. Based on our hypothesis, we develop
our sampling strategies. Through experiments conducted
on three well-known large-scale CF datasets (Netﬂix, Yahoo!
Music, and Last.fm), we discover that choosing unseen items
with high ranking score given by the current training model
as negative samples will not only signiﬁcantly improve the
rank biased performance measures (eﬀectiveness), but also
accelerate the model convergence (eﬃciency).

2. PRELIMINARIES

To make this paper self-contained, we ﬁrst have a brief
review on the BPR model and LambdaRank [1] before we
present the dynamic negative item sampling strategies in
Section 3. First we start from BPR [5]. A basic latent
factor model is stated in Eq. (1).

ˆrui = μ + bu + bi + p

T
u qi

(1)

As a pair-wise ranking approach, BPR takes each item pair
as its training case for each user. The (implicit feedback)
training data for user u can be formalized as
Du = {(cid:2)i, j(cid:3)u|i ∈ Iu ∧ j ∈ I\Iu},

where I represents the whole item set and Iu represents the
set of items that user u has given positive feedback. The
cost on each item pair (cid:2)i, j(cid:3)u is deﬁned using area under
ROC curve (AUC) as

C((cid:2)i, j(cid:3)u) = zuδ(ˆrui − ˆruj),

(2)
where zu is the normalization term and loss function δ(ˆrui−
ˆruj) can be normally implemented as logistic loss2, which is
always explained as the inverse probability of ranking item
i higher than j.

δ(ˆrui − ˆruj) =

1

1 + eˆrui−ˆruj

(3)

The factor in SGD update rule for each parameter w is
written as

∂C((cid:2)i, j(cid:3)u)

∂w

∂C((cid:2)i, j(cid:3)u)
∂(ˆrui − ˆruj)

∂(ˆrui − ˆruj)

∂w

=
≡ λij (

∂ ˆrui
∂w

− ∂ ˆruj
∂w

),

(4)

where ∂ ˆrui
∂w belongs to the latent factor model parameter
updating, and λij can be regarded as the learning weight
for this pair. Just like the ranking performance optimization
in IR tasks, we can borrow the idea of LambdaRank [1] to
2In addition, δ(·) can be implemented using other functions
such as the 0-1 or hinge loss.

Current Item Ranking List

1.

2.

3.

4.

5.

6.

Two example pairs 
for posiƟve item 6

Item Pair <6,1>: 

NDCG = 0.302

Item Pair <6,4>: 

NDCG = 0.035

: Unobserved Item

: PosiƟve Item

Figure 1: An example rank list produced by the
current model. The pair with the item in rank 1
as the negative sample has a higher ΔN DCG weight
than the one with item in rank 4 as the negative
sample.

optimize the rank biased performance measures in top-N
CF tasks. We formulate a LambdaRank weight function as
f (λij , ζu), where ζu is the current item ranking list for user
u. Thus

∂C((cid:2)i, j(cid:3)u)

∂w

= f (λij , ζu)(

∂ ˆrui
∂w

− ∂ ˆruj
∂w

),

(5)

where f (λij , ζu) assigns a learning weight on each BPR pair
(cid:2)i, j(cid:3)u based on the current item ranking list ζu. By deﬁning
diﬀerent f (λij , ζu), we can obtain diﬀerent goals in various
item recommendation tasks.

In IR tasks with NDCG as target, f (λij , ζu) can be deﬁned

as (in [1])

f (λij , ζu) ≡ λijΔN DCGij ,

(6)

where ΔN DCGij is the absolute changed NDCG value for
the ranking list ζu if item i and j get switched. This im-
plementation is reasonable in IR but unfortunately imprac-
tical in top-N CF tasks. The reason is that to calculate
ΔN DCGij of diﬀerent item pairs, the system needs to rank
all the items. In IR tasks, the candidate documents returned
by the retrieval model have been limited to a small size
(e.g, 1,000). However, in top-N CF tasks, since there is
no query at all, all the unobserved items can be regarded as
candidates. Thus the ranking list is always large in size (e.g.,
624,961 for Yahoo! Music), which makes the ranking process
and the calculation of f (λij , ζu) very time-consuming.

3. DYNAMIC NEGATIVE ITEM SAMPLING
To solve this problem, we propose a series of negative item
sampling strategies. Suppose we have an ideal LambdaRank
weight function f (λij , ζu) for each possible training item pair
(cid:2)i, j(cid:3)u given the current item ranking list ζu, the main idea
is if we have a scheme that generates the training item pair
(cid:2)i, j(cid:3)u with the probability proportional to f (λij , ζu)/λij
(just like ΔN DCGij in the case of Eq. (6)), then we have
an almost equivalent training model.
3.1 Rank-aware Reject Sampling Strategies

Figure 1 gives an example of which item pair should have
a higher weight. As a general result, the item pairs whose
negative item has a higher ranking should be sampled with
higher probability. It satisﬁes regardless of the ranking of
the positive item. This is intuitively correct because the
higher ranked negative items hurt the ranking performance
of the current model more than the lower ranked ones; Even
if such unobserved item is a relevant one, ranking it lower

786Algorithm 1 Ranking-Aware Reject Sampling - Linear
Require: Unobserved item set I\Iu, scoring function s(·),

parameter β
Draw sample j, l uniformly from I\Iu
Query s(j) and s(l)
if s(j) > s(l) then

Return j with probability 1

1+β , or return l otherwise

else

Return l with probability 1

1+β , or return j otherwise

end if

Algorithm 2 Ranking-Aware Reject Sampling - General
Require: Unobserved item set I\Iu, scoring function s(·),

parameters β1, β2 . . . , βn
Draw sample j1, . . . , jn+1 uniformly from I\Iu
Query s(j1), . . . , s(jn+1)
Sort j1, . . . , jn+1 by descending order of s(j1), . . . , s(jn+1)
Return one item from the sorted list with the multinomial
distribution {1, β1, β2 . . . , βn}/(1 +

(cid:2)n

k=1 βk)

than observed positive items is still reasonable. Thus more
training eﬀort should be paid on such pairs.

However, an eﬃciency problem arises as we have to rank
all unobserved items. Here we propose a ranking-aware
reject sampling algorithm to solve the ranking eﬃciency
problem. We need to draw a sample from the unobserved
item set I\Iu, and the probability of picking the item j as
the negative item satisﬁes

pj ∝ f (λij , ζu)/λij ≡ g(xj),

(7)
where g(xj) is a sampling weight function, and xj ∈ [0, 1]
is the relative ranking position of item j in the unobserved
item list. Here xj = 0 means ranking at the top and xj = 1
means ranking at the tail. In addition, we suppose that the
items are ranked via the scores from a scoring function s(j).
Now the goal is to eﬃciently pick the items at higher rank
(with lower xj) with higher probability.

3.1.1 Linear Weighting Function

We ﬁrst design the reject sampling procedure in Algorithm

1. Then the probability of item j to be sampled satisﬁes
Pr(s(j) ≤ s(l))

Pr(s(j) > s(l)) +

pj =

β

1

1 + β

1 + β

∝ (1 − xj) + βxj = −(1 − β)xj + 1 ≡ g(xj).

(8)

We can ﬁnd the sampling probability is a linear function
to the relative ranking position. Furthermore, the time
complexity is O(1), much lower than the brute-force version,
which requires O(|I\Iu|) computation time.
3.1.2 General Polynomial Weighting Function

We can generalize the sampling weight function to n-
degree polynomial ones with n + 1 samples to be drawn,
as shown in Algorithm 2. Then the probability of item j to
be sampled satisﬁes

pj ∝ 1C

0

n(1 − xj)

n

+

n(cid:3)

k=1

βkC

k
nx

k

j (1 − xj)

n−k

,

(9)

which is a polynomial function with degree of n. In partic-
ular, setting all βk = 0, we can get a scheme that picks the
top from n + 1 randomly selected items, which is O(n + 1)
time complexity. Figure 2 gives several examples of sampling
weight functions.

y
t
i
s
n
e
d

 
y
t
i
l
i

b
a
b
o
r
p

 

g
n

i
l

p
m
a
S

y
t
i
s
n
e
d

 
y
t
i
l
i

b
a
b
o
r
p

 

g
n

i
l

p
m
a
S

2

1.5

1

0.5

0

0

6

4

2

0

0

3

2

1

0.5

Relative ranking

5−Degree Polynomial

0

0

1

0.5

Relative ranking

10−Degree Polynomial

10

8

6

4

2

0

0

0.5

Relative ranking

0.5

Relative ranking

1

1

1

Figure 2: Illustrations for diﬀerent sampling weight
functions. Here for each function, all βk = 0.

Table 1: Characteristics of the datasets.
Dataset

Yahoo! Music

Last.fm

Users
Items

Netﬂix
480,189
17,770

1,000,990
624,961

992

961,417

Ratings

100,480,507

262,810,175

19,150,868

3.2 Relationship with Other Approaches

Due to the page limit, we will not give a general discussion
of related works in this paper, but focus on the relation-
ship between our approach and other related ones. So far,
we have proposed the dynamic negative item sampling s-
trategies to eﬃciently optimize the rank biased performance
measures for top-N CF tasks. This is essentially diﬀerent
from most ranking-oriented CF algorithms [6, 7, 9] where
ﬁrstly the target ranking function is somehow smoothed
and then a pair-wise or list-wise learning method is per-
formed. Our framework is adaptive to diﬀerent ranking
measures, just by deﬁning diﬀerent negative item sampling
strategies. Compared with LambdaRank [1] in IR tasks, we
point out the impractical computation cost problem in top-
N CF tasks, which makes clear that the dynamic negative
item sampling strategy is a key contribution of this work.
Among CF works, there are also some negative item sam-
pling considerations but they focus on diﬀerent performance
measures in other CF tasks, such as RMSE in one-class CF
[4] and serendipity in music/movie recommendation [3]. In
addition, none of these works involves dynamic negative item
sampling strategies.

4. EXPERIMENTS
4.1 Experiment Setup

We conduct our experiment on three widely used large-
scale CF datasets: Netﬂix, Yahoo! Music, and Last.fm. De-
tails of these three datasets are shown in Table 1. Following
the experiment setting of [3], we pick the 5-star ratings for
Netﬂix and 80 or higher ratings for Yahoo! Music as positive
feedbacks, and Last.fm itself is an implicit feedback dataset.
For training and test data splitting, we follow [3] to use the
original splitting on Netﬂix and Yahoo! Music; and we follow
[10] to give a 4:1 random splitting on Last.fm.

For comparison, since BPR is a strong baseline and we
mainly focus on the impact of dynamic negative item sam-
pling in this paper, here we only compare our approaches
with BPR. Both BPR and our approach (denoted as DNS)
are built based on SVD as in Eq. (1). Following [3, 10], the
factor number of SVD is set to 100. Similar experimental

787Table 2: Ranking performance comparison, where
“*” means signiﬁcant improvement.

Netﬂix

NDCG@5 NDCG@10

0.2052
0.2906
41.6%*

0.2017
0.2887
43.1%*

P@5
0.3826
0.4708
23.1%*

P@10
0.3272
0.4012
22.6%*

Yahoo! Music

P@5
0.1588
0.4243
167.2%*

P@10
0.1359
0.3671
170.1%*

NDCG@5 NDCG@10

0.1683
0.4458
164.9%*

Last.fm

0.1481
0.3981
168.8%*

P@5
0.1231
0.1323
7.5%*

P@10
0.1168
0.1202
2.9%

NDCG@5 NDCG@10

0.1270
0.1355
6.7%*

0.1207
0.1250
3.6%

MAP
0.1403
0.2036
45.1%*

MAP
0.0615
0.1644
167.3%*

MAP
0.0221
0.0223
0.9%

BPR
DNS
Impv.

BPR
DNS
Impv.

BPR
DNS
Impv.

results are observed for other CF algorithms such as SVD++
or SVD-Neighbourhood.

The evaluation measures include Precision@N [3], NDCG@N

[2], and MAP [6], all of which are rank biased performance
measures. Due to the page limit, we will not give the detailed
formulae of these measures.
4.2 Results and Discussion

4.2.1 Overall Ranking Performance

First we provide the overall performance of the compared
approaches on the three datasets, shown in Table 2. Here
the performance of DNS is equipped with the optimal sam-
pling strategy. From the result we can see the signiﬁcant
improvements brought from our approach on almost all the
measures and datasets, which shows the eﬀectiveness and
robustness of our approach.

Furthermore, among the three datasets, the improvement
on Yahoo! Music is the most signiﬁcant and the one on
Last.fm is the least. Actually, from the experiment we ﬁnd
the fact that BPR’s recommendation is somehow similar
with popularity-based recommendation since it performs the
uniform negative item sampling and optimizes AUC. This
is because the more popular an item is, the more times it
acts as positive sample in the pair-wise training. Therefore,
DNS is expected to lead larger improvements on the datasets
which are more long tailed3. From the analysis on these
datasets [3], we can see Yahoo! Music is actually the most
long tailed and Last.fm is the least, which is consistent with
our claim.

In addition, we also investigate the ranking performance

(NDCG@N ) against the polynomial degree of sampling weight
function in Figure 3. Here for each polynomial degree, we
only consider the function with all βk = 0 because the
non-zero βk cases act similarly with the considered ones.
From the result we can see that the polynomial degree has
diﬀerent improvement trend on diﬀerent datasets. By tuning
the polynomial degree of sampling weight function we can
empirically ﬁnd the optimal sampling strategy.

4.2.2 Convergency and Efﬁciency

From the time complexity analysis in Section 3.1.2, we
know that the time complexity is linear with respect to the
polynomial degree of the sampling weight function. How-
ever, this fact does not mean the higher-degree sampling
weight function is necessarily more ineﬃcient, because it can
requires fewer training rounds to get the model converged.
In Figure 4, we compare the performance convergence of
3The popularity-based recommendation generally works
worse on more long tailed datasets.

G
C
D
N

0.45

0.4

0.35

0.3

0.25

0.2

0.15

 
0

Yahoo! Music

 

Last.fm

 

0.135

0.13

0.125

0.12

G
C
D
N

 
0

NDCG@5
NDCG@10

2

4

6

8

10

12

Polynomial degree

NDCG@5
NDCG@10

5
Polynomial degree

10

15

20

Figure 3: NDCG Performance against polynomial
degrees on Yahoo! Music and Last.fm.

5
@
G
C
D
N

0.3

0.25

0.2

0.15

0.1

 
0

 

BPR
DNS−Lin
DNS−5
DNS−14

5000

10000

15000

Time (seconds)

Figure 4: Performance convergence against training
time on Netﬂix.

BPR and DNS with diﬀerent polynomial degrees against
the real training time on Netﬂix. From the result we can
see that within the same training time, DNS with the high-
er polynomial degree has a higher NDCG@5 performance,
and DNS has a faster convergency, which indicates that our
approach also has improvement on eﬃciency.

5. CONCLUSION AND FUTURE WORK

In this paper, we have proposed the dynamic negative item
sampling strategies to optimize the rank biased performance
measures for top-N CF tasks. Experimental results on three
well-known large-scale CF datasets verify the eﬀectiveness
and eﬃciency improvement of our approach.
In the fu-
ture work, we plan to leverage the dynamic negative item
sampling approaches to optimize other measures in recom-
mender systems such as item serendipity and freshness.
6. REFERENCES
[1] C. Burges, R. Ragno, and Q. V. Le. Learning to rank with

nonsmooth cost functions. In NIPS, 2007.

[2] N. Liu and Q. Yang. Eigenrank: a ranking-oriented approach to

collaborative ﬁltering. In SIGIR, 2008.

[3] Q. Lu, T. Chen, W. Zhang, D. Yang, and Y. Yu. Serendipitous

personalized ranking for top-n recommendation. In WI, 2012.

[4] R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. Lukose, M. Scholz, and

Q. Yang. One-class collaborative ﬁltering. In ICDM, 2008.

[5] S. Rendle, C. Freudenthaler, Z. Gantner, and

L. Schmidt-Thieme. Bpr: Bayesian personalized ranking from
implicit feedback. In UAI, 2009.

[6] Y. Shi, A. Karatzoglou, L. Baltrunas, M. Larson, A. Hanjalic,

and N. Oliver. Tfmap: optimizing map for top-n context-aware
recommendation. In SIGIR, 2012.

[7] Y. Shi, A. Karatzoglou, L. Baltrunas, M. Larson, N. Oliver,

and A. Hanjalic. Climf: learning to maximize reciprocal rank
with collaborative less-is-more ﬁltering. In RecSys, 2012.

[8] Y. Shi, M. Larson, and A. Hanjalic. List-wise learning to rank
with matrix factorization for collaborative ﬁltering. In RecSys,
2010.

[9] M. Weimer, A. Karatzoglou, Q. Le, A. Smola, et al.
Coﬁrank-maximum margin matrix factorization for
collaborative ranking. In NIPS, 2007.

[10] D. Yang, T. Chen, W. Zhang, Q. Lu, and Y. Yu. Local implicit

feedback mining for music recommendation. In RecSys, 2012.

788