Fresh BrowseRank

Maxim Zhukovskiy

Andrei Khropov

Gleb Gusev

Pavel Serdyukov

16 Leo Tolstoy St., Moscow, 119021 Russia

{zhukmax, akhropov, gleb57, pavser}@yandex-team.ru

Yandex

ABSTRACT
In the last years, a lot of attention was attracted by the prob-
lem of page authority computation based on user browsing
behavior. However, the proposed methods have a number of
limitations. In particular, they run on a single snapshot of a
user browsing graph ignoring substantially dynamic nature
of user browsing activity, which makes such methods recency
unaware. This paper proposes a new method for comput-
ing page importance, referred to as Fresh BrowseRank. The
score of a page by our algorithm equals to the weight in a
stationary distribution of a ﬂexible random walk, which is
controlled by recency-sensitive weights of vertices and edges.
Our method generalizes some previous approaches, provides
better capability for capturing the dynamics of the Web
and users behavior, and overcomes essential limitations of
BrowseRank. The experimental results demonstrate that
our method enables to achieve more relevant and fresh rank-
ing results than the classic BrowseRank.
Categories and Subject Descriptions: H.3.3 [Informa-
tion Storage and Retrieval]:
Information Search and Re-
trieval
General Terms: Algorithms, Experimentation, Performance
Keywords: Page authority, BrowseRank, freshness, web
search, learning
1.

INTRODUCTION

Web page authority scores are regarded as one of the most
useful features for ranking algorithms. There are many ap-
proaches to evaluation of page importance. Among them
there are those which analyze the user browsing histories.
Particularly, BrowseRank algorithm [1] measures the page’s
importance by its probability in the stationary distribution
of a continuous-time Markov process on the user browsing
graph. Despite undeniable advantages of BrowseRank and
its generalizations (see Section 2), these algorithms miss the
temporal aspect of the Web. Newer pages are probably more
relevant to recency sensitive queries than the older ones, and
therefore the temporal aspect of document relevance relates

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for proﬁt or commercial advantage and that copies bear
this notice and the full citation on the ﬁrst page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior speciﬁc permission and/or a fee. Request
permissions from permissions@acm.org.
SIGIR’13, July 28–August 1, 2013, Dublin, Ireland.
Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

to the to the ability of a browsing based page authority
measure to distinguish between relevant and irrelevant doc-
uments. With regard to web pages devoted to periodical
events such as news, government law issues, sport reviews
or conference homepages, a surfer looks for content likely
related to newer facts and events. By this reason the prob-
lem of constructing recency sensitive (or “fresh”) BrowseR-
ank should be of great interest for commercial web search
engines.

In this work we present the algorithm called Fresh BrowseR-

ank. We make our algorithm fresh-aware by weighting pages
according to their freshness. In order to show the eﬀective-
ness of Fresh BrowseRank, we compare it with the classic
BrowseRank on a large sample of user browsing graph and
demonstrate that our algorithm is better performing than
BrowseRank. To the best of our knowledge the proposed
algorithm is the ﬁrst fresh-aware ranking algorithm based
on the user browsing history.

The remainder of the paper is organized as follows. Sec-
tion 2 contains a short review of related approaches to mea-
suring page importance. In Section 3 we describe a frame-
work necessary to introduce our algorithm. We deﬁne Fresh
BrowseRank in Section 4.
In Section 5 we introduce the
method we employ for tuning of parameters of our algo-
rithm. The experimental results are reported in Section 6.
In Section 7 we discuss potential applications and future
work.

2. RELATED WORK

A widely used approach to page importance computation
is analysis of the web as a graph of pages connected with
hyperlinks. The most acknowledged link-based method is
PageRank (Page et al.
[2]). According to this algorithm
the score of a page p equals its weight in the stationary dis-
tribution of Discrete-Time Markov process which models a
random walk on the hyperlink graph. Such approaches of
computing web page authority have some weaknesses. Par-
ticulary, a signiﬁcant portion of pages and hyperlinks are
not reliable and not used by real users. The other items are
used with essentially diﬀerent level of activity. Therefore, a
random surfer modeled by using a plain hyperlink graph is
not realistic. In 2008 Liu et al.
[1] proposed BrowseRank,
which computes the page importance using user browsing
behavior data. The browsing graph contains richer informa-
tion such as staying times on web pages by users, number of
transitions between web pages by users. Unlike PageRank
algorithm based on a discrete random work, BrowseRank
exploits a Continuous-Time Markov Process driven by user

1029browsing statistics.This model provides a more realistic view
on pages’ importance. However, a proper web ranking al-
gorithm should possess some properties that BrowseRank
algorithm still does not. Liu et al. in [3], [4] proposed diﬀer-
ent generalizations of the algorithm which overcome some of
its imperfections. In [3] the authors introduce diﬀerent ways
of estimating the distribution of the staying time. In [4] a
Markov Skeleton Process is used to model the random walk
conducted by the web surfer. They show that this framework
can cover many existing algorithms (among them PageR-
ank, Usage-based PageRank [5], TrustRank [6], BrowseRank
Plus, MobileRank [7] as its special cases. The parameters of
these algorithms can be chosen in such a way that they be-
come classical BrowseRank. There are also other approaches
of computing page authority using user behavior data which
do not exploit random walk (see, for example, [8]).

An important problem which is not solved by all the men-
tioned algorithms is the recency ranking problem. As it is
shown in [9], the user browsing graph is changing signiﬁ-
cantly day by day. Therefore, pages with a high BrowseR-
ank score a few days ago can be not authoritative in the
present.

Yu et al.

[10] were among the ﬁrst to study algorithms
of link analysis sensitive to the temporal aspects of the
Web. The authors modiﬁed PageRank by weighting each
hyperlink according to its age. Other algorithms of recency-
sensitive link-based ranking were studied by Amitay et al. in
[11], Berberich et al. in [12] and [13], Yang et al. in [14], Dai
and Davison in [15]. The algorithm T-Fresh from the last
paper generalizes the ideas from the other above-mentioned
papers. However, T-Fresh has a number of shortcomings
which are overcome by the algorithm APR introduced by
Zhukovskii et al. in [16]. Both methods are based on graph
weightings that capture freshness of pages and hyperlinks.
Dai and Davison constructed two diﬀerent factors of page
importance that depend on pages’ freshness and links’ fresh-
ness respectively. In contrast to T-fresh, the freshness mea-
sure of APR depends on combined pages’ and links’ activi-
ties. This approach allows to control inﬂuence of both types
of activities on the assigned score. Following similar princi-
ples, we propose a solution to overcome the problem of re-
cency insensitivity of BrowseRank as we show in Section 6.
To the best of our knowledge this paper is the ﬁrst to pro-
pose a recency-sensitive variation of BrowseRank.

3. FRAMEWORK AND NOTATION

Popular search engines suggest users to install browser
toolbars that, among other useful features, monitor user
browsing sessions in order to use this aggregated information
later on to improve their search quality. The anonymized
information describing user behavior (visited pages, times
of visiting, submitted queries etc.) is stored in the brows-
ing log. We deﬁne the sessions and the user’s browsing
graph in the same way as Liu et al.
[1]. Let S be a user
session. We denote its pages by p1(S), p2(S), ..., pk(S)(S).
For each i ∈ {1, 2, ..., k(S) − 1} toolbar makes a record
pi(S) → pi+1(S). We call pages pi(S), pi+1(S) the neigh-
boring elements of the session S.

For each page p from the browsing log, we denote the num-
ber of sessions this page starts with by s(p). For each pair
of neighboring elements {pi, pi+1} from a session we denote
the number of sessions containing such a pair of neighboring
elements by I(pi, pi+1).

We deﬁne the user browsing graph G = (V, E) as follows.
The set of vertices V consists of all the web pages mentioned
in the browsing log and contains one additional vertex x.
The set of directed edges E represents all the ordered pairs
of neighboring elements {p1, p2}. The set E contains also
additional edges from the last pages of all the sessions to
the vertex x. Let σ(x) = 0. For any page p such that
p → x ∈ E denote the number of sessions ﬁnished with p by
I(p, x).

Let us remind the deﬁnition of BrowseRank. Reset proba-
bility σ(p) is a probability of choosing page p while we start
a new browsing session. It is proportional to the number of
sessions s(p) starting from the page p. Therefore σ(x) = 0.
Transition probability w(p1 → p2) is a probability of clicking
a hyperlink p1 → p2. It equals to I(p1, p2)/

(cid:32) (cid:80)

I(p1, p)

(cid:33)

.

p1→p∈E

The estimated staying time Q(p) of the page p is deﬁned in
[1]. BrowseRank of p equals Q(p)π(p), where

π(p) = ˜α(p)σ(p) + (1 − α)

ω(˜p → p)π(˜p)

(cid:88)

˜p(cid:54)=x: ˜p→p∈E

(the last equations hold for p = x as well), ˜α(p) = α(1 −
π(x)) + π(x).

Note that the transition probabilities do not depend on
the freshness of links and the user chooses old and fresh
links with the same probabilities. Therefore, we make the
transition probabilities fresh by weighting the links accord-
ing to the freshness scores of the destination pages. In the
next session we introduce this freshness measure.

4. FRESH BROWSERANK

Let us deﬁne the freshness measure of a page. We use the
framework from [16]. Consider two moments of time τ, T ,
τ < T . We divide the interval [τ, T ] into K parts: [ti−1, ti],
i ∈ {1, 2, . . . , K}, t0 = τ , ti − ti−1 = T−τ
K . For each page
p from V denote by t(p) the date when it was created. We
consider vertex x to be created at moment τ .
Let i ∈ {1, 2, . . . , K}. Let p ∈ V be a vertex created
before moment ti. We deﬁne the freshness score Fi(p) of p
in the i-th period of time in the following way.

1) We deﬁne the initial value F0

i (p) capturing freshness of

page p and its links as follows:

i (p) = a0ni(p) + b0mi(p), p (cid:54)= x,
F0

(1)

where a0, b0, are nonnegative parameters (which are learned
according to the method described in Section 6); ni(p) = 1 if
the vertex p is created in the i-th period, otherwise ni(p) =
0; mi(p) is the number of visits of page in the i-th period.
We set F 0

i (x) = 0.

2) Initial measure F0

i (p) is spreading over vertices by out-

going edges:

∆Fi(p) = µF0
(1 − µ)

i (p)+

(cid:88)

˜p(cid:54)=x: ˜p→p∈E

Wi(p)(cid:80)

p(cid:48)∈V : ˜p→p(cid:48)∈E

Wi(p(cid:48))

∆Fi(˜p), (2)

where µ ∈ [0, 1], Wi(p) is a score assigned by the “local”
freshness measure to the vertex p in the i-th period. This
measure is deﬁned in the same way as initial measure F0
i

1030(the values of the parameters may be diﬀerent from those of
the parameters in equation (1)),

Wi(p) = a1ni(p) + b1mi(p) +

nj(p), a1, b1 (cid:62) 0.

(3)

(cid:88)

j(cid:54)i

We want to “spread freshness measure” through outgoing
links from a page even if there are no fresh links among
them. Therefore we increase the weight of the page by 1
(the last summand in 3) if it was created before moment ti.
The system described in Equation 2 illustrates the inﬂuence
of neighbors on the freshness measure of the page.

3) Finally, freshness measure Fi is deﬁned as follows: Fi(p)
= βFi−1(p) + ∆Fi(p). The measure decreases exponentially
as time goes if there are no activities concerned with the
vertex p (the parameter β is from (0, 1)). Indeed Fi(p) =
βi∆F0(p) if there were no such activities during the period
[τ, ti].

In Equation 2 all considered vertices and edges are sup-

posed to be created before the time moment ti.

Let the freshness measure assign to page p in the graph
G the score FK (p). We make transition probability fresh
by replacing I(p1, p2) with I(p1, p2)FK (p2). In other words,
Fresh transition probability ωF(p1 → p2) of edge p1 → p2
and
equals to I(p1, p2)FK (p2)/
Fresh BrowseRank of p equals Q(p)πF(p), where

p: p1→p∈E I(p1, p)FK (p)

(cid:16)(cid:80)

(cid:17)

πF(p) = ˜α(p)σ(p) + (1 − α)

ωF(˜p → p)πF(˜p).

(cid:88)

˜p(cid:54)=x: ˜p→p∈E

Parameter

[τ, T ]

K
a0
b0
a1

b1

µ
α
β

Description

the considered period of time
the number of time intervals

the gain F0
i (p) receives if t(p) = i
the gain Wi(p) receives if t(p) = i

the gain F0

i (p) receives if

a user clicks to p in the i-th period

the gain Wi(p) receives if

a user clicks to p in the i-th period
damping factor for Fi(p) calculating

damping factor for FBR score calculating

the rate of decreasing of Fi(p)

Table 1: Parameters of Fresh BrowseRank.

In Table 1 we give the description of all the parameters of

the algorithm.

5. LEARNING

page p2 but i < j. The function h is a loss function. We
consider loss with margins bij > 0, where 1 (cid:54) i < j (cid:54) k:
h(i, j, x) = max{x+bij, 0}2. Let ω be a vector of parameters
of FBR. We minimize

(cid:88)

(cid:88)

(cid:88)

h(i, j, fq(p2) − fq(p1))

F (ω) =

1(cid:54)i<j(cid:54)k

q

p1∈V i

q ,p2∈V j

q

by a gradient based optimization method. A fresh ranking
algorithm requires frequent tuning of parameters. A simple
choice of values of parameters from a large set takes a lot of
time. Thus applying such simple choice makes it impossible
to get a fresh score improving a search quality. Let us in-
troduce the way we found the derivative ∂πF
. To the best
∂ωi
of our knowledge we are the ﬁrst to get derivatives of the
stationary distribution of Markov process when its transi-
tion probabilities are functions of a stationary distribution
of another Markov process (such nested Markov processes
are widely used, see [15], [16]). It is easy to ﬁnd the deriva-
tives ∂πF resh
, ∂πF
∂β as the solutions of the following system
of linear equations.

∂α

∂πF
∂α

(cid:88)

(p) = σ(p)

1 − πF(x) + (1 − α)

∂πF
∂α

(x)

+

ωF(˜p → p)

(1 − α)

∂πF
∂α

(˜p) − πF(˜p)

(4)

;

(cid:18)

(cid:18)

˜p(cid:54)=x: ˜p→p∈E

∂πF
∂β

(cid:88)

(cid:18)

˜p(cid:54)=x: ˜p→p∈E

(p) = σ(p)(1 − α)

(x) + (1 − α)×

∂πF
∂β

ωF(˜p → p)

∂πF
∂β

(˜p) +

∂ωF
∂β

(˜p → p)πF(˜p)

, (5)

(cid:19)
(cid:19)

(cid:19)

we get the derivative ∂w
following equation:

∂β (q → p) by ﬁnding ∂Fk
k−1(cid:88)

(i + 1)βi∆Fi+1(p).

∂FK
∂β

(p) =

i=0

∂β (p) from the

∂µ , ∂πF

∂a0 , ∂πF

∂a1 (derivatives ∂πF

Let us introduce the systems of linear equations with the
solutions ∂πF
∂b1 are the so-
lutions of the same equations). The ﬁrst equations of the
systems are the same with the equations of (5). We just
should choose the considered parameter instead of β. It re-
mains to ﬁnd ∂∆Fi

∂b0 , ∂πF

∂µ , ∂∆Fi

∂a0 , ∂∆Fi
∂a1 :

∂∆Fi

∂µ

(cid:88)

(p) = F 0

i (p)+

Wi(˜p → p)

˜p(cid:54)=x: ˜p→p∈E

(cid:18)

(˜p) − ∆Fi(˜p)

(6)

,

(cid:19)
(cid:33)

;

(1 − µ)

(cid:44)(cid:32)

∂∆Fi

∂µ

(cid:80)

(cid:88)
(cid:18)

Let fq(p) be the value of our feature for a page p and a
query q. We make it query-dependent by combining FBR
linearly with a query-dependent feature.

where Wi(˜p → p) = Wi(p)

Wi(p(cid:48))

p(cid:48)∈V : ˜p→p(cid:48)∈E

q , V 2

q , ..., V k
q

In other words, V 1
q

The training data contains a collection of queries and
sets of pages V 1
for each query q which are or-
dered from the most relevant (or fresh) to irrelevant (or not
fresh) pages.
is the set of all pages
with the highest score selected from among k labels, pages
from the set V k
q have the lowest score. For any two pages
q let h(i, j, fq(p2) − fq(p1)) be a value of
q , p2 ∈ V j
p1 ∈ V i
a penalty we get if the position of the page p1 according
to our ranking algorithm is higher then the position of the

∂∆Fi

∂a0 (p) = µni(p) + (1− µ)
(cid:88)

∂a1 (p) = (1 − µ)

∂∆Fi

˜p(cid:54)=x: ˜p→p∈E

Wi(˜p → p)

∂∆Fi
∂a0 (˜p);

˜p(cid:54)=x: ˜p→p∈E

Wi(˜p → p)

∂∆Fi
∂a1 (˜p)+

∂Wi

∂a1 (˜p → p)∆Fi(˜p)

(cid:19)

.

(7)

1031Parameters τ, T, K are chosen among a small number of vari-
ants. We consider the period of time [τ, T ] of the length
which is equal to 1 week. The parameter K is chosen in
such a way that the length of one period [ti−1, ti] is from
among 1 day, 6 hours, 3 hours and 1 hour.

6. EXPERIMENTAL RESULTS

All experiments are performed with pages and links crawled
in December 2012 by a popular commercial search engine.
We utilize all the records from the toolbar that were made
from 10 December 2012 to 16 December 2012. There are
113M pages and 478M transitions in the log. For ranking
evaluation we sampled a set of queries from the queries sub-
mitted by real users during the period from 14th till 17th
December. A query is a pair <text of query, time of submit-
ting>. For each query a set of URLs was judged by profes-
sional assessors hired by the search engine. When an asses-
sor judged a pair <query, URL> he assigned a label based
on both the freshness of the page in respect to the query
time and the topical relevance of the page to the query. Due
to speciﬁcs of the task, we consider only recency-sensitive
queries, which our algorithm is focused on. Hence, in order
to be relevant for such queries, the documents need to be
both fresh and topically relevant at the same time. Assessors
are instructed to consider documents to be fresh at least to
some degree if only the last access to the document according
to the toolbar logs took place not earlier than 3 days before
the time of the judged query. Finally, the above-described
procedure resulted into 200 judged recency-sensitive queries
(with 3000 judged query-URL pairs) for our evaluation.

The relevance score is selected from among the editorial
labels: Perfect, Excellent, Good, Fair, Bad. We divide our
data into two parts. On the ﬁrst part (75% of the dataset)
we train the parameters and on the second part we test
the algorithms. We compare Fresh BrowseRank with classic
BrowseRank in the following way used also by Dai and Davi-
son [15] and Zhukovskiy et al.
[16]. These algorithms are
combined linearly by ranks with BM25. Then parameters
for Fresh BrowseRank are chosen by maximizing the loss-
function in the way described in Section 5. The parameter
of linear combination with BM25 is chosen by maximizing
the Normalized Discounted Cumulative Gain (NDCG) met-
ric. We obtain the following parameters.

K = 24, a0 ≈ 5.2, b0 ≈ 1.0, a1 ≈ 6.9, b1 ≈ 1.1,

µ = 0.2, α = 0.18, β = 0.9.

The parameter K is chosen from the set {7, 28, 56, 168}. In
these cases the lengths of periods [ti−1, ti] equal to 1 day, 6
hours, 3 hours and 1 hour correspondingly.

Table 2 demonstrates the ranking performance on metrics

NDCG@5 and NDCG@10 over the algorithms.

Algorithm NDCG@5 NDCG@10

FBR
BR

0.71256
0.68312

0.784

0.75188

Table 2: Performance.

7. CONCLUSION

In this paper we introduce the new recency-sensitive al-
gorithm of user’s behavior analysis Fresh BrowseRank. We

compare it with BrowseRank. We test our algorithm on a
large data set and demonstrate that our algorithm is bet-
ter than BrowseRank. Besides our results being interesting
on their own, they may be used by commercial web search
engines for improving a search quality. It seems natural to
propose other recency-sensitive algorithms of user’s behavior
analysis based on our framework. By this reason we believe
that our approach will be the basis for the new research in
this area.

It would be interesting to study the other aspects of the
Web the user’s behavior analysis algorithms are missing. For
example, it is natural to introduce the layer of query nodes
into the graph.

We also introduce the method of training parameters of
nested Markov processes. It would be interesting to exploit
these algorithms for other algorithms based on such pro-
cesses.

8. REFERENCES
[1] Y. Liu, B. Gao, T.-Y. Liu, Y. Zhang, Z. Ma, S. He, H. Li,

BrowseRank: Letting Web Users Vote for Page
Importance. Proc. SIGIR’08, pp. 451–458 , 2008.

[2] L. Page, S. Brin, R. Motwani, and T. Winograd, The

PageRank citation ranking: Bringing order to the web.
http://dbpubs.stanford.edu/pub/1999-66, 1999.

[3] Y. Liu. T.-Y. Liu, B. Gao, Z. Ma, H. Li, A framework to

compute page importance based on user behaviors, Inf
Retrieval, 13: 22–45, 2010.

[4] B. Gao, T.-Y. Liu, Z. Ma, T. Wang, H. Li, A General

Markov Framework for Page Importance Computation,
Proc. CIKM’09, pp. 1835–1838, 2009.

[5] M. Eirinaki, M. Vazirgiannis, UPR: Usage-based Page

Ranking for Web Personalization, Proc. on Fifth IEEE
International Conference on Data Mining, pp. 130–137,
2005.

[6] Z. Gyongyi, H. Garcia-Molina, J. Pedersen, Combating web
spam with trustrank, Proc. InVLDB’04, pp. 576–587, 2004.

[7] B. Gao, T.-Y. Liu, Yu. Liu, T. Wang, Z.-M. Ma, H. Li,

Page Importance Computation Based on Markov Processes,
Inf. Retrieval, 14 (5), pp. 488–514, 2011.

[8] G. Zhu, G. Mishne, Mining Rich Session Context to

Improve Web Search, Proc. KDD’09, pp. 1037–1046 , 2009.

[9] Y. Liu, Y. Jin, M. Zhang, S. Ma, L. Ru, User Browsing

Graph: Structure, Evolution and Application, WSDM 2009,
2009.

[10] P. S. Yu, X. Li, and B. Liu, On the temporal dimension of

search. Proc. WWW’04, pp. 448–449, 2004.

[11] E. Amitay, D. Carmel, M. Herscovici, R. Lempel, and

A. Soﬀer. Trend detection through temporal link analysis.
Journal of the American Society for Information Science
and Technology, 55(14), pp. 1270–1281, 2004.

[12] K. Berberich, S. Bedathur, M. Vazirgiannis, G. Weikum.

Buzzrank... and the trend is your friend. Proc. WWW’06,
pp. 937–938, 2006.

[13] K. Berberich, M. Vazirgiannis, G. Weikum, Time-aware

authority ranking. Int. Math., 2(3), pp. 301–332, 2005.

[14] L. Yang, L. Qi, Y. P. Zhao, B. Gao, and T. Y. Liu. Link

analysis using time series of web graphs. Proc. CIKM’07,
pp. 1011–1014, 2007.

[15] Na Dai and Brian D. Davison, Freshness Matters: In

Flowers, Food, and Web Authority. Proc. SIGIR’10,
pp. 114–121, 2010.

[16] M. Zhukovskii, D. Vinogradov, G. Gusev, P. Serdyukov,

A. Raigorodkii, Recency-sensitive model of web page
authority. Proc. CIKM’12, pp. 2627–2630, 2012.

1032