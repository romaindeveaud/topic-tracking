A Novel Topic Model for Automatic Term Extraction 

 Sujian Li1         Jiwei Li1           Tao Song1           Wenjie Li2            Baobao Chang1 

1 Key Laboratory of Computational Linguistics (Peking University), Ministry of Education,  

School of Electronics Engineering and Computer Science, CHINA 

2 The Innovative Intelligent Computing Center, 

The Hong Kong Polytechnic University Shenzhen Research Institute, Shenzhen, CHINA 

{lisujian, bdlijiwei, stao, chbb} @pku.edu.cn; cswjli@comp.polyu.edu.hk 

 

ABSTRACT 
Automatic  term  extraction  (ATE)  aims  at  extracting  domain-
specific terms from a corpus of a certain domain. Termhood is one 
essential measure for judging whether a phrase is a term. Previous 
researches  on  termhood  mainly  depend  on  the  word  frequency 
information.  In  this  paper,  we  propose  to  compute  termhood 
based on semantic representation of words. A novel topic model, 
namely  i-SWB,  is  developed  to  map  the  domain  corpus  into  a 
latent semantic space, which is composed of some general topics, 
a background topic and a documents-specific topic. Experiments 
on  four  domains  demonstrate  that  our  approach  outperforms  the 
state-of-the-art ATE approaches.  
Categories and Subject Descriptors 
H.3.1 [Information Storage and Retrieval]: Content Analysis 
and Indexing – linguistic processing, Thesauruses.  
General Terms 
Algorithms, Experimentation. 
Keywords 
Term Extraction, Topic Model, Termhood. 
1.  INTRODUCTION 
So  far,  most  researches  on  automatic  term  extraction  have  been 
guided by two essential measures defined by [6], namely unithood 
and termhood. Unithood examines syntactic formation of terms or 
the  degree  (or  significance)  of  the  association  among  the  term 
constituents.  Termhood,  on  the  other  hand,  aims  to  capture  the 
semantic  relatedness  of  a  term  to  a  domain  concept.  However, 
there is no uniform definition of what is semantic relatedness, and 
how to compute termhood is still an open problem. 
Previous  researches  have  attempted  to  measure  termhood  by 
applying  several  statistical  measures  within  a  domain  or  across 
domains,  such  as  TF-IDF,  C-value/NC-value  [5],  co-occurrence 
[4] and inter-domain entropy [2]. These statistical measures often 
ignore  the  informative  words  with  very  high  frequency  or  very 
low frequency and do not take into account the semantics carried 
by terms. Taking the term “NRZ electrical input” in the electric 
engineering  domain  for  example,  “NRZ”  only  occurs  in  a  few 
documents  while  “electrical”  occurs 
in  many  documents 
frequently. Using TF-IDF to measure termhood, low scores will 
be assigned to both “NRZ” and “electrical”, which in turn causes 
the  term  “NRZ  electrical  input”  to  have  a  low  termhood.  It  is 

Permission  to  make  digital  or  hard  copies  of  all  or  part  of  this  work  for 
personal or classroom use is granted without fee provided that copies are 
not made or distributed for profit or commercial advantage and that copies 
bear  this  notice  and  the  full  citation  on  the  first  page.  Copyrights  for 
components  of  this  work  owned  by  others  than  ACM  must  be  honored. 
Abstracting  with  credit  is  permitted.  To  copy  otherwise,  or  republish,  to 
post on servers or to redistribute to lists, requires prior specific permission 
and/or a fee. Request permissions from permissions@acm.org. 
SIGIR’13, July 28–August 1, 2013, Dublin, Ireland. 
Copyright © 2013 ACM  978-1-4503-2034-4/13/07…$15.00. 

obvious that frequency-based measures will keep many real terms 
out of the door. In fact, a domain is described semantically from 
various aspects. Again, let’s take the electric engineering domain 
for  example.  The  words  like  “input”  emphasize  some  specific 
topic  in  a  domain  while  the  words  like  “electrical”  provide  the 
background  of  that  domain.  There  also  exist  a  cluster  of  words 
like  “NRZ”  which  occur  in  the  corpus  infrequently,  but  tend  to 
occur  in  a  few  documents  frequently.  Such  words  can  reflect 
some  special  characteristics  of  the  domain.  Based  on  these 
observations, we argue that three semantic aspects can be used in 
the  representation  of  words:  Domain  background  words  (e.g. 
electrical)  describe  the  domain  in  general.  Domain  topic  words 
(e.g. input) represent a certain topic in a given domain. Domain 
documents-specific  words  (e.g.  NRZ)  are  specific  to  a  small 
number  of  documents  and  exhibit  the  characteristics  of  the 
domain. We assume that a term can be recognized by identifying 
whether  its  constituent  words  belong  to  some  of  the  three 
semantic aspects. 
As  for  semantic  representation  of  words,  unsupervised  topic 
models  have  shown  their  advantages  [1]  [3].  Latent  Dirichlet 
Allocation  (LDA)  is  a  well-known  example  of  such  models.  It 
posits that each document can be seen as a mixture of latent topics 
and  each  topic  as  the  distribution  over  a  given  vocabulary.  To 
trade-off generality and specificity of words, Chemudugunta et al. 
[3]  further  defined  the  special  words  with  background  (SWB) 
model  that  allowed  words  to  be  modeled  as  originating  from 
general  topics,  or  document-specific  topics,  or  a  corpus-wide 
background topic. The existing work proves that topic models are 
competent for the semantic representation of words. However, to 
our  knowledge,  no  prior  work  has  introduced  such  kind  of 
semantic representation to term extraction. 
Inspired by Chemudugunta’s idea of generality and specificity [3], 
in this paper we propose a novel topic model, namely i-SWB to 
model  the  three  suggested  semantic  aspects.  In  i-SWB,  three 
kinds  of  topics,  namely background  topic,  general  topics,  and 
documents-specific  topic  are  correspondingly  constructed  to 
generate 
in  a  domain  corpus.  Compared  with 
Chemudugunta’s SWB model, there are two main improvements 
in i-SWB to tailor to term extraction. First, specificity in i-SWB is 
modeled at the corpus level and one documents-specific topic is 
set  to  identify  a  cluster  of  idiosyncratic  words  from  the  whole 
corpus.  Thus,  i-SWB  avoids  the  computationally  intensive 
problem in SWB where the number of  document-specific  topics 
grows  linearly  with  the  number  of  documents.  Second,  i-SWB 
makes  use  of  both  document  frequency  (DF)  and 
topic 
information to control the generation of words, while SWB only 
uses a simple multinomial variable to control which topic a word 
is  generated  from.  This  improvement  comes  from  the  following 
findings  that  have  been  verified  in  the  experiments:  the  words 
occurring in many documents and distributing over many general 

the  words 

885topics  with  higher  probability  in  LDA  are  likely  to  present 
background  information,  while  the  words  occurring  in  a  few 
documents only and distributing over a certain topic in LDA with 
medium or low probabilities are usually idiosyncratic and provide 
some special information of the domain. Next, with the semantic 
representation of words in i-SWB, we implement an ATE system 
which outperforms the existing ATE approaches. 

2.  MODEL DESCRIPTION 
2.1  LDA and SWB Fundamentals 
The  hierarchical  Bayesian  LDA  models  the  probability  of  a 
corpus on hidden topics as in Fig. 1(a). The topic distribution of 
each  document  θd  is  drawn  from  a  prior  Dirichlet  distribution 
Dir(α),  and  each  document  word  wd,n  is  sampled  from  a  topic-
z  specified  by  a  drawn  from  the  topic-
word  distribution 
document distribution θd. The topic assignments z for each word 
in the corpus can be efficiently sampled via Gibbs sampling, and 
the  predictive  distributions  for  θ  and    can  be  computed  by 
averaging over multiple samples.  



d

,d nz

(a)

D

dN

,d nw

T

t



,d nu

,d nw

,d nz

t

0

B

1





d

d

D

2

              

    

Figure 1. Graphical models for  (a) LDA and (b) SWB. 

To formulate background and special information, Chemudugunta 
et al. (2006) proposed the SWB model as illustrated in Fig. 1(b). 
In SWB, the variable ud,n acts as a switch: if ud,n = 0, the current 
word  is  generated  by  the  general  topics  as  in  LDA,  whereas  if 
ud,n=1  or  ud,n=2,  words  are  sampled  from  a  corpus  specific 
multinomial or a document-specific multinomial (with symmetric 
Dirichlet  priors  β1  and  β2)  respectively.  ud,n  is  sampled  from  a 
document-specific  multinomial  d  ,  and  it  has  a  symmetric 
Dirichlet prior γ.  Applying a Gibbs sampler on SWB, we can get 
the sampling equations for each word wd,n in document d: 

p

(

d n
,



0,

z

d n
,



t

|

w,x



(

d n
, )

,

z



(

d n
, )

,
, )
 

,

0



p

(

d n
,



1|

w x

,



(

d n
, )

,

z



(

d n
, )

,

)
 
1

,



p

(

d n
,



2 |

w x

,



(

d n
, )

,

z



(

d n
, )

,

)
 

,

2



N
N



d n
, )
3



d

0, (


d

, (


d n
, )



d n
, )

, (


d n
, )



C
TD
td
, (

C
TD
t d
'

'

t




d n
, )
3







d

1, (


, (


d n
, )



d n
, )
3





d

2, (


d

, (


d n
, )



N
N
d
N
N

C
WT
wt
, (

C
WT
w t

w

'





d n
, )

' , (


d n
, )


0
V



0

(1) 



T


C
WB
wb
C
'
C
WD
wd
C

, (

WB
w b
'

w

w

'

, (

WD
w d
'



d n
, )

, (


d n
, )


d n
, )

, (


d n
, )


1
V


   (2) 


1


2
V



2

(3) 

where –(d,n) indicates that the current word wd,n is excluded for 
the count, V denotes the vocabulary size, Nd is the number of the 
words in document d and Nd0, Nd1, and Nd2 are the number of the 
words  in  document  d  assigned  to  the  latent  topics,  background 
topic and document topics, respectively. 
tdC  is the number of the 
words that are assigned topic t in document d.  WT
wbC and  WD
wdC  
are the number of the words that wd,n is assigned to topic t, to the 
background topic and to the documents-specific topic respectively.   

wtC ,  WB

TD

,

)

w
d n
,

w
d n
,

p DF 
(

to  set  a  variable  (e.g.  d  in  SWB)  which  is  drawn  from  a 
symmetric  Dirichlet  prior.  As  a  rule  of  thumb,  document 
frequency (DF) information can be used as a determining factor to 
examine the specificity or generality of words related to a domain. 
In  addition,  we  use  the  word  distribution  in  general  topics  as 
another factor to determine the specificity and generality of words. 
Fig. 2 and 3 show the graphic model and the generation process of 
i-SWB.  Instead  of d,  a  three-dimensional  vector d,n  is  used  to 
control  topic  generation  and  its  value  is  determined  by  an 
experience  function 
 where 
 denotes  the 
document  frequency  of  the  word  wd,n  and 
denotes  the 
probability  vector  that  the  word  wd,n  distributes  over  all  the 
general topics. 
 
 
 
 
 
 
 

,d nwDF
,d nw

,d nu

,d nz

,d nw

d

DF

D



B

,d n

2

t

1

0

Figure 2．Graphical model of i-SWB. 

2

~



  
(
)

          draw 

1.  Draw
B Dir
2.  For each topic 


D Dir
)
(
 , 
~

1
T
t
]
[1,
: 
t Dir
(
)
  
~
0
3.  For each document 
D
d
[1,
d Dir
)
(
~
draw 
  

For each word wd,n : 
p DF

w
w
d n
d n
,
,
multi
(
  
)

, ~ (

i.   draw 
d n
ii.  draw 

d n
,
iii.  draw : 

(a) 
(b) 

~

: 

d n
,

]

,

)

 

if 
if 
if 

,

,

2
1
0

d n  , draw 
d n  , draw 
d n  , draw 
and 

d nw
, ~
d nw
, ~
z
, ~
d n
d nw
, ~

multi   
)D
multi    
)B
multi   
)
d
)d nz
multi   

(
(
(
(

,

,

Figure 3．Generation process of i-SWB. 

t

)

(1

topic 

t T

  

,  one  background 

To  formally  present  the  i-SWB  model,  let  V  be  the  vocabulary 
size  and  D  be  the  number  of  documents.  There  are  T  general 
B  and  one 
topics 
D  which  have  symmetric  Dirichlet 
documents-specific  topic 
priors of β0, β1 and β2 respectively. Each topic is characterized by 
a  distribution  over  the  V  words.  α  is  the  fixed  parameter  of 
symmetric Dirichlet prior for the D document-topic multinomials 
represented by a D×T matrix θ. Let wd,n be the observed variable 
representing the nth word in document d, ud,n the hidden variable 
denoting  which  kind  of  topic  wd,n  is  assigned  to,  and  zd,n  the 
hidden  variable  indicating  that  the  general  topic  wd,n  may  be 
assigned to.  

2.2  i-SWB Model 
In  i-SWB,  the  documents-specific  topic  is  defined  at  the  corpus 
level  and  the  corpus  is  composed  of  three  kinds  of  topics 
including background topic, documents-specific topic and general 
topics. To control the generation of these topics, a simple way is 

2.3  Model Inference 
We use a Gibbs sampler to perform model inference. Due to space 
limitation, we give the result of Gibbs Sampling directly. 

886P u
(

d n
,





(0)

d n
,



|

t



0,

z
d n
,
C
TD
td
d n
, ( , )


C
TD
t d
'

t

'

d n
, ( , )


w z
,
d n
( , )




T



P u
(

d n
,



1|

w z
,

,


d n
,

,

u



(

d n
, )

,)



(1)

d n
,

P u
(

d n
,



2 |

w z
,

,


d n
,

,

u



(

d n
, )

)



(2)

d n
,

'

w



,)


u
,
,

d n
d n
( , )
,

C
WT
wt
d n
, ( , )

C
WT
w t
d n
' , ( , )

C
WB
wb
,
(

C
WB
w b
'
w
'
C
WD
wd
,
(

C
WD
w d
'









w

,

'

d n
, )


0
V


0


1
V

d n
, )


2
V


d n
, )

d n
, )





(

(

,

          (4) 

 (5) 


1

(6) 


2

(1)
d n
,
DF
w
d n
,
D

Eqs. (4), (5) and (6) are similar to Eqs. (1), (2) and (3), except the 
,d n ,  whose 
first  terms  in  each  of  them.  Then,  we  determine 
value depends on 

,d nw  as follows: 

 and 

,d nwDF

   

(1

E

(

(0)
d n
,

))



w
d n
,

DF
w
d n
,
D

;    

E  

(

)d n

,

w

;    

   

(1

E

(

(2)
d n
,

w
d n
,

)) (1

 

)

         (7) 

(

E 

where 
that wd,n is assigned to each general topic.  

)d nw

,

 is  used  to  measure  the  evenness  of  distribution 



 

E

(



)



w

d n
,

C
W T
 
w
t
d n
,
C
W T
w
d n
,

t T


t

'

t
'
log

C
W T
w
t
d n
,

C
W T
w
d n
,

t

'

log

T

t

'

           (8) 

w tC
WT
,d n

 denotes the number of times that wd,n is assigned to 
where 
the general topic t. In Eq. (8), the numerator computes the entropy 
that  the  word  wd,n  is  assigned  to  the  general  topics,  and  the 
denominator  denotes  the  maximum  entropy  value  that  wd,n  is 
 is 
evenly assigned to each general topic. The range of 
(0,1].  The  experience  Equations  (7)  and  (8)  reflect  that  a 
background word is more likely to uniformly distribute on general 
topics  and  a  documents-specific  word  is  more  likely  to  have  a 
larger DF value. With one Gibbs sampling, we can also make the 
following estimation: 

E 

d nw
,

(

)

t

d





B

w





C
TD


td
C
T
TD


t d
'
t
'
C
WB


wb
1
V
C
WB

w b
'

w

'


1

, 

t

w



, 

D

w

,    




w

'

C
WT

wt
C
WT
w t
'
C
WD
wd
C


0
V


0


2
WD
V

w d
'

w

'




2

      (9) 

In  our  experiments,  we  set  T=20, =50/T, 0=0.1, 1=0.01  and 
2=0.01. We initialize the corpus by sampling each word from the 
general topics and run 1000 iterations to stabilize the distribution 
of z and u. 
3.  TERM EXTRACTION 
This  section  will  introduce  the  proposed  i-SWB  based  term 
extraction.  As  stated  in  Section  1,  the  ATE  process  is  usually 
guided by two measures: unithood for acquiring term candidates 
and  termhood  for  further  identifying  terms  from  the  candidates. 
Following the work of Frantzi [5], the unithood technique adopted 
in our work is mainly based on a linguistic filter as the following 
three steps: 
Step  1:  Part-of-speech  (POS)  tagging:  We  use  a  Maximum-
entropy  POS  tagger1 implemented  by  Standford  NLP  group  to 
assign a grammatical tag (e.g. noun, verb, adjective etc.) to each 
word in the corpus. 
                                                                 
1 http://www-nlp.stanford.edu/software/tagger.shtml 

Step  2:  Linguistic  filtering:  Since  most  terms  are  noun  phrases 
which consist of nouns, adjectives and some variants of verbs and 
end with a noun word, here we present our method with the filter: 
(FW | Verb | Adj | Noun)* Noun, where FW usually denotes the 
unknown words. 
Step 3: Frequency recording: for each term candidate, we record 
its  frequency  occurring  in  the  whole  corpus  and  exclude  those 
occurring only once from the candidate list. 
Now we get a list of term candidates with their frequency {ci, tfi}.  
w w w . To 
Suppose each candidate ci consists of Li words 
i
compute termhood, each candidate is scored according to tfi and 
B   
the  results  of  i-SWB  model.  According  to  the  values  of 
D  in  Eqs.  (9),  we  extract  the  top  H  (e.g.  200)  highest 
and 
distributed words for each topic, namely Vt, VB and VD, which can 
be  seen  as  the  typical  words  of  the  corresponding  topic.  An 
intuitive  idea  is  that,  a  good  candidate  should  be  composed  of 
typical  words  which  are  representative  of  a  certain  topic.  Thus, 
the termhood of ci is computed as:  

2...

,t

iL
i

1

i

Termhood c
(

)

i



log(

tf

)



i

1

 

j L w

,

i

j





V
{
t

}
t T
 

B D
{ , }

w j

mt

w

j

     (10) 

j

j

w

)



mt

t

w

jwmt

arg max(
t T
B D
{ , }
 
 denotes  the  topic  which  wj  is  most  likely  to  be 
where 
assigned.  To  compute  ci,  we  only  consider  those  constituent 
words that are typical of a certain topic. Then the candidates with 
the highest termhood values are taken as terms. 
4.  EXPERIMENTS 
4.1  Experiment Setup 
We  evaluate  the  i-SWB  based  term  extraction  method  on  four 
domain  specific  patent  corpora,  including  molecular  biology 
(C12N),  metallurgy(C22C),  electric  engineering(G01C)  and 
mechanical  engineering(H03M).  Statistics  of  the  documents  in 
each domain are summarized in Table 1. 

Table 1. Description of corpora 

No. of 

Domain 

metallurgy 

documents 

No. of words 

electric engine. 

11,496 
12,226 
9,462 
5,492 

1,880,739 
1,915,066 
1,741,820 
935,059 

Corpus 
CorpusC12N molecular biology 
CorpusC22C
CorpusG01C mechanical engine. 
CorpusH03M
It is difficult to collect a complete list of domain terms which is 
necessary for evaluation. Inspired by the pooling technique used 
in Information Retrieval (IR), we semi-automatically construct a 
lexicon for each domain. For each domain, every baseline system 
and our system submits one term list. The five baseline systems 
used will be introduced in the next subsections. We take the top 
500  terms  from  every  system  to  form  the  pool  for  that  domain. 
Then  from  the  pool,  four  graduate  students  majoring  in  the 
corresponding domain manually pick out the correct ones to form 
a  pseudo-lexicon  for  each  domain.  The  sizes  of  the  pseudo-
lexicons  are  1473,  1380,  1509  and  1370  for  molecular  biology, 
metallurgy,  mechanical  engineering  and  electric  engineering. 
Then,  we  compare  system  performances  with  the  popular  IR 
evaluation measures - precision at 6 different cut-off values P@n, 
where n=50, 100, 200, 300, 400, 500. 

8874.2  Comparison with Other Topic Models 
The i-SWB model is the key of our ATE system and we compare 
it with two commonly used topic models, i.e. SWB (Baseline 1) 
and  LDA  (Baseline  2).  Except  the  construction  of  topic  model, 
the whole process of term extraction is the same as introduced in 
Section 3. Fig. 4 below illustrates the P@n values of 3 different 
topic models on four domains. The blue bars represent the P@n 
values of our system, the red bars represent the SWB model, and 
the green bars represent the LDA model. From the figure, we can 
see that our model significantly outperforms the other two models. 
Taking the P@50 measure for example, the relative improvement 
of  i-SWB  over  SWB  in  the  domains  of  molecular  biology, 
metallurgy,  mechanical  engineering  and  electric  engineering 
reaches respectively 12.2%, 11.9%, 9.8% and 11.4% respectively.  

Domain of molecular biology

Domain of  metallurgy

Domain of  mechanical engineering

Domain of electric engineering

Figure 4. Comparison of different topic models. 

 

When further analyzing the terms that are wrongly identified by 
each  system,  we  find  that  if  SWB  is  applied,  the  word  “signal” 
reflecting  some  general  topic  is  assigned  to  some  document-
specific topics due to its high frequency in some documents and 
then the phrases such as “original signal” and “resulting  signal” 
are wrongly identified as terms. On the other hand, if LDA is used, 
some  general  words  such  as  “purpose”  and  “problem”  which 
occur frequently in the corpus are assigned to specific topics and 
the  phrases  of  “signal  purpose”  and  “problem  solving”  are 
wrongly  identified  as  terms.  These  kinds  of  problems  can  be 
overcome in i-SWB. However, the terms identified by i-SWB that 
are formed by sequences of several typical words are not always 
the real terms. For example, “signal” and “component” are both 
correctly  assigned  to  general  topics  with  higher  probability  but 
“signal  component”  is  not  a  real  term.  To  solve  this  problem, 
semantic representation of terms is worth exploring. 
4.3  Comparison with Online ATE Service 
We  also  compare  our  system  with  three  state-of-the-art  ATE 
systems.  We  use  two  online  free  systems  -  TerMine 2  and 
TermoStat3, as Baseline  3 and Baseline  4. TerMine uses the C-
value/ NC-value to compute termhood, while TermoStat is based 
on a statistical test and the target items are highly specific to the 
domain  corpus  being  analyzed.  In  addition,  we  implement  a 
baseline system (Baseline  5)  which  adopts  TF-IDF  in  termhood 
computation. Fig. 5 compares our system with the three baseline 
systems  over  the  P@n  values  and  shows  that  our  system 
obviously performs better than the other three. This verifies that 
the  semantic  analysis  of  words  are  helpful  to  the  ATE  task. 
TerMine performs slightly better than TermoStat. But the TF-IDF 
                                                                 
2 http://www.nactem.ac.uk/software/termine/ 
3 http://idefix.ling.umontreal.ca/~drouinp/termostat_web/ 

technique  performs  unstably:  better 
the 
metallurgy  domain,  worse  than  TerMine  and  TermoStat  in  the 
domain  of  mechanical  engineering.  This  may  suggest  that  the 
performance of TF-IDF heavily depends on the corpus quality.  

than  TerMine 

in 

Domain of molecular biology

Domain of  metallurgy

Domain of  mechanical engineering
Domain of electric engineering
Figure 5. Comparison with other ATE approaches. 

 

includes  general 

latent  semantic  space,  which 

5.  CONCLUSION 
In  this  paper,  we  argue  that  the  termhood  measure  should  take 
consideration  of  semantic  information.  To  cater  to  this  idea,  we 
design a novel topic model i-SWB to map the domain corpus into 
the 
topics, 
background topic and documents-specific topic. Based on i-SWB, 
we implement our ATE system and evaluate it on four domains 
(i.e. molecular biology, metallurgy, mechanical engineering, and 
electric  engineering).  The  experimental  results  show  that  our 
approach outperforms the state-of-the-art ATE approaches. 
6.  ACKNOWLEDGMENTS 
This research has been supported by NSFC grants (No. 61273278 
and  61272291),  National  Key  Technology  R&D  Program 
(No:2011BAH1B0403), 
(No. 
2012AA011101)  and  National  Social  Science  Foundation  (No: 
12&ZD227),.  We  also  thank  the  anonymous  reviewers  for  their 
helpful comments. Corresponding authors: Sujian Li and Baobao 
Chang. 
7.  REFERENCES 
[1]  Blei, D. M., Ng, A. Y., Jordan, M.I. 2003. Latent Dirichlet 
allocation, The Journal of Machine Learning Research, pp. 
993-1022. 

National 

863 

Program 

[2]  Chang J.-S. 2005. Domain specific word extraction from 
hierarchical web documents: a first step toward building 
lexicon trees from web corpora. In Proceedings of the 4th 
SIGHAN Workshop on Chinese Language Learning: 64-71. 

[3]  Chemudugunta, C., Smyth, P. and Steyvers, M. 2006. 

Modeling general and specific aspects of documents with a 
probabilistic topic model. In NIPS 19, pp. 241–248. 

[4]  Hisamitsu, T., Niwa, Y., and Tsujii, J. 2000. A method of 
measuring term representativeness - baseline method using 
co-occurrence distribution, COLING 2000, pp.320-326. 

[5]  Frantzi, K., Ananiadou, S. and Mima, H. 2000. Automatic 

recognition of multi-word terms: the C-value/NC-value 
method. International Journal of Digital Libraries, 3(2): 117-
132 

[6]  Kageura, K. and Umino, B. 1996. Methods of automatic term 

recognition. Terminology, 3(2).  

888