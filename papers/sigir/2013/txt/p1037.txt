A Study on the Accuracy of Flickr’s Geotag Data

Claudia Hauff∗

Delft University of Technology

Delft, The Netherlands
c.hauff@tudelft.nl

ABSTRACT
Obtaining geographically tagged multimedia items from so-
cial Web platforms such as Flickr is beneﬁcial for a variety of
applications including the automatic creation of travelogues
and personalized travel recommendations. In order to take
advantage of the large number of photos and videos that do
not contain (GPS-based) latitude/longitude coordinates, a
number of approaches have been proposed to estimate the
geographic location where they were taken. Such location
estimation methods rely on existing geotagged multimedia
items as training data. Across application and usage sce-
narios, it is commonly assumed that the available geotagged
items contain (reasonably) accurate latitude/longitude coor-
dinates. Here, we consider this assumption and investigate
how accurate the provided location data is. We conduct a
study of Flickr images and videos and ﬁnd that the accu-
racy of the geotag information is highly dependent on the
popularity of the location: images/videos taken at popular
(unpopular) locations, are likely to be geotagged with a high
(low) degree of accuracy with respect to the ground truth.

Categories and Subject Descriptors: H.3.3 Information
Storage and Retrieval: Information Search and Retrieval
Keywords: geotags, positional accuracy, social Web

1.

INTRODUCTION

Obtaining geographically tagged multimedia items (i.e.
items with latitude/longitude information) such as images
and videos from social Web platforms such as Flickr1 is ben-
eﬁcial for a variety of applications including the automatic
illustration of travelogues [6], personalized travel recommen-
dations [1, 2] and the organization of personal multimedia
archives.

In order to take advantage of the large number of multime-
∗This research has received funding from the European
Union Seventh Framework Programme (FP7/2007-2013),
grant agreement no ICT 257831 (ImREAL project).
1Flickr, http://www.flickr.com/

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for proﬁt or commercial advantage and that copies bear
this notice and the full citation on the ﬁrst page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior speciﬁc permission and/or a fee. Request
permissions from permissions@acm.org.
SIGIR’13, July 28–August 1, 2013, Dublin, Ireland.
Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

dia items that do not contain (GPS-based) latitude/longitude
coordinates, a number of approaches, e.g. [4, 3, 9, 11, 5] have
been proposed to estimate the geographic location where
the image or video was taken. Such location estimation
approaches rely on existing geotagged multimedia items as
training data. It is commonly assumed that the geotagged
multimedia items, as available from Flickr, contain reason-
ably accurate latitude/longitude coordinates, though it re-
mains largely unclear what “reasonably” in this context means
and to what extent the acceptable error varies between the
diﬀerent use cases.

Shaw et al. [10] recently reported that on Foursquare2
data, the median accuracy is 70 meters while the mean ac-
curacy is 551 meters, that is, the true location of a venue
and the location reported by a GPS-enabled mobile device,
diﬀers on average by more than 500 meters. In contrast, a
study under ideal conditions by Zandbergen & Barbeau [12]
has shown that GPS-enabled devices can report highly ac-
curate locations (with less than 10 meter deviation from the
true location), not just in outdoor but also indoor settings.
A confounding factor on Flickr is, that not only images and
videos from GPS-enabled devices contain latitude/longitude
information. Users can also manually indicate on a world
map, where an image or video was taken, a process which
also yields geotag information.

In this paper, we investigate the positional accuracy of the
geotag information of Flickr images and videos. Similarly
to the works just described, we aim to determine the diﬀer-
ence between the true location of a venue and the location
recorded in Flickr’s meta-data. To this end, we manually
annotate 2500 Flickr images and videos3.

Our two main ﬁndings can be summarized as follows:
• The positional accuracy is highly dependent on the
popularity of the venue: images taken at popular venues
contain highly accurate positional data with an aver-
age distance to the ground truth location of 11 − 13
meters. In contrast, images taken at unpopular venues
contain much larger positional inaccuracies, with an
average error between 47 − 167 meters.
• When comparing the Flickr-based positional data with
the manually corrected positional data on the location
estimation task, we ﬁnd considerable diﬀerences in the
algorithms’ performances, indicating that the varying

2Foursquare, https://foursquare.com/
3For brevity, in the rest of the paper we will use the term
image(s), though our data contains images as well as videos.
For the experiments reported here, we treat images and
videos in exactly the same manner.

1037quality of location data should be taken into account
when evaluating this task.

2. THE LOCATION ESTIMATION TASK

Approaches proposed to solve the task of placing images
on the world map by determining their latitude and longi-
tude, have been relying on a variety of sources that are based
on the image and its meta-data, the user uploading the im-
age or external knowledge bases. Textual features exploited
from the image are mostly the assigned tags and the title as
well as the description. Visual features derived from the im-
ages include a variety of types, such as color histograms or
edge histograms [7] (for videos, keyframes are ﬁrst extracted
and then treated as images).

Serdyukov et al. [9] phrased the problem as an information
retrieval task, where world regions are considered as docu-
ments and the textual meta-data of an image to be placed on
the world map is considered as query. Speciﬁcally, the tags
assigned to images on Flickr are exploited as query terms.
A grid is placed over the world map which results in equally
sized cells. Each training image (with known location) is
assigned to its correct grid cell. For each cell, a language
model [13] is created from the tags assigned by the user,
and a test image is assigned to the geographic cell that pro-
duces the highest probability for generating the image’s tag
set. To determine whether a tag is geographic in nature,
GeoNames4 is employed, a large gazetteer of geographic en-
tities.

Also based on tags is the approach proposed in [11]. In
contrast to [9], the location estimation is performed on diﬀer-
ent levels of granularity (city granularity, street level gran-
ularity, etc.) and the evidence obtained over the diﬀerent
granularities is combined in order to output the best match
granularity location estimate.

The text-based approach by Hauﬀ et al. [4] combines the
advantages of the previous two works by considering infor-
mation from the training data only (i.e. no external data
sources are used): dynamically shaped region sizes are uti-
lized and terms are ﬁltered based on their geographic scope
which is derived from the training data. It could be shown
that by employing such geo-ﬁltering, the placing accuracy
can be increased substantially.

Finally, an approach that not only exploits textual infor-
mation but also visual features was proposed in [5]. Here,
textual information (tags) is the primary source of infor-
mation, and visual features are used as fall-back option in
instances where tags do not provide meaningful information.
The accuracy of estimating the geographic location of im-
ages is commonly evaluated by reporting the percentage
of test images whose estimated location is within a dis-
tance of x from the ground truth latitude/longitude co-
ordinates.
In early works, e.g. [9], common ranges for x
were: {1, 10, 50, 100, 1000} kilometres. More recently, with
the improvement of the algorithms’ performances, ranges of
x = {10, 100, 500} meters have also been investigated [3].

3. ANNOTATION STUDY

In order to obtain insights into the positional accuracy of
Flickr’s geotagged images, we chose to manually annotate
images of ten venues. These venues were chosen with the
following criteria in mind:
4GeoNames, http://www.geonames.org/

the annotation process easy for the annotator.

about the venue (i.e. it is relatively well-known).

• A reasonable number of images should exist on Flickr
• The venue has a distinctive indoor component, to make
• The venue has a limited size, so that the ground truth
location (a single latitude/longitude coordinate pair)
is suﬃciently accurate. For this reason, a national
park, for instance, is unsuitable, whereas a church or
chapel is (relatively) small and pictures taken inside
such venue should only be meters away from the ground
truth location.

or tags of the image,

of all images available through Flickr’s search API that:

As ground truth location, we extract the latitude/longitude
coordinates as they appear on the venue’s Wikipedia5 page.
In the next step, for each venue, we collect the set (cid:61)query
• contain the query text in either the title, description
• were taken within a 1 kilometre radius of the true lo-
cation (and thus, we only consider geotagged images),
• and have Flickr’s highest accuracy level (16)6.
As query, we employ the commonly used English name of
a venue. Additionally, for each venue, we manually identify
three to ﬁve examples images that contain distinctive fea-
tures of the venue’s interior. Three such example images for
the Sistine Chapel are shown in the top row of Fig. 1. Based
on these “gold standard” images, the annotator is shown 250
randomly chosen images from (cid:61)query (but no more than one
image per uploader). For each image, the annotator de-
termines whether it was taken inside or outside the venue.
When no judgement can be made, unknown is assigned to
the image. Three examples of annotations are shown in the
bottom row of Fig. 1.

Figure 1: Top row:
annotator for the query sistine chapel.
tom row:
side/outside/unknown (in this order).

example images shown to
Bot-
images that were annotated with in-

4. RESULTS

Based on our research question, we are mostly interested
in the images that are annotated as having been taken in-
side a venue - if their Flickr-based geotags are correct, they

5Wikipedia, http://www.wikipedia.org/
6On Flickr, diﬀerent accuracy levels exist, the highest being
16 which means that the location is accurate at the street-
level. Note though, that 16 is also Flickr’s default accuracy
level when no accuracy information is provided. For this
reason, we repeated all experiments on level 15 as well - the
conclusions remain the same.

1038should only diﬀer by a few meters from the ground truth lo-
cation. Here, we report the results for all three annotation
types, though it should be emphasized that for images and
videos taken outside a venue, we cannot make claims about
the accuracy of their geotag information.

Tab. 1 provides a comprehensive overview of our annota-
tion data and the results. As an example, consider the venue
Sistine chapel, a small chapel in the Apostolic Palace in Vat-
ican City. For the query sistine chapel (without any geo-
graphic restrictions), Flickr returns nearly 30, 000 images.
When restricting the search geographically as described in
Sec. 3 though, the result set shrinks to 1, 377 images (4.8%
of the original result set). This is a common pattern; only a
small minority of images are geotagged with high accuracy.
Evident is also the range in popularity of the diﬀerent
venues - more than 350, 000 images are retrieved for the
query sagrada familia compared to approximately 4, 000 im-
ages for the query aachen cathedral.

When considering the annotation results of the 250 ran-
domly chosen images for each venue, we ﬁnd that in most
cases the annotator is able to make a decision whether or
not the image was indeed taken inside the venue. The re-
sults for unknown often stem from close-ups, where it is not
possible to decide where exactly the images was taken.

The most important information with respect to our re-
search question is shown in the last three columns of Tab. 1.
Here, the average (as well as minimum and maximum) dis-
tance of the annotated images to the ground truth location is
shown in meters. Again as an example, the images that were
found to have been taken inside the Sistine Chapel, have on
average a distance of 167 meters to the ground truth loca-
tion; the minimum being 5 meters and the maximum being
more than 450 meters. For the images that were taken out-
side the Sistine Chapel, the distances are greater, as one
would expect. However, when considering the venues with
more than 8, 000 geotagged images (hagia sophia, sagrada
familia, paris notre dame), a very diﬀerent picture emerges:
the average distance to the ground truth is less than 15 me-
ters, and the maximum distance is 27 meters. Thus, for very
popular destinations, the images are indeed closely aligned
with the ground truth location.

Fig. 2 presents a diﬀerent view of the data: here, the num-
ber of geotagged images in the spatial neighbourhood are
plotted against the average and maximum distances of the
annotated images to their ground truth location. A trend is
clearly visible, though more venues need to be investigated
for a more precise analysis.

Figure 2: Scatter plot of the total number of geo-
tagged images vs. the distance (average, maximum)
to the ground truth for the inside images. Each
point represents one venue.

Location Estimation Task.

We also consider the implications these ﬁndings have on
established data sets for the image placing task. Here, we
utilize a standard benchmark for this task, namely the Me-
diaEval 2011 [8] data set. It consists of 3.2 million training
images drawn from Flickr and 5345 test items that need to
be placed on the world map. We ﬁrst analyse the Flickr im-
age density in the spatial neighbourhood of each test item
by determining the number of Flickr images that appear
within a 1 kilometre radius of the test item (at accuracy 16
but without the restriction of particular query terms). The
plot in Fig. 3 shows the result: nearly half of the test items
(2372) have a neighbourhood of 1000 images or less, while
63% of test items (3387) have a neighbourhood of 5000 im-
ages or less. Since we ﬁnd in our annotation study that im-
ages with such sparsely populated neighbourhoods are prone
to be hundred(s) of meters oﬀ the true location, we have to
conclude that for these test items the evaluation measures
should be limited to at most the 1km range.

Figure 3: Plot of the number of test items in the
MediaEval 2011 test set with less than X images in
the neighbourhood of 1km.

Lastly, we also conduct a location estimation experiment
with our 793 images that were annotated as having been
taken inside our ten venues and we create two types of
ground truth locations for them: (i) the Flickr-based ground
truth is the location information of each image as provided
by the Flickr meta-data, and (ii) the corrected ground truth,
i.e. the location information as we ﬁnd it for each venue on
Wikipedia. We implemented the image placing approach
for Flickr data as presented in [4], with and without geo-
ﬁltering.

The results are shown in Tab. 2. We report the per-
centage of the 793 images that have been placed within
{10, 50, 100, 1000, 10000} meters of the ground truth loca-
tion. As in previous work, we ﬁnd that geo-ﬁltering im-
proves the accuracy considerably. More importantly, when
comparing the results of the two ground truth versions, we
ﬁnd that the Flickr-based ground truth evaluation underes-
timates the accuracy of the evaluation in the 10m range by
a large degree: while 5.7% of test items were placed within
10m of the Flickr-based ground truth, 12.2% of images were
placed within the 10m range when considering the highly
accurate corrected ground truth.

5. CONCLUSIONS

In this work we have investigated the accuracy of geo-
tagged images and videos as they are found “in the wild”,
i.e. on social Web portals. We chose on Flickr, as one of the
most widely used data sources in research and conducted
an annotation study, in which we investigated the positional

025005,00010,00015,00020,00025,00030,0000100200300400500600700800#GeotaggedimagesDistancetothegroundtruth(inmeters)  averagemaximum11010010005,00010,000100,000300,000050010001500200025003000350040004500500055006000#Imageswithina1kmradius#Testitems1039Query
explanation

sistine chapel
chapel; Vatican City
sagrada familia
church;Barcelona, Spain
duomo di milano
cathedral; Milan, Italy
hallgrimskirkja
church; Reykjavik, Iceland
king’s college chapel
chapel; Cambridge, UK
aachen cathedral
cathedral; Aachen, Germany
hagia sophia
museum; Istanbul, Turkey
vienna stephen cathedral
cathedral; Vienna, Austria
prague vitus cathedral
cathedral; Prague, Czech Republic
paris notre dame
church; Paris, France

Manual annotations of 250

Distance to ground truth (in m)

geotagged

randomly selected
geotagged images

mean

min. max.

#photos

#photos #inside #unknown #outside

inside

unknown

outside

28,820

354,017

24,393

20,768

8,478

4,291

78,155

10,824

33,625

337,469

1,377
4.8%
13,801
3.9%
3,389
13.9%
1,064
5.1%
1,123
13.2%
608
14.2%
8,018
10.3%
1,560
14.4%
4,453
13.2%
29,614
8.8%

106

94

28

35

47

37

176

56

89

125

32

49

21

8

17

2

31

30

34

47

112

107

201

207

186

71

46

164

127

78

166.8
5.1 454.1
11.1
0.7 18.4
47.7
1.6 143.9
78.7
0.0 344.0
99.6
36.9 723.1
65.1
13.5 175.4
13.7
0.0 26.8
47.9
0.0 722.6
50.1
7.5 308.6
11.6
0.7 21.9

245.2
−
10.3
−
79.4
−
97.9
−
130.2
−
53.8
−
16.3
−
55.0
−
84.4
−
11.1
−

0.0

313.6
32.1 508.9
10.4
18.3
125.5
4.8 1022.5
129.5
0.0 766.5
158.7
4.6 722.9
81.7
12.3 473.7
13.0
26.7
74.0
2.7 761.7
94.1
0.0 503.6
11.2
21.6

1.8

2.1

Table 1: Annotation overview. The total number of Flickr images retrieved for a query (#photos) is compared
with the number of geotagged images retrieved when reducing the search to a 1km radius of the true location.
250 images are randomly drawn from the geotagged images and manually annotated with respect to being
taken inside/outside the venue (or unknown). The ﬁnal three columns show the mean, min. and max. distance
in meters of the annotated images to the true location (min./max. for unknown removed for brevity).

Flickr-based
ground truth

Corrected
ground truth

Geo-
Filter

yes
no

yes
no

10m

50m

100m

1km

10km

Accuracy

5.67% 26.48% 33.92% 58.76% 83.10%
2.40% 12.48% 21.56% 49.81% 76.04%

12.23% 24.71% 30.26% 58.76% 83.10%
4.41% 10.47% 17.65% 49.94% 76.04%

Table 2: Location estimation accuracy for a number
of distance cutoﬀs. Test items are the 793 items that
were taken inside one of our ten venues.

accuracy of Flickr images and videos. To this end, we se-
lected ten venues and manually annotated 2500 items with
respect to being taken inside or outside the venue. By fo-
cusing on the images that were taken inside the venue, we
were able to compare their Flickr-based latitude/longitude
coordinates with ground truth coordinates derived for each
venue from Wikipedia.

We found that the accuracy of the geotag information
strongly depends on the number of items available on Flickr
in the neighbourhood of the venue - images taken at highly
popular venues have a high degree of accuracy, while im-
ages taken at less popular venues exhibit a lower degree of
accuracy. In particular, we found an average diﬀerence be-
tween the gold standard location and the provided location
of 11 − 13 meters for the popular venues and diﬀerences of
approximately 47 − 167 meters for the less popular venues.
This ﬁnding has implications for several applications that
rely on such data sources, as they often assume highly pre-
cise location information.

In future work, we plan to address a number of limitations
our current study has. It is known that GPS-enabled devices

are somewhat less accurate indoors than outdoors. However,
since on Flickr images can also be placed on the world map
manually by the image owners, future work should focus
on distinguishing these two types of geotagged images. Do
diﬀerent patterns emerge when separating these two types
of geotagged data? Furthermore, we will investigate more
application scenarios that exploit geotagged information in
order to determine to what extent their results are inﬂuenced
by the spatial inaccuracies of the data.

6. REFERENCES

[1] M. Clements, P. Serdyukov, A. P. de Vries, and M. J. T. Reinders. Using

flickr geotags to predict user travel behaviour. In SIGIR ’10, pages
851–852, 2010.

[2] M. De Choudhury, M. Feldman, S. Amer-Yahia, N. Golbandi, R. Lempel,

and C. Yu. Automatic construction of travel itineraries using social
breadcrumbs. In HT ’10, pages 35–44, 2010.

[3] G. Friedland, J. Choi, H. Lei, and A. Janin. Multimodal location

estimation on flickr videos. In WSM ’11, pages 23–28, 2011.

[4] C. Hauff and G.-J. Houben. Placing images on the world map: a

microblog-based enrichment approach. In SIGIR ’12, pages 691–700, 2012.

[5] P. Kelm, S. Schmiedeke, and T. Sikora. Multi-modal, multi-resource

methods for placing flickr videos on the map. In ICMR ’11, pages
52:1–52:8, 2011.

[6] X. Lu, Y. Pang, Q. Hao, and L. Zhang. Visualizing textual travelogue

with location-relevant images. In LBSN ’09, pages 65–68, 2009.

[7] M. Lux and S. A. Chatzichristofis. Lire: lucene image retrieval: an

extensible java cbir library. In MM ’08, pages 1085–1088, 2008.

[8] A. Rae, V. Murdock, P. Serdyukov, and P. Kelm. Working Notes for the

Placing Task at MediaEval 2011. In MediaEval 2011 Workshop, 2011.

[9] P. Serdyukov, V. Murdock, and R. van Zwol. Placing flickr photos on a

map. In SIGIR ’09, pages 484–491, 2009.

[10] B. Shaw, J. Shea, S. Sinha, and A. Hogue. Learning to rank for

spatiotemporal search. In WSDM ’13, pages 717–726, 2013.

[11] O. Van Laere, S. Schockaert, and B. Dhoedt. Combining multi-resolution

evidence for georeferencing Flickr images. In SUM ’10, pages 347–360,
2010.

[12] P. A. Zandbergen and S. J. Barbeau. Positional accuracy of assisted gps

data from high-sensitivity gps-enabled mobile phones. The Journal of
Navigation, 64:381–399, 2011.

[13] C. Zhai and J. Lafferty. A study of smoothing methods for language

models applied to ad hoc information retrieval. In SIGIR ’01, pages
334–342, 2001.

1040