SoPRa: A New Social Personalized Ranking

Function for Improving Web Search

Mohamed Reda

Bouadjenek
PRiSM Laboratory
Versailles University

∗

mrb@prism.uvsq.fr

∗

Hakim Hacid

Sidetrade

114 Rue Gallieni, 92100

Boulogne-Billancourt, France
hhacid@sidetrade.com

Mokrane Bouzeghoub

PRiSM Laboratory
Versailles University

mokrane.bouzeghoub@

prism.uvsq.fr

ABSTRACT
We present in this paper a contribution to IR modeling by
proposing a new ranking function called SoPRa that consid-
ers the social dimension of the Web. This social dimension
is any social information that surrounds documents along
with the social context of users. Currently, our approach re-
lies on folksonomies for extracting these social contexts, but
it can be extended to use any social meta-data, e.g. com-
ments, ratings, tweets, etc. The evaluation performed on
our approach shows its beneﬁts for personalized search.
Categories and Subject Descriptors: H.3.3 [Informa-
tion Systems]: Information Search and Retrieval
General Terms: Algorithms, Experimentation.
Keywords: Information Retrieval, Social networks.

INTRODUCTION

1.
Nowadays, the Web is becoming more and more complex
with the socialization and interaction between individuals
and objects. This evolution is known as social Web, which
includes linking people through the World Wide Web. This
is mainly done through platforms such as Facebook, Twitter,
or YouTube, where users can comment, spread, share and
tag information and resources. The social Web leaded to
facilitate the implication of users in the enrichment of the
social context of web pages1. Especially, it allows users to
freely tag web pages with annotations. These annotations
can be easily used to get an intuition about the content of
web pages to which they are related. Hence, several research
works ([4, 7, 9, 19]) reported that adding tags to the content
of a document enhances the search quality, as they are good
summaries for documents. In particular, tags are useful for
documents that contain few terms.
∗This work has been mainly done when the authors was at
Bell Labs France, Centre de Villarceaux.
1In this paper, we also refer to web pages as documents or
resources.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
SIGIR’13, July 28–August 1, 2013, Dublin, Ireland.
Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

In such a context, classic models of Information Retrieval
(IR) should be adapted by considering (i) the social context
that surrounds web pages and resources, e.g.
their anno-
tations, their associated comments, their ratings, etc. and
(ii) the social context of users, e.g. their used tags, their
comments, their trustworthiness, etc. Exploiting social in-
formation has a number of advantages (for IR in particular).
First, feedback information in social networks is provided
directly by the user, so user interests accurate information
can be harvested as people actively express their opinions
on social platforms. Second, a huge amount of social infor-
mation is published and available with the agreement of the
publishers. Exploiting this information should not violate
user privacy, in particular social tagging information, which
doesn’t contain sensitive information about users. Finally,
social resources are often publicly accessible, as most of so-
cial networks provide APIs to access their data.

In this paper, we are interested in improving the IR model
by proposing a new ranking function for documents, while
considering the social context of the Web. The approach we
are proposing relies on social annotations, which are associ-
ated to documents in bookmarking systems but can consider
other social metadata, e.g. comments, tweets, etc.

In this context, we propose the following contributions:
(1) A Social Personalized Ranking function called SoPRa.
(2) A method for weighing user proﬁles and social docu-
ments. (3) An extension of SoPRa by considering tagging
users individually. (4) An intensive evaluation of SoPRa.

The rest of this paper is organized as follows:

in Sec-
tion 2.1, we present the fundamental concepts, and we for-
mally deﬁne the problem we tackle. Section 3 presents the
related work. Section 4 introduces our approach for rank-
ing documents. Experiments are discussed in Section 5. We
conclude and provide some future directions in Section 6.

2. BACKGROUND

2.1 Background and notation

Social bookmarking systems are based on the techniques
of social tagging. The principle is to provide the user with a
mean to freely annotate resources on the Web with tags, e.g.
URIs in delicious, or images in Flickr. These annotations
can be shared with others. This unstructured approach to
classiﬁcation is often referred to as a folksonomy. A folkson-
omy is based on the notion of bookmark, which is formally
deﬁned as follows:

861Deﬁnition 1. Let U, T, R be respectively the set of Users,
Tags and Resources. A bookmark is a triplet (u,t,r) such as
u ∈ U, t ∈ T, r ∈ R, which represents the fact that the user
u has annotated the resource r with the tag t.

Then, a folksonomy is formally deﬁned as follows:

Deﬁnition 2. Let U, T, R be respectively the set of Users,
Tags and Resources. A folksonomy F(U, T, R) is a subset
of the Cartesian product U × T × R such that each triple
(u, t, r) ∈ F is a bookmark.

In this paper we use the notation summarized in Table 1.

ever, we consider a new aspect, which is a social matching
score between a query and the annotations of documents.

Table 1: Paper’s Notation Overview

Variable

Description

Figure 1:
tween the diﬀerent approaches.

Illustration of the basic diﬀerences be-

u, d, t

Respectively a user u, a document d and a tag t.

U, D, T

Respectively a set of users, documents and tags.

| A |

The number of element in the set A.

4. SoPRa FUNCTION

Respectively the set of tags used by u, tags used to

annotate d, and tags used by u to annotate d.

Respectively the set of documents tagged by u, documents

In this Section, we ﬁrst deﬁne the SoPRa function, and
then we present the methods for modeling social documents
and users. Finally, we present an extended version of SoPRa.

4.1 Basic SoPRa

We follow the widely used Vector Space Model (VSM),
where all the queries and the documents are mapped to be
vectors in a universal term space.

On the one hand, we believe that a matching score be-
tween a document d and a query q should be based on (i)
a textual matching score, and (ii) a social matching score.
The textual matching score expresses the similarity between
the textual content of d and q. The social matching score
expresses how similar the social representation of d is, for q.
This social representation is based on the annotations asso-
ciated to d. More formally, in this work, we consider these
two ranking scores as independent evidence, and we propose
to merge them using a linear function as follows:

Score(q, d) = β × Cos(−→q ,

−→
−→
Td) + (1 − β) × Sim(−→q ,
d ) (1)
−→
where β is a weight that is equal to 0.5, Sim(−→q ,
d ) de-
notes the textual matching score between d and q (currently
computed using the Apache Lucene search engine in our im-
−→
plementation), and
Td is the vector that models the social
representation of the document d.

On the other hand, in the non-personalized search engines
(classic IR models), the relevance between a query and a
document is assumed to be only based on the textual content
of the document. However, as relevance is actually relative
for each user, considering only a matching between a query
and documents is not enough to generate satisfactory search
results. Thus, we propose to estimate the interest of a user
u to a document d by computing a similarity between the
proﬁle of u and the social representation of d. Then, we
propose to merge this interest value to the previous ranking
score computed in Equation 1 for computing an overall score
to a document. Formally, the ranking score of a document
d that potentially match the query q issued by a user u is
computed as follows:

Rank(d, q, u) = γ × Cos(−→pu,

−→
Td) + (1 − γ) × Score(q, d) (2)

where, γ is the weight that satisﬁes 0 ≤ γ ≤ 1. The ranking
model of the basic SoPRa function is illustrated in Figure 1

Tu , Td ,

Tu,d

Du , Dt,

Du,t

Ut , Ud ,

Ut,d

Cos( ~A, ~B)
−→pu

tagged with t, and documents tagged by u with t.

Respectively the set of users that use t, users that

annotate d, and users that used t to annotate d.

The cosine similarity measure between two vectors.

The weighted vector of the profile of the user u.

2.2 Problem deﬁnition

We can formalize the ranking problem as follows: Let con-
sider a folksonomy F(U, T, R) whose a user u ∈ U submits
a query q to a search engine. We would like to re-rank the
set of resources Rq ⊆ R (or documents) that match q, such
that relevant resources for u are highlighted and pushed to
the top for maximizing his satisfaction and personalizing the
search results. The ranking follows an ordering τ = [r1 ≥
r2 ≥ · · · ≥ rk] in which rk ∈ R and the ordering relation is
deﬁned by ri ≥ rj ⇔ Rank(ri, q, u) ≥ Rank(rj, q, u), where
Rank(r, q, u) is a ranking function that quantify similarity
between the query and the resource w.r.t the user [14].

3. RELATED WORK

We distinguished two categories for social results re-ranking
that diﬀer in the way social information is used. The ﬁrst
category uses social information by adding a social relevance
to documents while the second use it for personalization.
Re-ranking using social relevance: Several approaches
have been proposed to improve document re-ranking using
social relevance. Social relevance refers to information so-
cially created that characterizes a document from a point of
view of its interest, i.e.
its general interest, its popularity,
etc. Many approaches [1, 10, 13, 18] have been proposed to
adapt popular algorithms such as PageRank and HITS.
In general, users have diﬀer-
Personalized re-ranking:
ent interests. Hence, in an IR system, providing the same
sorted documents is not really suitable. Thus, a personal-
ized function to sort documents w.r.t each user is expected
to improve results. Many approaches have been proposed
to personalize the ranking using social information [8, 14,
15, 17]. These approaches consider a matching between the
user proﬁle and a document, and a matching between the
query and the document annotations as in Figure 1. The
approach we are proposing is part of this initiative. How-

862for more clarity. In summary, SoPRa ranks documents ac-
cording to: (i) a textual content matching score of docu-
ments and the query, (ii) a social matching score of docu-
ments and the query, and (iii) the social interest score of the
user to documents.

4.2 Weighting scheme

In this paper, the social representations of documents and
the user proﬁles are estimated by their social annotations
and modeled as in the VSM. Hence, if we consider web pages
or users as documents and annotations as terms, the above
setting is right for the VSM. Even if the VSM has been
developed a long time ago, it has shown its eﬀectiveness
for IR and remains very competitive and challenging. One
of the key points in the VSM is the weighting of terms.
We propose to simply weight annotations using the tf-idf
measure as follows:

wd

t = tft×log(

| R |
| Rt |

), wu

t = utft × log(cid:18) | U |
| Ut |(cid:19)

(3)

where wd
t is the weight of the term t in the social represen-
tation of d, tft denotes the tag frequency, wu
t is the weight
of the term t in the proﬁle of u, and utfu is the user term
frequency, i.e. the number of time the user u used the tag t.

4.3 Extended SoPRa

In classic models of IR, the content of a web page is con-
sidered as a mixture of homogeneous terms generated by
the same creator, i.e. the author of the web page. However,
social bookmarking systems allow users to freely assign an-
notations to documents following their own vocabulary to
describe these documents. Hence, unlike the textual con-
tent of a web page, annotations can be seen as a mixture
of heterogeneous fragments, where each fragment describes
the content of the web page with annotations of a particular
user. This notion of fragments is illustrated in Figure 1 as
clusters of annotations. Consequently, we believe that IR
ranking functions may be improved by considering indepen-
dently each user that annotates a web page. Strengthening
annotations provided by similar users to the query issuer
can enhance the score of a document. To address this prob-
lem, we propose an extension of SoPRa by discriminating
between users who annotate web pages and by considering
their similarities with the query issuer. Hence, we extend
the basic SoPRa as follows:

−−−→

−−−→

uk ∈Ud

Cos(−−→puk , −→pu) × Cos(−→pu,

Tuk ,d) + (1 − γ)×

Cos(−−→puk , −→pu) × Cos(−→q ,

Rank(d, q, u) = γ × X
uk ∈Ud

β × X
(4)
−−−→
where
Tuk ,d is the vector that models the social representa-
tion of the document d based only on the annotations pro-
vided by uk to d. The ranking model of the extended SoPRa
is illustrated in Figure 1 for more clarity.

Tuk ,d) + (1 − β) × Sim(−→q ,

−→
d )




In summary, in this section, we presented SoPRa in its ba-
sic form as well as an extension of SoPRa, which individually
consider users and their similarities to the query issuer. In
the next Section, we present the evaluation we performed.

5. EVALUATION

To evaluate our approach, we have selected a delicious
dataset, which is public, described and analyzed in [16]. Be-

fore the experiments, we performed four data preprocessing
tasks: (1) We remove annotations that are too personal or
meaningless, e.g. “toread”, “Imported IE Fa-vorites”, etc.
(2) The list of terms undergoes a stemming by means of the
Porter’s algorithm in such a way to eliminate the diﬀerences
between terms having the same root. (3) We downloaded
all the available web pages while removing those which are
no longer available using the cURL command line tool. (4)
Finally, we removed all the non-english web pages. Table 2
gives a description of the resulted dataset.

Table 2: Details of the delicious dataset

Bookmarks

Users

Tags Web pages

Unique terms

9 675 294

318 769

425 183

1 321 039

12 015 123

5.1 Evaluation methodology

Making evaluations for personalized search is a challenge

since relevance judgments can only be assessed by end-users [8].
This is diﬃcult to achieve at a large scale. However, diﬀer-
ent eﬀorts [3, 4, 11] state that the tagging behavior of a user
of a folksonomy closely reﬂects his behavior of search on the
Web. In other words, if a user tags a document d with a tag
t, he will choose to access the document d if it appears in
the result obtained by submitting t as query to the search
engine. Thus, we can easily state that any bookmark (u, t, r)
that represents a user u who tagged a document d with tag
t, can be used as a test query for evaluations. The main idea
of these experiments is based on the following assumption:
For a query q = {t} issued by u with query term t, relevant

documents are those tagged by u with t.

Hence, for each evaluation, we randomly select 2000 pairs
(u, t), which are considered to form a personalized query set.
For each corresponding pair (u, t), we remove all the book-
marks (u, t, r) ∈ F, ∀r ∈ R in order to not promote the re-
source r (or document) in the results obtained by submitting
t as a query in our algorithm and the considered baselines.
By removing these bookmarks, the results should not be bi-
ased in favor of documents that simply are tagged with query
terms and making comparisons to the baseline uniformly.
Hence, for each pair, the user u sends the query q = {t} to
the system. Then, we retrieve and rank all the documents
that match this query using our approach or a speciﬁc base-
line, where documents are indexed based on their textual
content using the Apache Lucene. Finally, according to the
previous assumption, we compute the Mean Average Pre-
cision (MAP) and the Mean Reciprocal Rank (MRR) over
the 2000 queries. The random selection was carried out 10
times independently, and we report the average results.

5.2 Comparison with baselines

We compare our approach to several personalized and
non-personalized baselines, in which the social based score is
merged with the textual based matching score using a linear
function with a γ parameter. The results are illustrated in
Figure 2, while varying γ.

5.2.1 SoPRa VS non-personalized ranking approaches

We compare our approach to: SocialPageRank (SPR) [1],
Dmitriev06 [9], and the Lucene naive score. We also com-
pare our approach to an approach where the matching score
is computed as in Equation 1, and we refer to this approach

863 0.06
 0.055
 0.05
 0.045
 0.04
 0.035
 0.03
 0.025
 0.02
 0.015
 0.01
 0.005

 0.07

 0.06

 0.05

 0.04

 0.03

 0.02

 0.01

 0

 0

 0.2

 0.4

 0.6

 0.8

 1

 0

 0.2

 0.4

 0.6

 0.8

 1

Values of(cid:9)(cid:9) γ

Values of(cid:9)(cid:9) γ

(a) Mean Average Precision

(b) Mean Reciprocal Rank

SoPRa Basic

SoPRa Ext

BL-Q

Lucene

Xu08

Noll07

SPR

LDA-Q

tf-if

Dmitriev06

LDA-P

Sem-Search

Figure 2: Comparison with the baselines.

as BL-Q. The last approach use LDA [5], where we construct
a model using documents. Then, for each document that
match a query, we compute a similarity between its topic
and the topic of the query (inferred by considering queries
as documents) using the cosine measure. The obtained value
is merged with the textual ranking score and we refer to this
approach as LDA-Q.

The results show that SoPRa and its extension is much
more eﬃcient than all the non-personalized approaches for
all values of γ. Hence, we conclude that the personalization
eﬀorts introduced by SoPRa improve the search quality. We
also notice that most of the non-personalized approaches de-
cease their performance for high values of γ. This is certainly
due to the fact that they are not designed for personalized
search, since these approaches fail in discriminating between
users in spite of their preferences.

5.2.2 SoPRa VS personalized ranking approaches

Here we compare our approach to: Xu08 [17], Noll07 [12],
tf-if [14], and Semantic Search [2]. We also use an approach
based on LDA, where we construct a model using docu-
ments. Then, for each document that match a query, we
compute a similarity between its topic and the topic of the
user proﬁle (inferred by considering users as documents) us-
ing the cosine measure. The obtained value is merged with
the textual ranking score and we refer to this approach as
LDA-P. Here, the obtained results also show that our ap-
proach is much more eﬃcient than all the baselines for all
values of γ. Especially, our approach outperform the LDA-
P approach and the Xu08 approach, which we consider as
the closest works to our. We also notice that the Noll07
and the tf-if approaches give poor results. This is certainly
due to the fact that they fail in ranking documents that
doesn’t share tags with users, since in our experiment we
remove the triplets that associate the user, the query terms
and documents.

Finally, we note that the better performance are obtained
for γ ∈ [0.6, 0.8] for the basic SoPRa, a compromise be-
tween the user interest matching score and the query aﬃnity
matching score. As for the extended SoPRa, it seems that γ
has no impact on the results. This show that the extension
proposed takes full advantage of the user interest matching
score and the query aﬃnity matching score. We also note
that the extension of SoPRa provides better performance
than the basic one. This shows that considering users indi-

vidually and their similarities to the query issuer provide a
better estimation of the relevance of documents.

6. CONCLUSION AND FUTURE WORK

This paper discusses a contribution to the area of IR mod-
eling while leveraging the social dimension of the web. We
proposed a new documents ranking function called SoPRa,
which uses social information to enhance and improve web
search. The experiments performed show the beneﬁt of So-
PRa while comparing it to the closest works. SoPRa can
be improved in diﬀerent way. First, the temporal dimension
of social users’ behavior has not been deeply investigated
yet in the literature, e.g. considering the evolution of the
taste of users in the ranking function. Second, considering a
social relevance score factor, which characterizes documents
from a point of view of interest, is a possible improvement
of SoPRa, e.g.
their popularities. Finally, performing an
online user evaluation in order to validate our results is an
ongoing task. SoPRa has been developed and integrated to
the LAICOS [6] platform.

7. REFERENCES
[1] S. Bao, G. Xue, X. Wu, Y. Yu, B. Fei, and Z. Su. Optimizing

web search using social annotations. In WWW, 2007.

[2] M. Bender, T. Crecelius, M. Kacimi, S. Michel, T. Neumann,
J. X. Parreira, R. Schenkel, and G. Weikum. Exploiting social
relations for query expansion and result ranking. In ICDE
Workshops, 2008.

[3] D. Benz, A. Hotho, R. J¨aschke, B. Krause, and G. Stumme.
Query logs as folksonomies. Datenbank-Spektrum, 10:15–24,
2010.

[4] K. Bischoﬀ, C. S. Firan, W. Nejdl, and R. Paiu. Can all tags be

used for search? In CIKM, 2008.

[5] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet

allocation. J. Mach. Learn. Res., 3:993–1022, March 2003.

[6] M. R. Bouadjenek, H. Hacid, and M. Bouzeghoub. LAICOS:

An Open Source Platform for Personalized Social Web Search.
In KDD, 2013.

[7] M. R. Bouadjenek, H. Hacid, M. Bouzeghoub, and A. Vakali.

Using Social Annotations to Enhance Document Representation
for Personalized Search. In SIGIR, 2013.

[8] D. Carmel, N. Zwerdling, I. Guy, S. Ofek-Koifman, N. Har’el,

I. Ronen, E. Uziel, S. Yogev, and S. Chernov. Personalized
social search based on the user’s social network. In CIKM,
2009.

[9] P. A. Dmitriev, N. Eiron, M. Fontoura, and E. Shekita. Using

annotations in enterprise search. In WWW, 2006.

[10] A. Hotho, R. J¨aschke, C. Schmitz, and G. Stumme. Information

retrieval in folksonomies: Search and ranking. In Y. Sure and
J. Domingue, editors, The Semantic Web: Research and
Applications, 2006.

[11] B. Krause, A. Hotho, and G. Stumme. A comparison of social

bookmarking with traditional search. In ECIR, 2008.

[12] M. G. Noll and C. Meinel. Web search personalization via

social bookmarking and tagging. In ISWC’07/ASWC’07, 2007.

[13] T. Takahashi and H. Kitagawa. A ranking method for web

search using social bookmarks. In DASFAA, 2009.

[14] D. Vallet, I. Cantador, and J. M. Jose. Personalizing web

search with folksonomy-based user and document proﬁles. In
ECIR, 2010.

[15] Q. Wang and H. Jin. Exploring online social activities for

adaptive search personalization. In CIKM, 2010.

[16] R. Wetzker, C. Zimmermann, and C. Bauckhage. Analyzing

social bookmarking systems: A del.icio.us cookbook. In ECAI,
2008.

[17] S. Xu, S. Bao, B. Fei, Z. Su, and Y. Yu. Exploring folksonomy

for personalized search. In SIGIR, 2008.

[18] Y. Yanbe, A. Jatowt, S. Nakamura, and K. Tanaka. Towards

improving web search by utilizing social bookmarks. In ICWE,
2007.

[19] X. Zhang, L. Yang, X. Wu, H. Guo, Z. Guo, S. Bao, Y. Yu, and

Z. Su. sdoc: exploring social wisdom for document
enhancement in web mining. In CIKM, 2009.

864