Sumblr: Continuous Summarization of Evolving

Tweet Streams

Lidan Shou 1;2

Zhenhua Wang 1 Ke Chen1 Gang Chen1

1College of Computer Science and Technology

2State Key Lab of CAD&CG

Zhejiang University
Hangzhou, China

{should, wzh-cs, chenk, cg}@zju.edu.cn

ABSTRACT
With the explosive growth of microblogging services, short-
text messages (also known as tweets) are being created and
shared at an unprecedented rate. Tweets in its raw form
can be incredibly informative, but also overwhelming. For
both end-users and data analysts it is a nightmare to plow
through millions of tweets which contain enormous noises
and redundancies. In this paper, we study continuous tweet
summarization as a solution to address this problem. While
traditional document summarization methods focus on static
and small-scale data, we aim to deal with dynamic, quickly
arriving, and large-scale tweet streams. We propose a novel
prototype called Sumblr (SUMmarization By stream cLus-
teRing) for tweet streams. We ﬁrst propose an online tweet
stream clustering algorithm to cluster tweets and maintain
distilled statistics called Tweet Cluster Vectors. Then we de-
velop a TCV-Rank summarization technique for generating
online summaries and historical summaries of arbitrary time
durations. Finally, we describe a topic evolvement detection
method, which consumes online and historical summaries to
produce timelines automatically from tweet streams. Our
experiments on large-scale real tweets demonstrate the eﬃ-
ciency and eﬀectiveness of our approach.

Categories and Subject Descriptors
H.3.1 [Content Analysis and Indexing]: Abstracting
methods; H.3.4 [Systems and Software]: Performance
evaluation (eﬃciency and eﬀectiveness)

Keywords
Tweet stream; continuous summarization; timeline

1.

INTRODUCTION

With the explosive growth of microblogging services, such
as Twitter, Weibo and Tumblr, short-text messages known
as tweets are being created and shared at an unprecedented

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for proﬁt or commercial advantage and that copies bear
this notice and the full citation on the ﬁrst page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior speciﬁc permission and/or a fee. Request
permissions from permissions@acm.org.
SIGIR’13, July 28–August 1, 2013, Dublin, Ireland.
Copyright 2013 ACM 978-1-4503-2034-4/13/07 ...$15.00.

Figure 1: A timeline example for topic “Apple”

rate. Take Twitter for instance, receiving over 400 million
tweets per day1, it has become an invaluable source of news,
blogs, opinions, and more. Tweets in its raw form can be
incredibly informative, but also overwhelming. For exam-
ple, searching for a hot topic in Twitter can yield millions of
tweets, which span for weeks. Even if ﬁltering is allowed,
plowing through so many tweets for interesting contents
would be a nightmare, not to mention the enormous noises
and redundancies that one could encounter. To make things
worse, new tweets satisfying the ﬁltering criteria may arrive
continuously, at an unpredictable rate.

A possible solution to the above problem is continuous
tweet summarization, which represents the massive tweets
in a set of short text pieces covering the main topics (or
sub-topics of course). Speciﬁcally, let us look at an example,
which presumes availability of a topic-related tweet stream,
for example tweets about “Apple”. With a tweet summariza-
tion system, we can (i) continuously monitor “Apple”-related
tweets arriving from the stream and produce a continuous
timeline which grows by time. (ii) Suppose a user wants to
learn the main happenings about “Apple” from the tweets
between 22 Oct 2012 and 11 Nov 2012. The range timeline
during that period can be provided to her, so that she un-
derstands the big picture of topic evolution in those weeks
(as shown in Figure 1). (iii) After that, she may need more
detailed reports for a much smaller duration (e.g. from 8 am
to 11 pm on 5 Nov), which is like a drill-down summary on
the duration. (iv) Alternatively, she may ask for a more con-
cise report during 21 Oct to 30 Oct, in a roll-up summary.

1https://blog.twitter.com/2013/celebrating-twitter7

533the current clusters maintained in memory. This algorithm
ﬁrst computes centrality scores for tweets kept in TCVs, and
selects the top-ranked ones in terms of content coverage and
novelty.
(2) To compute historical summaries where the
user speciﬁes an arbitrary time duration, we ﬁrst retrieve
two historical cluster snapshots from the PTF with respect
to the two endpoints (the beginning and ending points) of
the duration. Then, based on the diﬀerence between the two
cluster snapshots, the TCV-Rank summarization algorithm
is applied to generate summaries.

The summarization module also contains a topic evolve-
ment detection algorithm, which consumes online/historical
summaries to produce continuous/range timelines. A time-
line is a sequence of time-stamped summaries (nodes). Both
continuous and range timelines are generated by monitoring
a quantity called summary-based variation, which is deﬁned
for summaries during the course of topic evolvement. A large
variation at a particular moment implies a sub-topic change,
leading to the addition of a new node on the timeline.

The main contributions of our work include: (1) A con-
tinuous tweet stream summarization framework; (2) Novel
data structures and algorithms for online summarization and
historical summarization of any arbitrary time interval; (3)
A topic evolvement detection scheme for continuous and
range timelines; (4) Extensive experiments on real Twitter
datasets, showing promising results in terms of summary
quality and eﬃciency.

The rest of the paper is organized as follows. Section 2
reviews the related work. Section 3 explains concepts includ-
ing TCV and PTF. Section 4 describes our Sumblr frame-
work in detail. The experimental settings and results are
presented in Section 5. In Section 6, we conclude the paper.
2. RELATED WORK

In this section, we review the related work including stream
data clustering, traditional document summarization and mi-
croblog summarization and mining.
2.1 Stream Data Clustering

Stream data clustering has been widely studied in the lit-
erature. CluStream [1] is one of the most classic stream
clustering methods. It consists of an online micro-clustering
component and an oﬄine macro-clustering component. The
pyramidal time frame is also proposed in [1] to recall histor-
ical micro-clusters for diﬀerent time durations.

A variety of services on the Web such as news ﬁltering,
text crawling, and topic detecting etc. have posed require-
ments for text stream clustering. A few algorithms have
been proposed to tackle the problem [7][10][27][29]. Most
of these techniques adopt partition-based approaches to en-
able online clustering of stream data. As a consequence,
these techniques fail to provide eﬀective analysis on clusters
formed over diﬀerent time durations.

In [2], the authors propose to generate duration-based
clustering results by extending CluStream for text and cat-
egorical data stream. However, this algorithm relies on an
online phase to generate large number of “micro-clusters”,
leading to ineﬃciency and poor storage utilization.
2.2 Traditional Document Summarization

Document summarization techniques can be categorized
into two types: extractive techniques and abstractive ones.
The former selects sentences from the documents, while the
latter may generate phrases and sentences that do not ap-

Figure 2: The framework of Sumblr

Such application would not only facilitate easy navigation
in topic-relevant tweets, but also support a range of data
analysis tasks such as instant reports or historical survey.

Implementing continuous tweet stream summarization is
not an easy task, as the tweets are of noisy, redundant, and
social nature. More importantly, tweets arrive very quickly
and are strongly correlated with their posted time. A good
solution to continuous tweet stream summarization has to
address the following issues: (1) Eﬃciency - tweet streams
always have very large scales, so their summarization should
be highly eﬃcient, with only one pass over the data; (2)Flex-
ibility - the ability to provide tweet summaries of arbitrary
time durations. (3)Topic evolvement - to automatically de-
tect sub-topic changes and the moments that they happen.
Unfortunately, the importance of continuous summariza-
tion has long been overlooked by the research community.
Although there exist numerous studies on document sum-
marization [6, 26, 23, 13, 9, 11], these methods cannot sat-
isfy our requirements, because: (1) They mainly focus on
static and small-sized datasets, making it intractable to im-
prove their eﬃciency.
(2) To provide summary for arbi-
trary duration, these techniques will have to perform iter-
ative/recursive summarization for every possible time du-
ration, which is unacceptable. (3) The summary results of
these algorithms are insensitive to time. Thus it is diﬃcult
for them to detect topic evolvement.

In this paper, we introduce a novel tweet summarization
prototype called Sumblr (SUMmarization By stream cLus-
teRing). To the best of our knowledge, our work is the ﬁrst
to study continuous tweet stream summarization. The over-
all structure of the prototype is depicted in Figure 2. Sumblr
consists of two main components, namely a Tweet Stream
Clustering module and a High-level Summarization module.
In the tweet stream clustering module, we design an eﬃcient
tweet stream clustering algorithm, an online algorithm allow-
ing for eﬀective clustering of tweets with only one pass over
the data. This algorithm uses two data structures to keep
important tweet information in clusters. The ﬁrst one is a
compressed structure called Tweet Cluster Vector (TCV).
TCVs are considered as potential sub-topic delegates and
maintained dynamically in memory during stream process-
ing. The second structure is the Pyramidal Time Frame
(PTF) [1], which is used to store and organize cluster snap-
shots at diﬀerent moments, thus allowing historical tweet
data to be retrieved by any arbitrary time durations.

The high-level summarization module supports the gen-
eration of two kinds of summaries: online summaries and
historical ones. (1) To generate online summaries, we pro-
pose a TCV-Rank summarization algorithm by referring to

(cid:55)(cid:90)(cid:72)(cid:72)(cid:87)(cid:3)(cid:54)(cid:87)(cid:85)(cid:72)(cid:68)(cid:80)(cid:3)(cid:38)(cid:79)(cid:88)(cid:86)(cid:87)(cid:72)(cid:85)(cid:76)(cid:81)(cid:74)(cid:55)(cid:90)(cid:72)(cid:72)(cid:87)(cid:3)(cid:38)(cid:79)(cid:88)(cid:86)(cid:87)(cid:72)(cid:85)(cid:3)(cid:57)(cid:72)(cid:70)(cid:87)(cid:82)(cid:85)(cid:86)(cid:51)(cid:92)(cid:85)(cid:68)(cid:80)(cid:76)(cid:71)(cid:68)(cid:79)(cid:3)(cid:55)(cid:76)(cid:80)(cid:72)(cid:3)(cid:41)(cid:85)(cid:68)(cid:80)(cid:72)(cid:50)(cid:81)(cid:79)(cid:76)(cid:81)(cid:72)(cid:3)(cid:54)(cid:88)(cid:80)(cid:80)(cid:68)(cid:85)(cid:76)(cid:72)(cid:86)(cid:43)(cid:76)(cid:86)(cid:87)(cid:82)(cid:85)(cid:76)(cid:70)(cid:68)(cid:79)(cid:54)(cid:88)(cid:80)(cid:80)(cid:68)(cid:85)(cid:76)(cid:72)(cid:86)(cid:40)(cid:89)(cid:82)(cid:79)(cid:89)(cid:72)(cid:80)(cid:72)(cid:81)(cid:87)(cid:3)(cid:39)(cid:72)(cid:87)(cid:72)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:56)(cid:86)(cid:72)(cid:85)(cid:43)(cid:76)(cid:74)(cid:75)(cid:16)(cid:79)(cid:72)(cid:89)(cid:72)(cid:79)(cid:3)(cid:54)(cid:88)(cid:80)(cid:80)(cid:68)(cid:85)(cid:76)(cid:93)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:55)(cid:90)(cid:72)(cid:72)(cid:87)(cid:3)(cid:54)(cid:87)(cid:85)(cid:72)(cid:68)(cid:80)(cid:55)(cid:76)(cid:80)(cid:72)(cid:79)(cid:76)(cid:81)(cid:72)534pear in the original documents. In this paper, we focus on
extractive summarization.

Extractive document summarization has received a lot of
recent attention. Most of them assign salient scores to sen-
tences of the documents, and select the top-ranked sentences
[3][30] [19][26] [6][22]. Some works try to extract sentences
without such salient scores. A method using Singular Value
Decomposition (SVD) is proposed in [8] to select highly
ranked sentences. Wang et al. [23] use the Symmetric Non-
negative Matrix Factorization (SNMF) to cluster sentences
and choose sentences in each cluster for summarization. In
[11], He et al. propose to summarize documents from the
perspective of data reconstruction, and select sentences that
can best reconstruct the original documents. Unfortunately,
all above methods neglect the signiﬁcant temporal dimen-
sion of documents, which is critical in our problem.

Yan et al. propose a technique called Evolutionary Time-
line Summarization (ETS) [24] to compute evolution time-
lines consisting of individual but correlated component sum-
maries. However, the dates of component summaries are de-
termined by a pre-deﬁned timestamp set. In contrast, our
solution discovers the changing dates and generate timelines
dynamically during the process of continuous summariza-
tion. More importantly, ETS does not focus on eﬃciency
and scalability.
Its task is formulated as an optimization
problem via iterative substitution. Thus it does not meet
our requirements.
2.3 Microblog Summarization and Mining

While document summarization has been studied for years,
microblog summarization is still in its infancy. Shariﬁ et al.
proposed the Phrase Reinforcement algorithm to summarize
multiple tweet posts on the same topic with a single tweet
[20]. Later, Inouye et al. proposed a modiﬁed Hybrid TF-
IDF algorithm and a Cluster-based algorithm to generate
multiple post summaries [13]. In [9], Harabagiu et al.
in-
troduced a framework for microblog summarization which
capitalizes on a combination of two relevance models: an
event structure model and a user behavior model. Taka-
mura et al. proposed a microblog summarization method
based on the p-median problem, which takes posted time of
microblogs into consideration [21].

The emergence of microblogs also motivates research on
other mining tasks, including topic modeling [12], storyline
generation [14] and event exploration [17]. Most of these
researches focus on static datasets instead of data streams.
Yang et al. studied twitter stream analysis [25], but they
aim at frequent pattern mining and compression, which is
also a diﬀerent problem from ours.

To sum up, almost all existing document/microblog sum-
marization works mainly deal with static and small datsets,
and rarely pay attention to evolvement and eﬃciency issues.
3. PRELIMINARIES

In this section, we ﬁrst give a data model for tweets.
Then we introduce two data structures used in our solu-
tion, namely the Tweet Cluster Vector and the Pyramidal
Time Frame.
3.1 Tweet Representation

Generally, a document is represented as a textual vector,
where the value of each dimension is the TF-IDF score of a
word. However, tweets are not only textual, but also hav-
ing temporal nature - a tweet is strongly correlated with its
posted time. In addition, the importance of a tweet is af-

fected by the author’s social inﬂuence. To estimate the user
inﬂuence, we build a matrix based on social relationships
among users, and compute the UserRank as [5].

As a result, we deﬁne a tweet ti as a tuple: (tvi, tsi, wi),
where tvi is the textual vector, tsi is the posted timestamp
and wi is the UserRank value of the tweet’s author.
3.2 Tweet Cluster Vector

During tweet stream clustering, it is necessary to maintain
statistics for tweets to facilitate summary generation.
In
this section, we propose a new data structure called Tweet
Cluster Vector, which keeps information of tweet cluster.

n

Definition 1. For a cluster C containing tweets t1, t2, ..., tn,

textual vectors,
n

its Tweet Cluster Vector (TCV) is deﬁned as a tuple:
T CV (C) = (sum v, wsum v, ts1, ts2, n, f t set), where

∑
∑
• sum v =
i=1 tvi/||tvi|| is the sum of normalized
∑
i=1 wi·tvi is the sum of weighted textual
• wsum v =
∑
vectors,
• ts1 =
n
i=1 tsi is the sum of timestamps,
• ts2 =
n
i=1(tsi)2 is the quadratic sum of timestamps,
• n is the number of tweets in the cluster, and
• f t set is a focus tweet set of size m, consisting of the

closest m tweets to the cluster centroid.

The form of sum v is used for ease of presentation.
In
fact, we only store the identiﬁers and sums of values of the
words occurring in the cluster. The same convention is used
for wsum v. To select tweets into f t set, we use cosine
similarity as the distance metric.

From the deﬁnition, we can derive the vector of cluster

centroid (denoted as cv):

n∑

cv = (

i=1

wi · tvi)/n = wsum v/n

(1)

The deﬁnition of TCV is an extension of the cluster feature
vector in [28]. Like in [28], our TCV structure can also be
updated in an incremental way when new tweets arrive. We
shall discuss details on updates to TCV in Section 4.1.2.
3.3 Pyramidal Time Frame

To support summarization over user-deﬁned time dura-
tions, it is crucial to store the maintained TCVs at partic-
ular moments, which are called snapshots. While storing
snapshots at every moment is impractical due to huge stor-
age overhead, insuﬃcient snapshots make it hard to recall
historical information for diﬀerent durations. This dilemma
leads to the incorporation of the Pyramidal Time Frame [1]:

Definition 2. The Pyramidal Time Frame (PTF) stores

snapshots at diﬀering levels of granularity depending on the
recency. Snapshots are classiﬁed into diﬀerent orders which
vary from 0 to log(T ), where T is the time elapsed since the
beginning of the stream. The order of a particular class of
snapshots deﬁnes the level of granularity in time at which the
snapshots are maintained. The snapshots of diﬀerent orders
are maintained as follows:
• Snapshots of the i-th order occur at time intervals of
αi, where α is an integer and α ≥ 1. Speciﬁcally, each
snapshot of the i-th order is taken at a moment in time
when the timestamp from the beginning of the stream
is exactly divisible by αi.
• At any given moment in time, only the last αl + 1 (l ≥

1) snapshots of order i are stored.

535Table 1: Example of PTF with α = 3 and l = 2
Order Timestamps of snapshots in the same order

Algorithm 1: Incremental tweet stream clustering
Input: a cluster set S

4
3
2
1
0

81

54 27

72 63 45 36 18 9

84 78 75 69 66 60 57 51 48 42
86 85 83 82 80 79 77 76 74 73

According to the deﬁnition, PTF has two properties: (1)
The maximum order of any snapshot stored at T times-
tamps since the beginning of the stream is log(cid:11)(T ); (2) The
maximum number of snapshots maintained at T is (αl +
1) · log(cid:11)(T ). These properties are crucial for system per-
formance. Taking more snapshots (by using a larger α or
l) oﬀers better accuracy of time duration approximation,
but meanwhile causes larger storage overhead. Therefore,
we need to strike a balance between duration accuracy and
storage space. Note that we only maintain the current clus-
ters in main memory, and store all historical snapshots in
the PTF on disk.

To clarify how snapshots are stored, we give an example
here. Let α = 3 and l = 2, then there are at most 32 +1 = 10
snapshots stored in each order. Suppose the stream starts
at timestamp 1 and the current timestamp is 86. The stored
snapshots are illustrated in Table 1. Redundancy is removed
by storing each snapshot only in its highest possible order.
Note that for more recent timestamps, the time interval
between successive snapshots stored in PTF is smaller (ﬁner
granularity). This feature of PTF is consistent with the
demand that recent summaries should be of higher quality
because people usually care more about recent events.
4. THE SUMBLR FRAMEWORK

In this section, we present the details of our Sumblr frame-
work. As shown in Figure 2, our framework includes two
main modules: the tweet stream clustering module and the
high-level summarization module. In what follows, we will
elaborate these two modules respectively.
4.1 Tweet Stream Clustering

The tweet stream clustering module maintains the online
statistical data. Given a topic-based tweet stream, it is able
to eﬃciently cluster the tweets and maintain compact cluster
statistics, with only one scan on the data.
4.1.1 Initialization
At the beginning of the stream, we collect a small number
of tweets and use a k-means clustering algorithm to create
the initial clusters. The value of k and the initial cluster
centroids are decided via the Canopy [18] method. Once the
initial clusters are established, the ﬁrst set of TCVs are ini-
tialized according to Deﬁnition 1. Next, the stream cluster-
ing process starts to incrementally update the TCVs when
a new tweet arrives.
4.1.2 Incremental Clustering
Suppose a tweet t arrives at time ts, and there are N active
clusters at that time. First, we try to absorb t into one of the
current clusters. The priority is given to the cluster whose
centroid is the closest to t. Speciﬁcally, we get the centroid
(denoted as co) of a cluster based on Equation (1), compute
the cosine similarity between co and t, and ﬁnd the cluster
Cp with M axSim(co, t).

Note that although Cp is the closest to t, it does not mean
t naturally belongs to Cp. The reason is that t may still be

T weet t = stream.next();
choose Cp in S whose centroid is the closest to t;
if M axSim(cop, t) < M BS then

create a new cluster Cnew = {t};
S = S ∪ Cnew;

1 while !stream.end() do
2
3
4
5
6
7
8

update Cp with t;

else

9
10

if T Scurrent % (αi) == 0 then

store S into PTF;

very distant from Cp. In such case, a new cluster will be
created. The decision of whether to create a new cluster can
be made with the following heuristic.

Heuristic 1. If M axSim(co, t) is smaller than a Mini-
mum Bounding Similarity (MBS), then t is upgraded to
a new cluster. Otherwise, t is added to its closest cluster.
The MBS is deﬁned as β · Sim(co, ti), where β is a bound-
ing factor (0 < β < 1) and Sim(co, ti) is the average cosine
similarity between co and tweets included in Cp. According
to Section 3.2, Sim(co, ti) can be calculated by using the
information stored in TCV:

tvi · cv

||tvi|| · ||cv|| =

cv

n · ||cv||

tvi
||tvi||

n∑

i=1

1
n

n∑

i=1

Sim(co, ti) =

=

wsum v

n · || wsum v

|| · sum v =

wsum v · sum v
n · ||wsum v||
When adding a new cluster, it is hard to tell whether it is
noise or a truly new sub-topic. Actually, the decision cannot
be made until more tweets arrive. We discuss how noises are
diminished in Section 4.4.

n

n

After applying Heuristic 1, the corresponding TCV needs
to be updated. For a newly created cluster, its TCV can be
initialized easily. For an existing cluster, its components in
TCV can also be easily updated in an incremental manner,
except the focus tweet set.

Recall that in Deﬁnition 1, f t set is the set of the closest
m tweets to the cluster centroid. However, as new tweets
are added to the cluster during stream processing, the clus-
ter centroid would change unpredictably. Since we can not
store all tweets in the cluster, it is rather diﬃcult to main-
tain exact focus tweets. For this reason, we use a heuristic
strategy to choose promising candidates instead of exact fo-
cus tweets: for the newly absorbed tweet and those already
in f t set, we compute their cosine distances to the new cen-
troid, and select the closest m tweets. The advantage of
this strategy is that it gives a higher probability for fresh
tweets to get into the focus set, which usually represent new
statuses of the topic.

The above updating process is executed upon the arrival of
each new tweet. Meanwhile, when the current timestamp is
divisible by αi for any integer i, we store the snapshot of the
current TCVs into disk and index it by PTF. Algorithm 1
gives an overview of our incremental clustering procedure.

During incremental clustering, assume there are N active
clusters, the computational cost of ﬁnding the closest cluster
for every new tweet is O(N d), where d is the vocabulary size.
In addition, the complexity of computing Heuristic 1 and
updating TCV is O(d) and O(md) respectively, where m is

536Figure 3: Probability density func. of timestamp

Figure 4: A running example of cluster merging

the size of focus set. Then the total cost is O((N + m)d).
Because m and d are static, the computational cost depends
on N . Similarly, the storage costs in disk (TCV snapshots)
and memory (current TCVs) also depend on N .

Given the above analysis, we need to restrict the num-
ber of active clusters. We achieve this goal via two opera-
tions: deleting outdated clusters and merging similar clus-
ters. Since the computational complexity of deletion is O(N )
and that of merging is O(N 2), we use the former method for
periodical examination and use the latter method only when
memory limit is reached.
4.1.3 Deleting Outdated Clusters
For most events (such as news, football matches and con-
certs) in tweet stream, timeliness is important because they
usually do not last for a long time. Therefore it is safe to
delete the tweet clusters representing these sub-topics when
they are rarely discussed. To ﬁnd out such clusters, an intu-
itive way is to estimate the average arrival time (denoted as
Avgp) of the last p percent of tweets in a cluster. However,
storing p percent of tweets for every cluster will increase
memory requirements, especially when some clusters grow
√
big. Thus, we employ an approximate method to get Avgp.
Note that the temporal statistics in TCV of a cluster C al-
low us to compute the mean and standard deviation of times-
ts2/n − (ts1/n)2.
tamps of tweets in C: µc = ts1/n, σc =
Assuming that the tweet timestamps are normally dis-
tributed, we can obtain the arrival time of the qth percentile
of the tweets. The qth percentile is the value that cuts oﬀ the
ﬁrst q percent of the tweet timestamps when they are sorted
in ascending order. When q = 100 − p, the qth percentile is
the start timestamp of the last p percent of tweets (noted as
tsp in Figure 3). Then, we can approximate Avgp using the
(100 − p/2)-th percentile (noted as tsp=2 in Figure 3).
= (100 − p/2)%, we have
′
of tsp=2. Let x = tsp=2 and p
x − µc
σc

Now the problem is transformed into obtaining the value

F (x) = Φ(

⇒

′
) = p
−1(p
′
√
2erf

)

x = µc + σcΦ
= µc + σc ·

−1(2p

′ − 1)

where F (x) is the cumulative distribution function (CDF),
Φ(x) is the CDF of the standard normal distribution, and
−1(z) is the inverse error function and can be calculated
erf
using the Maclaurin series expansion [31].

The value of tsp=2 represents the freshness of cluster C.
We empirically set a freshness threshold as 3 days (as empir-
ically no bursty events would last longer) and set p = 10. If
tsp=2 is smaller than this threshold, i.e., the average times-

tamp of the latest 10 percent tweets is more than 3 days old,
then we regard C as an outdated cluster and remove it.
4.1.4 Merging Clusters
If the number of clusters keeps increasing and few of them
are deleted, the system memory will be exhausted. To avoid
this, we specify an upper limit for the number of clusters as
Nmax. When the limit is reached, a merging process starts.
The process merges clusters in a greedy way until the ter-
mination condition is satisﬁed. First, we sort all cluster pairs
by their centroid similarities in a descending order. Then,
beginning with the most similar pair, we try to merge two
clusters in the pair. When both clusters are single clusters
which have not been merged with other clusters, they are
merged into a new composite cluster. When one of them be-
longs to a composite cluster (it has been merged with others
before), then the other is also merged into that compos-
ite cluster. When both of them have been merged, if they
belong to the same composite cluster, this pair is skipped;
otherwise, the two composite clusters are merged together.
This process continues until there are only mc percentage
of the original clusters left (mc is a merge coeﬃcient which
provides a balance between available memory space and the
quality of remaining clusters). We omit the pseudo-code of
the algorithm due to space limitation.

During cluster merging, each composite cluster is given
an IDList which consists of IDs of the clusters merged in
it. Furthermore, its TCV is obtained by the Aggregation
operation to combine two TCVs.

Definition 3. (Aggregation Operation) Let C1 and C2
be two clusters, and their TCV structures be T CV (C1) and
T CV (C2). Then, when C1 and C2 are merged together, the
composite cluster’s T CV (C1 ∪ C2) is given by

• sum v = sum v1 + sum v2
• wsum v = wsum v1 + wsum v2
• ts1 = ts11 + ts12
• ts2 = ts21 + ts22
• n = n1 + n2
• f t set consists of the ﬁrst m tweets in f t set1∪f t set2,

sorted by distance to the newly merged centroid.

Figure 4 shows a running example of the process. For
ease of presentation, we use cluster centroids (the black solid
points) to represent clusters and use Euclidean distance in-
stead of cosine distance. First, we calculate distances for all
cluster pairs and sorted them as: (c1, c2), (c2, c4), (c1, c4),
(c5, c7), (c4, c5), .... Suppose mc = 0.7, then we need to re-
move 10× (1− 0.7) = 3 clusters. To start with, c1 and c2 are
merged into a composite cluster {c1, c2}. After that, when
processing the second pair (c2, c4), we ﬁnd that c2 has been
merged. Hence we combine c4 into {c1, c2}, and the compos-
ite cluster becomes {c1, c2, c4}. For next pair, c1 and c4 both
have been merged, so this pair is skipped. Next we merge
c5 and c7 into another composite cluster {c5, c7}. Now that
we have reduced the number of clusters by 3, the algorithm
terminates. Note that since only Nmax × (1 − mc) (denoted
as N
) clusters need to be removed, we would access at most
C 2
N′ + 1 = N
4.2 High-level Summarization

′ − 1)/2 + 1 pairs.

(N

′

′

The high-level summarization module provides two types
of summaries: online and historical summaries. The online
summaries are retrieved directly from the current clusters

(cid:70)(cid:87)(cid:86)(cid:73)(cid:11)(cid:87)(cid:86)(cid:12)(cid:87)(cid:86)(cid:83)(cid:87)(cid:86)(cid:83)(cid:18)(cid:21)(cid:11)(cid:20)(cid:3)(cid:16)(cid:83)(cid:12)(cid:8)(cid:11)(cid:83)(cid:18)(cid:21)(cid:12)(cid:8)(cid:70)(cid:20)(cid:70)(cid:21)(cid:70)(cid:22)(cid:70)(cid:23)(cid:70)(cid:24)(cid:70)(cid:25)(cid:70)(cid:26)(cid:70)(cid:27)(cid:70)(cid:28)(cid:70)(cid:20)(cid:19)(cid:94)(cid:70)(cid:20)(cid:15)(cid:70)(cid:21)(cid:96)(cid:94)(cid:70)(cid:24)(cid:15)(cid:70)(cid:26)(cid:96)(cid:94)(cid:70)(cid:20)(cid:15)(cid:70)(cid:21)(cid:15)(cid:70)(cid:23)(cid:96)537maintained in the memory. For historical summaries, re-
trieval of the required clusters is more complicated. In what
follows, we shall focus on the second type.

Suppose the length of a user-deﬁned time duration is H,
and the ending timestamp of the duration is tse. From PTF,
we can retrieve two snapshots whose timestamps are either
equal to or right before tse and tse − H, respectively. We
denote their timestamps by ts1 and ts2, and their cluster sets
by S(ts1) and S(ts2). Now the original duration [tse−H, tse]
is approximated by [ts2, ts1].

Intuitively, we need to perform a cluster set subtraction
between S(ts1) and S(ts2). For each cluster C in S(ts1), we
acquire its ID (if it is a single cluster) or IDs in its IDList
(a composite cluster). For each of these IDs, we ﬁnd the
corresponding cluster in S(ts2), and subtract its TCV from
C’s TCV according to:

Definition 4. (Subtraction Operation) Given a clus-
ter C1 in S(ts1) and its corresponding cluster C2 in S(ts2),
when C2 is subtracted from C1, their diﬀerence T CV (C1 −
C2) is given by

• sum v = sum v1 − sum v2
• wsum v = wsum v1 − wsum v2
• ts1 = ts11 − ts12
• ts2 = ts21 − ts22
• n = n1 − n2
• f t set consists of tweets which exist in f t set1 but not

in f t set2.

The above process eliminates the inﬂuence of clusters cre-
ated before ts2 on summary results. The ﬁnal set of clusters
after this process is the input for historical summarization.
4.2.1 TCV-Rank Summarization
Given an input cluster set, we denote its corresponding
TCV set as D(c). A tweet set T consists of all the tweets
in the f t sets in D(c). Our tweet summarization aims to
extract k tweets from T , so that they can cover as many
tweet contents as possible.

We ﬁrst prove it is a NP-hard problem, then we present a

greedy algorithm to solve it.

Lemma 1. The tweet summarization problem is NP-hard.
Proof. Let us ﬁrst describe this problem formally. F =
{T1, T2, ..., Tt} is a collection of non-empty subsets of T ,
where a subset Ti represents a sub-topic and |Ti| means the
number of its related tweets. The subsets may have some
tweets in common because one tweet can be related to more
than one sub-topic. Suppose for each Ti, there is a tweet
which represents the content of Ti’s sub-topic. Then, select-
ing k tweets is equivalent to selecting k subsets.
Now, the problem can be deﬁned as: given a number k and
a collection of sets F , ﬁnd a subset F′ ⊆ F, such that |F′| =
contains as many
tweets as possible). We notice that this is the Max-k-Cover
problem, which is NP-hard. Therefore, our summarization
problem is also NP-hard.

Ti∈F′ Ti| is maximized (i.e., F′

k and |∪

More generally, summary length are limited in terms of
words (250 words). Since the number of words and that of
tweets are linearly dependent, the problem is still NP-hard.

From the geometric interpretation, our summarization tends

to select tweets that span the intrinsic subspace of candidate
tweet space, such that it can cover most information of the
whole tweet set.

Algorithm 2: TCV-Rank summarization
Input: a cluster set D(c)
Output: a summary set S

1 S = ∅, T = {all the tweets in f t sets of D(c)};
2 Build a similarity graph on T ;
3 Compute LexRank scores LR;
4 Tc = {tweets with the highest score in each cluster};
5 while |S| < L do
6
7

calculate vi according to Equation (2);

foreach tweet ti in Tc do

select tmax with the highest vi;
8
S = S ∪ tmax;
9
10 while |S| < L do
i in T − S do
′
foreach tweet t
11
′
12
i according to Equation (2);

calculate v

13
14

′
select t
max with the highest v
S = S ∪ t

′
max;

′
i;

15 return S;

We design a greedy algorithm to select representative tweets

to form summaries (Algorithm 2). First, we gather tweets
from the f t sets in D(c) as a set T , and build a cosine simi-
larity graph. The maximum size of T is N × m, where N is
the number of clusters in D(c) and m is the size of f t set.
It is the upper bound because f t sets of some clusters (e.g.,
small clusters or clusters newly created) may not be full.
Next, we apply the LexRank method [6] to compute cen-
trality scores for tweets. LexRank is an eﬀective static sum-
marization method and is eﬃcient for small-sized datasets.
But when datasets become large, its eﬃciency drops quickly
(this will be shown in the experiment). The tweet set T
has at most N m tweets (usually hundreds or thousands), so
LexRank is suitable for our situation.

However, a potential problem of LexRank is that some
top-ranked tweets may have similar contents. Fortunately,
since the tweets are retrieved from TCVs, they have got
inherent cluster information. Hence, we choose one tweet
with the highest LexRank score from each TCV, and add
tweet t into the summary according to:

where λ (0 ≤ λ ≤ 1) is a weight parameter, nti is the size

of the cluster containing ti, nmax is the size of the biggest
cluster, LR(ti) is ti’s LexRank score and S is the summary
set containing already chosen tweets.

The motivation of Equation (2) is analogous to that of
Maximal Marginal Relevance (MMR) [4]. In query-oriented
summarization, MMR combines query relevance and infor-
mation novelty. Here, we combine coverage and novelty as
our criterion: the ﬁrst component on the right side of the
equation favors tweets which have high scores and belong
to big clusters (content coverage); the second component
penalizes redundant tweets with similar contents to those
already chosen (novelty).
After the ﬁrst round selection, if the summary length is
still not reached, then we try to select tweets globally (ti ∈
T − S) according to Equation (2).
The computational complexity for LexRank is O(r|T|2),
where r is the iteration number.
In tweet selection, note
that for each tweet, the ﬁrst component in the righthand of
Equation (2) only needs to be computed once, and the sec-

t = argmax

[λ

ti

nti
nmax

LR(ti) − (1 − λ) avg
tj∈S

Sim(ti, tj)],

(2)

538ond component can be updated incrementally. So the worst-
case cost of tweet selection is O(N 2 + (|S| − N ) · |T|). Since
|S| << |T|, the total cost for our algorithm is O(r|T|2 +
N 2) = O(rm2N 2). As mentioned before, N m is always
controlled at a relatively small number, hence the summa-
rization procedure is very eﬃcient.
4.3 Topic Evolvement Detection

Topic evolvment detection algorithm can produce contin-
uous and range timelines in a similar way. We shall only
describe the continuous case here.

As tweets arrive from the stream, online summaries are
generated continuously by utilizing real-time cluster statis-
tics. This allows for a continuous timeline. Generally, when
an obvious variation occurs in the main contents discussed
in tweets, we can expect a change of sub-topics (i.e., a time
node on the timeline). To quantify the variation, we use
Kullback-Leibler divergence to measure the distance between
two word distributions in two successive summaries Sp and
Sc, Sp is the previous summary and Sc is the current one.

p(w|Sc)ln

p(w|Sc)
p(w|Sp)

,

(3)

where

DKL(Sc||Sp) =

p(w|Sc) =
p(w|Sp) =

w∈V

∑
∑
∑

tf (w, Sc)
w′ tf (w′, Sc)
tf (w, Sp) + ϵ
w′ (tf (w′, Sp) + ϵ)

V is the vocabulary set and tf (w, S) is the term frequency
for word w in S. ϵ is a small positive constant for Laplace
Smoothing, which is applied to avoid zero values of p(w|Sp).
Furthermore, we normalize the distance into interval [0, 1)
using D = 1 − e

−DKL , for ease of comparison.

According to the summary-based variation, we determine

if the current time is a sub-topic changing node by:

Dcur
Davg

> τ,

where Dcur is the distance between current summary and its
previous neighboring summary, Davg is the average distance
of all the previous successive summary pairs which do not
produce time nodes, and τ (τ ≥ 1) is the decision threshold.
That is, we detect topic evolvement when there is a burst
in distances between successive summaries. In this way, we
can automatically draw a timeline as the stream proceeds.
4.4 Discussion

Handling noises The eﬀect of clusters of noises can be
diminished by two means in Sumblr. First, in tweet stream
clustering, noise clusters which are not updated frequently
will be deleted as outdated clusters. Second, in the summa-
rization step, tweets from noise clusters are far less likely to
be selected into summary, due to their small LexRank scores
and cluster sizes.

Extension to multi-topic streams So far we have
assumed a tweet stream of only one topic as the input to
Sumblr. However, we should note that Sumblr can be easily
extended for multi-topic streams. For example, when a new
tweet arrives, we ﬁrst decide its related topics by keyword
matching. Then it is delivered into diﬀerent groups of clus-
ters. Clusters are grouped by their corresponding topical
IDs. Consequently, Sumblr is applied within each cluster
group. It is important to note that this mechanism allows
for distributed system implementation.

Table 2: Basic information of 5 datasets

Topics (ﬁltering keywords)

#Tweets

Time Span

Obama
Chelsea

Arsenal Arsene Wenger

Tablet Smartphone Cellphone

Black Friday

5. EXPERIMENTS
5.1 Experimental Setup

95,055
438,884
323,555
231,011
124,684

2009.2 - 2009.10
2012.11 - 2012.12
2012.11 - 2012.12
2012.11 - 2012.12
2012.11 - 2012.12

Datasets We construct 5 datasets to evaluate Sumblr.
One is obtained by conducting keyword ﬁltering on a Twitter
dataset (from Feb. to Oct., 2009) used by [5]. The other
four include more recent tweets acquired in one month via
Twitter’s keyword tracking API 2. As we do not have access
to the respective users’ social networks for these four, we set
their weights of tweets wi to the default value of 1. Details
of the datasets are listed in Table 2.

Ground truth for summaries As no previous work has
conducted similar study on continuous summarization, we
have to build our own ground truth (reference summaries).
However, manual creation of these summaries is apparently
impractical due to the huge size of the datasets.

Thus, we employ a two-step method to obtain fair-quality

reference summaries without tremendous human labor:

1) Given a time duration, we ﬁrst retrieve the correspond-
ing tweet subset, and use the following three well-recognized
summarization algorithms to get three candidate summaries.
ClusterSum [13]: ﬁrst clusters the tweets and then sum-
marizes each cluster by picking the most weighted post ac-
cording to the hybrid TF-IDF weighting described in [13].

LexRank [6]: ﬁrst builds a sentence similarity graph, and
then selects important sentences based on the concept of
eigenvector centrality.

DSDR [11]: models the relationship among sentences us-
ing linear reconstruction, and ﬁnds an optimal set of repre-
sentative sentences to approximate the original documents,
by minimizing the reconstruction error.

2) Next, for each subset, the ﬁnal reference summary is
manually extracted from three candidate summaries. Pri-
ority is given to those sentences appearing in at least two
candidate summaries. The length of each summary is lim-
ited to 250 words.

Ground truth for timelines For the timeline gener-
ation test, the reference timelines are manually produced.
We choose the “Arsenal” and “Chelsea” datasets for this ex-
periment, as the ground truth for sport topics are relatively
easier to build manually. Speciﬁcally, we read through all the
related news during one month from news websites (Yahoo!
and ESPN), and select those dates as nodes on the refer-
ence timeline when important events happen, e.g., football
matches, players’ signing of new contracts, etc. 3

Baseline methods Most existing summarization meth-
ods are not designed to handle continuous summarization.
However, they can be adapted to streaming data by using
a sliding window scheme. As illustrated in Figure 8, each
window contains a certain number (window size) of tweets
which are summarized as a document. After that, the win-
dow moves forward by a step size, so that the oldest tweets
are discarded and the new ones are added into the window.

2https://dev.twitter.com/docs/api/1.1/post/statuses/ﬁlter
3Our datasets
at
http://db.zju.edu.cn/s/sumblr/.

and ground truth are

available

539Figure 5: Quality on step size

Figure 6: Eﬃciency on step size

Figure 7: Scalability on data size

Figure 8: The sliding window mechanism

In this way, we implement the sliding window version of the
above three algorithms, namely ClusterSum, LexRank, and
DSDR. The windows are dimensioned by number of tweets
instead of time duration, because the number of tweets may
vary dramatically across ﬁxed-length durations, leading to
very poor performance of the baseline algorithms.

Evaluation method We apply the popular ROUGE

toolkit [15] for evaluation. Among supported metrics, ROUGE-
1 has been demonstrated to be the most consistent with hu-
man judgement [16]. Considering the short and informal
nature of the tweet contents, we decide that ROUGE-1 is
suitable for measuring tweet summaries.

To evaluate the metrics on a continuous time period [T0, T ],
we have to calculate the integral of the metric over the pe-

riod, which is given by∫

T

T0

metric(t)dt

(4)

The integral requires unaﬀordable number of samplings dur-
ing the period. In practice, we only sample the metrics by
each arrival of a certain number of new tweets. This number
is called the sampling interval. Note the sampling interval
must be no greater than the step size.

In our experiments, we ﬁnd similar trends in the compar-
ison of precision, recall and F-score between the proposed
approach and the baseline methods. Therefore, we shall
only report the F-score results to save space. The F-score
results presented are averaged on all ﬁve datasets.
5.2 Overall Performance Comparison

In this section, we compare the F-scores and runtime cost
between Sumblr and the three baseline algorithms (sliding
window version). As tweets are often produced very quickly
and reach a huge volume in a short while, it is hardly mean-
ingful to summarize a small number of tweets. Thus the
window size should be a relatively large one.
In this ex-
periment, we set window size to 20000, sampling interval to
2000. The step size varies from 4000 to 20000. The metrics
are averaged over the whole stream.

Figure 5 and Figure 6 present the results for diﬀerent step
sizes. In Figure 5, we also give a baseline Random method,
which selects tweets randomly from each window. Note that
Sumblr is not aﬀected by the step size, as it supports con-
tinuous summarization inherently.

The results show that when the step size is small (4000),

DSDR and LexRank achieve better summary quality than
Sumblr, at the expense of much more computation. When
step size ≥ 12000, Sumblr outperforms all the baseline meth-
ods in terms of both summarization quality and computation
cost. Although the eﬃciency of LexRank is comparable with
our method when step size ≥ 16000, its summary quality is
signiﬁcantly worse.

The above results reveal a major problem with the base-
line methods: These methods rely on a small step size to
produce quality summaries. Unfortunately, small step size
leads to very frequent and expensive computations for win-
dows. In contrast, Sumblr strikes a good balance between
summary quality and eﬃciency.

Another issue to note here is that, as the ground truth is
generated using these baseline methods, the summary qual-
ity is to some extent biased in favor of them.
Scalability
The scalability experiment evaluates the eﬃciency results of
a single window, while varying the window size. It simulates
the case of a large burst of tweets in a short period.

Figure 7 presents the scalability results for diﬀerent meth-
ods. Note that the y-axis is in the log scale. We can see that
our method outperforms the others signiﬁcantly. When the
data size is above 15000, Sumblr is faster than LexRank by
nearly an order of magnitude, and outperforms the other
two by more than that. The small ﬂuctuations in Sumblr
may be caused by the cluster deletions and merges.
5.3 Parameter Tuning

In this section, we tune the parameters in our approach.
In each of the following experiments, we vary one parameter
and keep the others ﬁxed.

Eﬀect of β. In Heuristic 1 we use β to determine whether
to create a new cluster. Figure 9(a) and Figure 9(b) show its
eﬀect on summary quality and eﬃciency. When β is small,
tweets related to diﬀerent sub-topics may be absorbed into
the same clusters, so the input of our summarization com-
ponent is of low quality. At the same time, there are many
focus tweets in each cluster, thus the time cost of cluster
updating and summarization is high. When β increases, too
many clusters are created, causing damage to both quality
and eﬃciency. A good choice is β = 0.07 as it gives more
balanced results.

Eﬀect of Nmax. Figure 9(c) and Figure 9(d) depicts
the performance of Nmax. For small Nmaxs, many merging
operations are conducted, which are time-consuming and
produce lots of low-quality clusters. For large values, stream
clustering is slow due to large number of clusters. Note
that the storage overhead (both in memory and disk) is also
higher for larger Nmaxs. A balanced value for Nmax is 150.
Eﬀect of mc. Another parameter in cluster merging is
mc (0 < mc < 1). It does not have signiﬁcant impact on

400080001200016000200000.250.300.350.400.450.50F-scorestep_size Random ClusterSum DSDR LexRank Sumblr40008000120001600020000020004000600080002000040000runtime (sec)step_size ClusterSum DSDR LexRank Sumblr05k10k15k20k25k30k35k40k10100100010000runtime (sec)data size ClusterSum DSDR LexRank Sumblr(cid:21)(cid:78)(cid:23)(cid:78)(cid:25)(cid:78)(cid:27)(cid:78)(cid:87)(cid:90)(cid:72)(cid:72)(cid:87)(cid:3)(cid:3)(cid:86)(cid:87)(cid:85)(cid:72)(cid:68)(cid:80)(cid:90)(cid:76)(cid:81)(cid:71)(cid:82)(cid:90)(cid:3)(cid:86)(cid:76)(cid:93)(cid:72)(cid:86)(cid:87)(cid:72)(cid:83)(cid:86)(cid:76)(cid:93)(cid:72)(cid:86)(cid:79)(cid:76)(cid:71)(cid:76)(cid:81)(cid:74)(cid:3)(cid:90)(cid:76)(cid:81)(cid:71)(cid:82)(cid:90)540(a) eﬀect of (cid:12) on quality

(b) eﬀect of (cid:12) on eﬃciency

(c) eﬀect of Nmax on quality

(d) eﬀect of Nmax on eﬃciency

(e) eﬀect of mc

(f) eﬀect of m

(g) eﬀect of (cid:21)

Figure 9: Performance of diﬀerent parameters

eﬃciency, so we only present its quality results (Figure 9(e)).
Small values of mc result in low-quality clusters, while large
ones lead to many merging operations, which in turn reduce
the quality of clusters. An ideal value for mc is 0.7.
Eﬀect of m. As shown in Figure 9(f), the summary
quality improves when m increases. When m ≥ 40, the
improvement is not obvious. Meanwhile, a larger m incurs
more storage overhead. We choose m = 40.
Eﬀect of λ. Finally we check the eﬀect of λ (0 ≤ λ ≤ 1),
which is a trade-oﬀ factor between content coverage and
novelty. We gradually vary λ from 0 to 1 at the step of 0.1
to examine its eﬀect, as shown in Figure 9(g). When λ ≥ 0.7,
the extreme emphasis on coverage causes performance loss.
Therefore, we set λ = 0.4 as a balanced factor.
5.4 Flexibility

One distinguishing feature of Sumblr is the ﬂexibility to
summarize tweets over arbitrary time durations. This fea-
ture is provided by incorporating the PTF. The eﬀective-
ness of PTF depends on α and l (Section 3.3). We ﬁx α
at 2 and show the results varying l. For consistency, we
extract a subset of one-month period from each dataset as
the input stream. The interval between two successive snap-
shots (timestamp unit) is one hour. For a timestamp ts, we
evaluate the results for drill-down/roll-up summaries using
durations with diﬀerent length len. Due to space limit, we
only present the average F-score for len varying from 1 day
to 10 days, and report score(ts) by interval of 48 hours.

∑
len F -score([ts − len, ts])

score(ts) =

10

(5)

Figure 10 gives the following observations:
• There exists a common trend for all ls: as a time dura-
tion is closer to the current time, the summary quality
improves. This is because PTF has ﬁner granularity of
snapshots for more recent moments. Thus the queried
durations can be better approximated.
• For diﬀerent values of l, the summary quality is similar
for recent durations, but decreases in diﬀerent degrees for
early durations. The reason is that for recent moments,
most of their snapshots or neighborhood snapshots are
still kept in PTFs regardless of l; while for early moments,
their snapshots are more likely to be removed from PTFs
with smaller ls, due to smaller capacity of each order.

Figure 11: Eﬀect of τ

Figure 10: Quality on time
duration
• A larger l leads to better results but more storage cost
(the numbers in the parentheses represent the amounts
of snapshots in PTF). This is obvious, as a larger l en-
ables PTF to store more snapshots, which results in more
accurate approximation and heavier storage burden.

For diﬀerent applications, Sumblr can be customized with
diﬀerent l values. For example, for real-time summarization,
a small l is enough; while for historical review, a large l is
needed.
5.5 Timeline Generation

In this section, we evaluate the eﬀectiveness of topic evolve-
ment detection. We present the precision, recall, and F-score
of the timeline nodes detected by our algorithm while vary-
ing the decision threshold τ .

From Figure 11, we can see that the recall declines as τ
increases. This is expected as higher threshold would ex-
clude more promising candidates i.e., produce more false
negatives. The precision and F-score both reach the highest
value when τ = 1.012. Although the recall drops when τ
increases, precision increases further (as more false positive
nodes are excluded). Surprisingly, when τ > 1.012, preci-
sion also drops. This may result from the incompleteness of
our manual timeline or noises in the datasets.

The output for “Arsenal” is presented in Table 3.

It is
interesting to ﬁnd that our summary-based timeline not only
detects important events (e.g. a match is called oﬀ due to a
tube strike), but also contains popular public opinions (e.g.
public calling for WENGER OUT).
6. CONCLUSION

We proposed a prototype called Sumblr which supported
continuous tweet stream summarization. Sumblr employed

0.040.050.060.070.080.090.100.110.370.380.390.400.410.42F-scoreβ0.040.050.060.070.080.090.100.1160090012001500180021002400runtime (sec)β305070901101301501701902100.340.360.380.400.42F-scoreNmax30507090110130150170190210600900120015001800210024002700Nmaxruntime (sec)0.00.10.20.30.40.50.60.70.80.91.00.390.400.410.42F-scoremc10203040506070800.4050.4100.4150.420F-scorem0.00.10.20.30.40.50.60.70.80.91.00.370.380.390.400.410.42F-scoreλ2883363844324805285766240.340.360.380.400.420.44endstartscorets l = 8 (592) l = 5 (173) l = 3 (63)1.0001.0041.0081.0121.0161.0200.00.10.20.30.40.50.60.70.8τ Precision Recall F-score541Table 3: Selected part of the timeline for “Arsenal”

12.12:
1. Yes Bradford! WENGER OUT.
2. Arsenal lose to Bradford: Should Arsene Wenger go?
3. Arsenal Chief Executive Ivan Gazidis has apologised to the club’s fans,
and described Arsenal’s defeat to Bradford.
12.16:
1. Every arsenal fan knows how chelsea fans feel like right now.
2. Game over, we lost.. Am I sad? No are arsenal fans happy? Yes, are
they gonna ever play world club cup? No.
3. RVP: ”I’m sorry to Arsenal fans, I’ve never been happier than this.
Finally I found a home and peace here. I’m happy at Man United.”
12.18:
1. Arsenal vs Reading Come on arsenal ♯Arsenal
2. What a come back! Cazorla is a class! But I love how Wenger gave the
right position for Walcott.
3. I know it’s ”only” Reading but still good to see Arsenal playing so well.

♯afc Arsenal’s Premier League match against West Ham on

12.19:
1. Good news for Arsenal fans: Wilshere, Oxlade-Chamberlain,
Ramsey, Gibbs and Jenkinson sign new contracts.
2.
Boxing Day is called oﬀ because of a possible tube strike.
3. Five Arsenal players sign new contracts, but not one of those
ﬁve is Theo Walcott.
4. Wenger: ”We hope we will be capable of building a team around
the young English players.” ♯Arsenal ♯AFC
12.20:
1. Champions League draw: Manchester United v Real Madrid,
Arsenal v Bayern Munich, Celtic v Juventus.
2. So it is @Arsenal Vs Bayern Munich....good game we’ll have :-)
12.22:
1. Arsenal better win the game against wigan.
2. Wilshere hails Arsenal’s ﬁghting spirit after Wigan win.

a tweet stream clustering algorithm to compress tweets into
TCVs and maintain them in an online fashion. Then, it
used a TCV-Rank summarization algorithm for generating
online summaries and historical summaries with arbitrary
time durations. The topic evolvement could be detected au-
tomatically, allowing Sumblr to produce dynamic timelines
for tweet streams. The experimental results demonstrated
the eﬃciency and eﬀectiveness of our method. For future
work, we aim to develop a multi-topic version of Sumblr in
a distributed system, and evaluate it on more complete and
large-scale datasets.
Acknowledgments
The work is supported by the National Science Foundation
of China (GrantNo. 61170034).
7. REFERENCES
[1] C. C. Aggarwal, J. Han, J. Wang, and P. S. Yu. A

framework for clustering evolving data streams. In VLDB,
pages 81–92, 2003.

[2] C. C. Aggarwal and P. S. Yu. On clustering massive text

and categorical data streams. Knowl. Inf. Syst.,
24(2):171–196, 2010.

[3] R. Barzilay and M. Elhadad. Using lexical chains for text
summarization. In Proceedings of the ACL Workshop on
Intelligent Scalable Text Summarization, pages 10–17, 1997.

[4] J. Carbonell and J. Goldstein. The use of mmr,

diversity-based reranking for reordering documents and
producing summaries. In SIGIR, pages 335–336, 1998.
[5] C. Chen, F. Li, B. C. Ooi, and S. Wu. Ti: an eﬃcient
indexing mechanism for real-time search on tweets. In
SIGMOD, pages 649–660, 2011.

[6] G. Erkan and D. R. Radev. Lexrank: graph-based lexical
centrality as salience in text summarization. J. Artif. Int.
Res., 22(1):457–479, 2004.

[7] L. Gong, J. Zeng, and S. Zhang. Text stream clustering

algorithm based on adaptive feature selection. Expert Syst.
Appl., 38(3):1393–1399, 2011.

[8] Y. Gong and X. Liu. Generic text summarization using

relevance measure and latent semantic analysis. In SIGIR,
pages 19–25, 2001.

[9] S. M. Harabagiu and A. Hickl. Relevance modeling for

microblog summarization. In ICWSM, 2011.

[10] Q. He, K. Chang, E.-P. Lim, and J. Zhang. Bursty feature

representation for clustering text streams. In SDM, 2007.

[11] Z. He, C. Chen, J. Bu, C. Wang, L. Zhang, D. Cai, and

X. He. Document summarization based on data
reconstruction. In AAAI, 2012.

[12] L. Hong, A. Ahmed, S. Gurumurthy, A. J. Smola, and

K. Tsioutsiouliklis. Discovering geographical topics in the
twitter stream. In WWW, pages 769–778, 2012.
[13] D. Inouye and J. K. Kalita. Comparing twitter

summarization algorithms for multiple post summaries. In
SocialCom, pages 298–306, 2011.

[14] C. Lin, C. Lin, J. Li, D. Wang, Y. Chen, and T. Li.

Generating event storylines from microblogs. In CIKM,
pages 175–184, 2012.

[15] C.-Y. Lin. Rouge: A package for automatic evaluation of

summaries. In Proc. ACL workshop on Text
Summarization Branches Out, pages 74–81, 2004.

[16] C.-Y. Lin and E. Hovy. Automatic evaluation of summaries

using n-gram co-occurrence statistics. In HLT-NAACL,
pages 71–78, 2003.

[17] A. Marcus, M. S. Bernstein, O. Badar, D. R. Karger,

S. Madden, and R. C. Miller. Twitinfo: aggregating and
visualizing microblogs for event exploration. In CHI, pages
227–236, 2011.

[18] A. McCallum, K. Nigam, and L. H. Ungar. Eﬃcient

clustering of high-dimensional data sets with application to
reference matching. In KDD, pages 169–178, 2000.

[19] D. R. Radev, H. Jing, M. Sty´s, and D. Tam.

Centroid-based summarization of multiple documents. Inf.
Process. Manage., 40(6):919–938, 2004.

[20] B. Shariﬁ, M.-A. Hutton, and J. Kalita. Summarizing

microblogs automatically. In HLT-NAACL, pages 685–688,
2010.

[21] H. Takamura, H. Yokono, and M. Okumura. Summarizing a

document stream. In ECIR, 2011.

[22] X. Wan and J. Yang. Multi-document summarization using
cluster-based link analysis. In SIGIR, pages 299–306, 2008.

[23] D. Wang, T. Li, S. Zhu, and C. Ding. Multi-document
summarization via sentence-level semantic analysis and
symmetric matrix factorization. In SIGIR, pages 307–314,
2008.

[24] R. Yan, X. Wan, J. Otterbacher, L. Kong, X. Li, and

Y. Zhang. Evolutionary timeline summarization: a
balanced optimization framework via iterative substitution.
In SIGIR, pages 745–754, 2011.

[25] X. Yang, A. Ghoting, Y. Ruan, and S. Parthasarathy. A

framework for summarizing and analyzing twitter feeds. In
KDD, pages 370–378, 2012.

[26] W.-t. Yih, J. Goodman, L. Vanderwende, and H. Suzuki.

Multi-document summarization by maximizing informative
content-words. In IJCAI, pages 1776–1782, 2007.

[27] J. Zhang, Z. Ghahramani, and Y. Yang. A probabilistic

model for online document clustering with application to
novelty detection. In NIPS, 2005.

[28] T. Zhang, R. Ramakrishnan, and M. Livny. Birch: an

eﬃcient data clustering method for very large databases. In
SIGMOD, pages 103–114, 1996.

[29] S. Zhong. Eﬃcient streaming text clustering. Neural

Networks, 18(5-6):790–798, 2005.

[30] Q. Zhou, L. Sun, and J. Nie. Is sum: A multi-document

summarizer based on document index graphic and lexical
chains. DUC2005, 2005.

[31] D. Zwillinger. CRC standard mathematical tables and

formulae. CRC press, 2011.

542